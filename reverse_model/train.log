2020-03-26 21:33:27,498 Hello! This is Joey-NMT.
2020-03-26 21:33:27,501 Total params: 113344
2020-03-26 21:33:27,501 Trainable parameters: ['decoder.att_vector_layer.bias', 'decoder.att_vector_layer.weight', 'decoder.attention.key_layer.weight', 'decoder.bridge_layer.bias', 'decoder.bridge_layer.weight', 'decoder.output_layer.weight', 'decoder.rnn.bias_hh_l0', 'decoder.rnn.bias_ih_l0', 'decoder.rnn.weight_hh_l0', 'decoder.rnn.weight_ih_l0', 'encoder.rnn.bias_hh_l0', 'encoder.rnn.bias_hh_l0_reverse', 'encoder.rnn.bias_ih_l0', 'encoder.rnn.bias_ih_l0_reverse', 'encoder.rnn.weight_hh_l0', 'encoder.rnn.weight_hh_l0_reverse', 'encoder.rnn.weight_ih_l0', 'encoder.rnn.weight_ih_l0_reverse', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-03-26 21:33:27,502 cfg.name                           : reverse_experiment
2020-03-26 21:33:27,502 cfg.data.src                       : src
2020-03-26 21:33:27,502 cfg.data.trg                       : trg
2020-03-26 21:33:27,502 cfg.data.train                     : test/data/reverse/train
2020-03-26 21:33:27,502 cfg.data.dev                       : test/data/reverse/dev
2020-03-26 21:33:27,502 cfg.data.test                      : test/data/reverse/test
2020-03-26 21:33:27,502 cfg.data.level                     : word
2020-03-26 21:33:27,502 cfg.data.lowercase                 : False
2020-03-26 21:33:27,502 cfg.data.max_sent_length           : 25
2020-03-26 21:33:27,502 cfg.data.src_voc_min_freq          : 0
2020-03-26 21:33:27,502 cfg.data.src_voc_limit             : 100
2020-03-26 21:33:27,502 cfg.data.trg_voc_min_freq          : 0
2020-03-26 21:33:27,503 cfg.data.trg_voc_limit             : 100
2020-03-26 21:33:27,503 cfg.testing.beam_size              : 1
2020-03-26 21:33:27,503 cfg.testing.alpha                  : 1.0
2020-03-26 21:33:27,503 cfg.training.random_seed           : 42
2020-03-26 21:33:27,503 cfg.training.optimizer             : adam
2020-03-26 21:33:27,503 cfg.training.learning_rate         : 0.001
2020-03-26 21:33:27,503 cfg.training.learning_rate_min     : 0.0002
2020-03-26 21:33:27,503 cfg.training.weight_decay          : 0.0
2020-03-26 21:33:27,503 cfg.training.clip_grad_norm        : 1.0
2020-03-26 21:33:27,503 cfg.training.batch_size            : 10
2020-03-26 21:33:27,503 cfg.training.batch_type            : sentence
2020-03-26 21:33:27,503 cfg.training.scheduling            : plateau
2020-03-26 21:33:27,504 cfg.training.patience              : 5
2020-03-26 21:33:27,504 cfg.training.decrease_factor       : 0.5
2020-03-26 21:33:27,504 cfg.training.early_stopping_metric : eval_metric
2020-03-26 21:33:27,504 cfg.training.epochs                : 2
2020-03-26 21:33:27,504 cfg.training.validation_freq       : 1000
2020-03-26 21:33:27,504 cfg.training.logging_freq          : 100
2020-03-26 21:33:27,504 cfg.training.eval_metric           : bleu
2020-03-26 21:33:27,504 cfg.training.model_dir             : reverse_model
2020-03-26 21:33:27,504 cfg.training.overwrite             : True
2020-03-26 21:33:27,504 cfg.training.shuffle               : True
2020-03-26 21:33:27,504 cfg.training.use_cuda              : False
2020-03-26 21:33:27,504 cfg.training.max_output_length     : 30
2020-03-26 21:33:27,504 cfg.training.print_valid_sents     : [0, 3, 6]
2020-03-26 21:33:27,504 cfg.training.keep_last_ckpts       : 2
2020-03-26 21:33:27,505 cfg.model.initializer              : xavier
2020-03-26 21:33:27,505 cfg.model.embed_initializer        : normal
2020-03-26 21:33:27,505 cfg.model.embed_init_weight        : 0.1
2020-03-26 21:33:27,505 cfg.model.bias_initializer         : zeros
2020-03-26 21:33:27,505 cfg.model.init_rnn_orthogonal      : False
2020-03-26 21:33:27,505 cfg.model.lstm_forget_gate         : 0.0
2020-03-26 21:33:27,505 cfg.model.encoder.rnn_type         : lstm
2020-03-26 21:33:27,505 cfg.model.encoder.embeddings.embedding_dim : 16
2020-03-26 21:33:27,505 cfg.model.encoder.embeddings.scale : False
2020-03-26 21:33:27,505 cfg.model.encoder.hidden_size      : 64
2020-03-26 21:33:27,505 cfg.model.encoder.bidirectional    : True
2020-03-26 21:33:27,506 cfg.model.encoder.dropout          : 0.1
2020-03-26 21:33:27,506 cfg.model.encoder.num_layers       : 1
2020-03-26 21:33:27,506 cfg.model.decoder.rnn_type         : lstm
2020-03-26 21:33:27,506 cfg.model.decoder.embeddings.embedding_dim : 16
2020-03-26 21:33:27,506 cfg.model.decoder.embeddings.scale : False
2020-03-26 21:33:27,506 cfg.model.decoder.hidden_size      : 64
2020-03-26 21:33:27,506 cfg.model.decoder.dropout          : 0.1
2020-03-26 21:33:27,506 cfg.model.decoder.hidden_dropout   : 0.1
2020-03-26 21:33:27,506 cfg.model.decoder.num_layers       : 1
2020-03-26 21:33:27,506 cfg.model.decoder.input_feeding    : True
2020-03-26 21:33:27,506 cfg.model.decoder.init_hidden      : bridge
2020-03-26 21:33:27,506 cfg.model.decoder.attention        : luong
2020-03-26 21:33:27,506 cfg.dqn.epochs                     : 2000
2020-03-26 21:33:27,507 cfg.dqn.sample_size                : 800
2020-03-26 21:33:27,507 cfg.dqn.lr                         : 0.01
2020-03-26 21:33:27,507 cfg.dqn.egreed_max                 : 0.9
2020-03-26 21:33:27,507 cfg.dqn.egreed_min                 : 0.01
2020-03-26 21:33:27,507 cfg.dqn.gamma_max                  : 0.9
2020-03-26 21:33:27,507 cfg.dqn.gamma_min                  : 0.5
2020-03-26 21:33:27,507 cfg.dqn.nu_iter                    : 200
2020-03-26 21:33:27,507 cfg.dqn.mem_cap                    : 5000
2020-03-26 21:33:27,507 cfg.dqn.beam_min                   : 2
2020-03-26 21:33:27,507 cfg.dqn.beam_max                   : 50
2020-03-26 21:33:27,507 cfg.dqn.state_type                 : hidden
2020-03-26 21:33:27,507 Data set sizes: 
	train 50000,
	valid 1001,
	test 1001
2020-03-26 21:33:27,507 First training example:
	[SRC] 28 14 42 7 20 38 18
	[TRG] 18 38 20 7 42 14 28
2020-03-26 21:33:27,507 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) 15 (5) 35 (6) 44 (7) 18 (8) 36 (9) 16
2020-03-26 21:33:27,508 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) 15 (5) 35 (6) 44 (7) 18 (8) 36 (9) 16
2020-03-26 21:33:27,508 Number of Src words (types): 54
2020-03-26 21:33:27,508 Number of Trg words (types): 54
2020-03-26 21:33:27,508 Model(
	encoder=RecurrentEncoder(LSTM(16, 64, batch_first=True, bidirectional=True)),
	decoder=RecurrentDecoder(rnn=LSTM(80, 64, batch_first=True), attention=LuongAttention),
	src_embed=Embeddings(embedding_dim=16, vocab_size=54),
	trg_embed=Embeddings(embedding_dim=16, vocab_size=54))
2020-03-26 21:33:27,508 EPOCH 1
2020-03-26 21:33:36,268 Epoch   1 Step:      100 Batch Loss:    57.503601 Tokens per Sec:     1555, Lr: 0.001000
2020-03-26 21:33:46,230 Epoch   1 Step:      200 Batch Loss:     8.731578 Tokens per Sec:     1420, Lr: 0.001000
2020-03-26 21:33:57,363 Epoch   1 Step:      300 Batch Loss:    43.461266 Tokens per Sec:     1252, Lr: 0.001000
2020-03-26 21:34:13,569 Epoch   1 Step:      400 Batch Loss:    69.030846 Tokens per Sec:      878, Lr: 0.001000
2020-03-26 21:34:21,392 Epoch   1 Step:      500 Batch Loss:    34.503277 Tokens per Sec:     1775, Lr: 0.001000
2020-03-26 21:34:28,109 Epoch   1 Step:      600 Batch Loss:    31.264904 Tokens per Sec:     2093, Lr: 0.001000
2020-03-26 21:34:34,290 Epoch   1 Step:      700 Batch Loss:     6.033685 Tokens per Sec:     2243, Lr: 0.001000
2020-03-26 21:34:42,656 Epoch   1 Step:      800 Batch Loss:    55.378326 Tokens per Sec:     1654, Lr: 0.001000
2020-03-26 21:34:52,873 Epoch   1 Step:      900 Batch Loss:    77.966179 Tokens per Sec:     1374, Lr: 0.001000
2020-03-26 21:35:03,792 Epoch   1 Step:     1000 Batch Loss:    54.161400 Tokens per Sec:     1278, Lr: 0.001000
2020-03-26 21:35:10,757 Hooray! New best validation result [eval_metric]!
2020-03-26 21:35:10,757 Saving new checkpoint.
2020-03-26 21:35:10,761 Example #0
2020-03-26 21:35:10,762 	Raw source:     ['1', '2', '3', '4', '5']
2020-03-26 21:35:10,762 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-03-26 21:35:10,762 	Source:     1 2 3 4 5
2020-03-26 21:35:10,762 	Reference:  5 4 3 2 1
2020-03-26 21:35:10,762 	Hypothesis: 5 4 3 2 1
2020-03-26 21:35:10,762 Example #3
2020-03-26 21:35:10,762 	Raw source:     ['22', '11', '39', '17', '45', '8', '9', '5', '49', '38', '46', '6', '0', '24', '11', '17', '0', '6', '36', '9', '49', '6', '35', '2', '25', '6', '27', '49', '10']
2020-03-26 21:35:10,762 	Raw hypothesis: ['10', '49', '27', '6', '25', '2', '35', '6', '49', '9', '36', '41', '0', '17', '17', '24', '24', '24', '41']
2020-03-26 21:35:10,762 	Source:     22 11 39 17 45 8 9 5 49 38 46 6 0 24 11 17 0 6 36 9 49 6 35 2 25 6 27 49 10
2020-03-26 21:35:10,762 	Reference:  10 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 49 5 9 8 45 17 39 11 22
2020-03-26 21:35:10,762 	Hypothesis: 10 49 27 6 25 2 35 6 49 9 36 41 0 17 17 24 24 24 41
2020-03-26 21:35:10,762 Example #6
2020-03-26 21:35:10,762 	Raw source:     ['37', '44', '14', '8', '3', '24', '4', '15', '27', '44', '41', '0', '44', '0', '28', '1', '46', '18', '10', '48', '9', '2', '22', '45', '6', '12', '37']
2020-03-26 21:35:10,763 	Raw hypothesis: ['37', '12', '6', '45', '22', '2', '9', '48', '10', '18', '18', '1', '28', '0', '0', '44', '0', '0', '41', '44', '44', '44']
2020-03-26 21:35:10,763 	Source:     37 44 14 8 3 24 4 15 27 44 41 0 44 0 28 1 46 18 10 48 9 2 22 45 6 12 37
2020-03-26 21:35:10,763 	Reference:  37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 27 15 4 24 3 8 14 44 37
2020-03-26 21:35:10,763 	Hypothesis: 37 12 6 45 22 2 9 48 10 18 18 1 28 0 0 44 0 0 41 44 44 44
2020-03-26 21:35:10,763 Validation result (greedy) at epoch   1, step     1000: bleu:  62.94, loss: 24412.4727, ppl:   4.4603, duration: 6.9694s
2020-03-26 21:35:23,093 Epoch   1 Step:     1100 Batch Loss:    25.324892 Tokens per Sec:     1119, Lr: 0.001000
2020-03-26 21:35:32,149 Epoch   1 Step:     1200 Batch Loss:    12.057315 Tokens per Sec:     1559, Lr: 0.001000
2020-03-26 21:35:38,842 Epoch   1 Step:     1300 Batch Loss:     2.377383 Tokens per Sec:     2110, Lr: 0.001000
2020-03-26 21:35:47,519 Epoch   1 Step:     1400 Batch Loss:     1.002357 Tokens per Sec:     1605, Lr: 0.001000
2020-03-26 21:35:57,343 Epoch   1 Step:     1500 Batch Loss:     1.234048 Tokens per Sec:     1435, Lr: 0.001000
2020-03-26 21:36:07,439 Epoch   1 Step:     1600 Batch Loss:     0.396375 Tokens per Sec:     1396, Lr: 0.001000
2020-03-26 21:36:17,729 Epoch   1 Step:     1700 Batch Loss:    43.561794 Tokens per Sec:     1324, Lr: 0.001000
2020-03-26 21:36:27,447 Epoch   1 Step:     1800 Batch Loss:    45.458900 Tokens per Sec:     1435, Lr: 0.001000
2020-03-26 21:36:37,198 Epoch   1 Step:     1900 Batch Loss:    83.491676 Tokens per Sec:     1434, Lr: 0.001000
2020-03-26 21:36:44,036 Epoch   1 Step:     2000 Batch Loss:     2.670304 Tokens per Sec:     2096, Lr: 0.001000
2020-03-26 21:36:51,454 Hooray! New best validation result [eval_metric]!
2020-03-26 21:36:51,454 Saving new checkpoint.
2020-03-26 21:36:51,458 Example #0
2020-03-26 21:36:51,458 	Raw source:     ['1', '2', '3', '4', '5']
2020-03-26 21:36:51,459 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-03-26 21:36:51,459 	Source:     1 2 3 4 5
2020-03-26 21:36:51,459 	Reference:  5 4 3 2 1
2020-03-26 21:36:51,459 	Hypothesis: 5 4 3 2 1
2020-03-26 21:36:51,459 Example #3
2020-03-26 21:36:51,459 	Raw source:     ['22', '11', '39', '17', '45', '8', '9', '5', '49', '38', '46', '6', '0', '24', '11', '17', '0', '6', '36', '9', '49', '6', '35', '2', '25', '6', '27', '49', '10']
2020-03-26 21:36:51,459 	Raw hypothesis: ['10', '49', '27', '6', '25', '2', '35', '6', '49', '9', '36', '6', '0', '17', '11', '24', '0', '6', '46', '38', '46', '17', '17']
2020-03-26 21:36:51,459 	Source:     22 11 39 17 45 8 9 5 49 38 46 6 0 24 11 17 0 6 36 9 49 6 35 2 25 6 27 49 10
2020-03-26 21:36:51,459 	Reference:  10 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 49 5 9 8 45 17 39 11 22
2020-03-26 21:36:51,459 	Hypothesis: 10 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 46 17 17
2020-03-26 21:36:51,459 Example #6
2020-03-26 21:36:51,459 	Raw source:     ['37', '44', '14', '8', '3', '24', '4', '15', '27', '44', '41', '0', '44', '0', '28', '1', '46', '18', '10', '48', '9', '2', '22', '45', '6', '12', '37']
2020-03-26 21:36:51,459 	Raw hypothesis: ['37', '12', '6', '45', '22', '2', '9', '48', '10', '18', '46', '1', '28', '0', '44', '0', '41', '44', '15', '15', '44', '24', '44', '44', '44', '44', '44', '44', '44', '44']
2020-03-26 21:36:51,460 	Source:     37 44 14 8 3 24 4 15 27 44 41 0 44 0 28 1 46 18 10 48 9 2 22 45 6 12 37
2020-03-26 21:36:51,460 	Reference:  37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 27 15 4 24 3 8 14 44 37
2020-03-26 21:36:51,460 	Hypothesis: 37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 15 15 44 24 44 44 44 44 44 44 44 44
2020-03-26 21:36:51,460 Validation result (greedy) at epoch   1, step     2000: bleu:  83.86, loss: 9434.7002, ppl:   1.7822, duration: 7.4232s
2020-03-26 21:37:03,125 Epoch   1 Step:     2100 Batch Loss:     0.439257 Tokens per Sec:     1198, Lr: 0.001000
2020-03-26 21:37:11,448 Epoch   1 Step:     2200 Batch Loss:     1.682382 Tokens per Sec:     1668, Lr: 0.001000
2020-03-26 21:37:21,660 Epoch   1 Step:     2300 Batch Loss:     0.553258 Tokens per Sec:     1377, Lr: 0.001000
2020-03-26 21:37:33,966 Epoch   1 Step:     2400 Batch Loss:     1.183450 Tokens per Sec:     1162, Lr: 0.001000
2020-03-26 21:37:43,431 Epoch   1 Step:     2500 Batch Loss:     0.801884 Tokens per Sec:     1463, Lr: 0.001000
2020-03-26 21:37:51,314 Epoch   1 Step:     2600 Batch Loss:    25.855219 Tokens per Sec:     1767, Lr: 0.001000
2020-03-26 21:38:00,681 Epoch   1 Step:     2700 Batch Loss:     0.137768 Tokens per Sec:     1458, Lr: 0.001000
2020-03-26 21:38:06,981 Epoch   1 Step:     2800 Batch Loss:     0.046096 Tokens per Sec:     2222, Lr: 0.001000
2020-03-26 21:38:17,379 Epoch   1 Step:     2900 Batch Loss:    34.070194 Tokens per Sec:     1352, Lr: 0.001000
2020-03-26 21:38:25,359 Epoch   1 Step:     3000 Batch Loss:     7.963470 Tokens per Sec:     1766, Lr: 0.001000
2020-03-26 21:38:32,131 Hooray! New best validation result [eval_metric]!
2020-03-26 21:38:32,132 Saving new checkpoint.
2020-03-26 21:38:32,137 Example #0
2020-03-26 21:38:32,137 	Raw source:     ['1', '2', '3', '4', '5']
2020-03-26 21:38:32,137 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-03-26 21:38:32,137 	Source:     1 2 3 4 5
2020-03-26 21:38:32,137 	Reference:  5 4 3 2 1
2020-03-26 21:38:32,137 	Hypothesis: 5 4 3 2 1
2020-03-26 21:38:32,137 Example #3
2020-03-26 21:38:32,137 	Raw source:     ['22', '11', '39', '17', '45', '8', '9', '5', '49', '38', '46', '6', '0', '24', '11', '17', '0', '6', '36', '9', '49', '6', '35', '2', '25', '6', '27', '49', '10']
2020-03-26 21:38:32,137 	Raw hypothesis: ['10', '49', '27', '6', '25', '2', '35', '6', '49', '9', '36', '6', '0', '17', '11', '24', '0', '6', '46', '38', '49', '5', '19']
2020-03-26 21:38:32,137 	Source:     22 11 39 17 45 8 9 5 49 38 46 6 0 24 11 17 0 6 36 9 49 6 35 2 25 6 27 49 10
2020-03-26 21:38:32,137 	Reference:  10 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 49 5 9 8 45 17 39 11 22
2020-03-26 21:38:32,138 	Hypothesis: 10 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 49 5 19
2020-03-26 21:38:32,138 Example #6
2020-03-26 21:38:32,138 	Raw source:     ['37', '44', '14', '8', '3', '24', '4', '15', '27', '44', '41', '0', '44', '0', '28', '1', '46', '18', '10', '48', '9', '2', '22', '45', '6', '12', '37']
2020-03-26 21:38:32,138 	Raw hypothesis: ['37', '12', '6', '45', '22', '2', '9', '48', '10', '18', '46', '1', '28', '0', '44', '0', '41', '44', '27', '15', '4', '44', '44']
2020-03-26 21:38:32,138 	Source:     37 44 14 8 3 24 4 15 27 44 41 0 44 0 28 1 46 18 10 48 9 2 22 45 6 12 37
2020-03-26 21:38:32,138 	Reference:  37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 27 15 4 24 3 8 14 44 37
2020-03-26 21:38:32,138 	Hypothesis: 37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 27 15 4 44 44
2020-03-26 21:38:32,138 Validation result (greedy) at epoch   1, step     3000: bleu:  86.18, loss: 9608.0488, ppl:   1.8012, duration: 6.7784s
2020-03-26 21:38:43,527 Epoch   1 Step:     3100 Batch Loss:    14.735098 Tokens per Sec:     1216, Lr: 0.001000
2020-03-26 21:38:53,356 Epoch   1 Step:     3200 Batch Loss:     0.101874 Tokens per Sec:     1390, Lr: 0.001000
2020-03-26 21:38:59,473 Epoch   1 Step:     3300 Batch Loss:     0.184121 Tokens per Sec:     2253, Lr: 0.001000
2020-03-26 21:39:09,034 Epoch   1 Step:     3400 Batch Loss:     0.075036 Tokens per Sec:     1469, Lr: 0.001000
2020-03-26 21:39:20,796 Epoch   1 Step:     3500 Batch Loss:     6.458379 Tokens per Sec:     1214, Lr: 0.001000
2020-03-26 21:39:30,057 Epoch   1 Step:     3600 Batch Loss:     0.255683 Tokens per Sec:     1515, Lr: 0.001000
2020-03-26 21:39:41,957 Epoch   1 Step:     3700 Batch Loss:     0.179457 Tokens per Sec:     1194, Lr: 0.001000
2020-03-26 21:39:53,639 Epoch   1 Step:     3800 Batch Loss:     0.185124 Tokens per Sec:     1184, Lr: 0.001000
2020-03-26 21:40:02,810 Epoch   1 Step:     3900 Batch Loss:     0.008982 Tokens per Sec:     1532, Lr: 0.001000
2020-03-26 21:40:12,432 Epoch   1 Step:     4000 Batch Loss:     0.009063 Tokens per Sec:     1462, Lr: 0.001000
2020-03-26 21:40:20,196 Hooray! New best validation result [eval_metric]!
2020-03-26 21:40:20,196 Saving new checkpoint.
2020-03-26 21:40:20,202 Example #0
2020-03-26 21:40:20,202 	Raw source:     ['1', '2', '3', '4', '5']
2020-03-26 21:40:20,202 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-03-26 21:40:20,202 	Source:     1 2 3 4 5
2020-03-26 21:40:20,202 	Reference:  5 4 3 2 1
2020-03-26 21:40:20,202 	Hypothesis: 5 4 3 2 1
2020-03-26 21:40:20,202 Example #3
2020-03-26 21:40:20,202 	Raw source:     ['22', '11', '39', '17', '45', '8', '9', '5', '49', '38', '46', '6', '0', '24', '11', '17', '0', '6', '36', '9', '49', '6', '35', '2', '25', '6', '27', '49', '10']
2020-03-26 21:40:20,202 	Raw hypothesis: ['10', '49', '27', '6', '25', '2', '35', '6', '49', '9', '36', '6', '0', '17', '11', '24', '0', '6', '46', '38', '5', '9', '33', '39']
2020-03-26 21:40:20,202 	Source:     22 11 39 17 45 8 9 5 49 38 46 6 0 24 11 17 0 6 36 9 49 6 35 2 25 6 27 49 10
2020-03-26 21:40:20,203 	Reference:  10 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 49 5 9 8 45 17 39 11 22
2020-03-26 21:40:20,203 	Hypothesis: 10 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 5 9 33 39
2020-03-26 21:40:20,203 Example #6
2020-03-26 21:40:20,203 	Raw source:     ['37', '44', '14', '8', '3', '24', '4', '15', '27', '44', '41', '0', '44', '0', '28', '1', '46', '18', '10', '48', '9', '2', '22', '45', '6', '12', '37']
2020-03-26 21:40:20,203 	Raw hypothesis: ['37', '12', '6', '45', '22', '2', '9', '48', '10', '18', '46', '1', '28', '0', '44', '0', '41', '44', '27', '18', '44', '3', '8', '44', '44', '44', '44']
2020-03-26 21:40:20,203 	Source:     37 44 14 8 3 24 4 15 27 44 41 0 44 0 28 1 46 18 10 48 9 2 22 45 6 12 37
2020-03-26 21:40:20,203 	Reference:  37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 27 15 4 24 3 8 14 44 37
2020-03-26 21:40:20,203 	Hypothesis: 37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 27 18 44 3 8 44 44 44 44
2020-03-26 21:40:20,203 Validation result (greedy) at epoch   1, step     4000: bleu:  88.20, loss: 8390.8271, ppl:   1.6718, duration: 7.7687s
2020-03-26 21:40:31,930 Epoch   1 Step:     4100 Batch Loss:     0.110413 Tokens per Sec:     1191, Lr: 0.001000
2020-03-26 21:40:41,323 Epoch   1 Step:     4200 Batch Loss:    19.867702 Tokens per Sec:     1456, Lr: 0.001000
2020-03-26 21:40:54,382 Epoch   1 Step:     4300 Batch Loss:    22.127529 Tokens per Sec:     1080, Lr: 0.001000
2020-03-26 21:41:06,364 Epoch   1 Step:     4400 Batch Loss:     0.025284 Tokens per Sec:     1118, Lr: 0.001000
2020-03-26 21:41:17,735 Epoch   1 Step:     4500 Batch Loss:     0.658331 Tokens per Sec:     1227, Lr: 0.001000
2020-03-26 21:41:24,823 Epoch   1 Step:     4600 Batch Loss:    28.885294 Tokens per Sec:     1925, Lr: 0.001000
2020-03-26 21:41:34,509 Epoch   1 Step:     4700 Batch Loss:     1.531138 Tokens per Sec:     1439, Lr: 0.001000
2020-03-26 21:41:45,839 Epoch   1 Step:     4800 Batch Loss:     0.172835 Tokens per Sec:     1236, Lr: 0.001000
2020-03-26 21:41:54,353 Epoch   1 Step:     4900 Batch Loss:    13.531740 Tokens per Sec:     1678, Lr: 0.001000
2020-03-26 21:42:01,317 Epoch   1 Step:     5000 Batch Loss:     4.085911 Tokens per Sec:     2024, Lr: 0.001000
2020-03-26 21:42:09,444 Hooray! New best validation result [eval_metric]!
2020-03-26 21:42:09,445 Saving new checkpoint.
2020-03-26 21:42:09,450 Example #0
2020-03-26 21:42:09,450 	Raw source:     ['1', '2', '3', '4', '5']
2020-03-26 21:42:09,451 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-03-26 21:42:09,451 	Source:     1 2 3 4 5
2020-03-26 21:42:09,451 	Reference:  5 4 3 2 1
2020-03-26 21:42:09,451 	Hypothesis: 5 4 3 2 1
2020-03-26 21:42:09,451 Example #3
2020-03-26 21:42:09,451 	Raw source:     ['22', '11', '39', '17', '45', '8', '9', '5', '49', '38', '46', '6', '0', '24', '11', '17', '0', '6', '36', '9', '49', '6', '35', '2', '25', '6', '27', '49', '10']
2020-03-26 21:42:09,451 	Raw hypothesis: ['11', '49', '27', '6', '25', '2', '35', '6', '49', '9', '36', '6', '0', '17', '11', '24', '0', '6', '46', '38', '9', '9', '9', '9', '9', '9', '9', '9', '9', '9']
2020-03-26 21:42:09,451 	Source:     22 11 39 17 45 8 9 5 49 38 46 6 0 24 11 17 0 6 36 9 49 6 35 2 25 6 27 49 10
2020-03-26 21:42:09,451 	Reference:  10 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 49 5 9 8 45 17 39 11 22
2020-03-26 21:42:09,451 	Hypothesis: 11 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 9 9 9 9 9 9 9 9 9 9
2020-03-26 21:42:09,451 Example #6
2020-03-26 21:42:09,451 	Raw source:     ['37', '44', '14', '8', '3', '24', '4', '15', '27', '44', '41', '0', '44', '0', '28', '1', '46', '18', '10', '48', '9', '2', '22', '45', '6', '12', '37']
2020-03-26 21:42:09,451 	Raw hypothesis: ['37', '12', '6', '45', '22', '2', '9', '48', '10', '18', '46', '1', '28', '0', '44', '0', '41', '44', '27', '15', '4', '24', '3', '33', '33', '37']
2020-03-26 21:42:09,452 	Source:     37 44 14 8 3 24 4 15 27 44 41 0 44 0 28 1 46 18 10 48 9 2 22 45 6 12 37
2020-03-26 21:42:09,452 	Reference:  37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 27 15 4 24 3 8 14 44 37
2020-03-26 21:42:09,452 	Hypothesis: 37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 27 15 4 24 3 33 33 37
2020-03-26 21:42:09,452 Validation result (greedy) at epoch   1, step     5000: bleu:  89.38, loss: 7910.2910, ppl:   1.6233, duration: 8.1346s
2020-03-26 21:42:11,132 Epoch   1: total training loss 86408.34
2020-03-26 21:42:11,132 EPOCH 2
2020-03-26 21:42:21,572 Epoch   2 Step:     5100 Batch Loss:     3.692537 Tokens per Sec:     1329, Lr: 0.001000
2020-03-26 21:42:31,985 Epoch   2 Step:     5200 Batch Loss:     0.021796 Tokens per Sec:     1380, Lr: 0.001000
2020-03-26 21:42:42,699 Epoch   2 Step:     5300 Batch Loss:    51.358055 Tokens per Sec:     1294, Lr: 0.001000
2020-03-26 21:42:53,130 Epoch   2 Step:     5400 Batch Loss:    65.844322 Tokens per Sec:     1316, Lr: 0.001000
2020-03-26 21:43:04,330 Epoch   2 Step:     5500 Batch Loss:     0.069354 Tokens per Sec:     1241, Lr: 0.001000
2020-03-26 21:43:15,452 Epoch   2 Step:     5600 Batch Loss:     0.334828 Tokens per Sec:     1241, Lr: 0.001000
2020-03-26 21:43:26,387 Epoch   2 Step:     5700 Batch Loss:     0.268485 Tokens per Sec:     1246, Lr: 0.001000
2020-03-26 21:43:38,201 Epoch   2 Step:     5800 Batch Loss:    24.810703 Tokens per Sec:     1182, Lr: 0.001000
2020-03-26 21:43:51,048 Epoch   2 Step:     5900 Batch Loss:     0.017227 Tokens per Sec:     1069, Lr: 0.001000
2020-03-26 21:44:01,521 Epoch   2 Step:     6000 Batch Loss:     0.000519 Tokens per Sec:     1322, Lr: 0.001000
2020-03-26 21:44:10,142 Hooray! New best validation result [eval_metric]!
2020-03-26 21:44:10,143 Saving new checkpoint.
2020-03-26 21:44:10,148 Example #0
2020-03-26 21:44:10,148 	Raw source:     ['1', '2', '3', '4', '5']
2020-03-26 21:44:10,148 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-03-26 21:44:10,148 	Source:     1 2 3 4 5
2020-03-26 21:44:10,148 	Reference:  5 4 3 2 1
2020-03-26 21:44:10,148 	Hypothesis: 5 4 3 2 1
2020-03-26 21:44:10,148 Example #3
2020-03-26 21:44:10,148 	Raw source:     ['22', '11', '39', '17', '45', '8', '9', '5', '49', '38', '46', '6', '0', '24', '11', '17', '0', '6', '36', '9', '49', '6', '35', '2', '25', '6', '27', '49', '10']
2020-03-26 21:44:10,149 	Raw hypothesis: ['10', '49', '27', '6', '25', '2', '35', '6', '49', '9', '36', '6', '0', '17', '11', '24', '0', '6', '46', '38', '49', '9', '9', '9', '11']
2020-03-26 21:44:10,149 	Source:     22 11 39 17 45 8 9 5 49 38 46 6 0 24 11 17 0 6 36 9 49 6 35 2 25 6 27 49 10
2020-03-26 21:44:10,149 	Reference:  10 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 49 5 9 8 45 17 39 11 22
2020-03-26 21:44:10,149 	Hypothesis: 10 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 49 9 9 9 11
2020-03-26 21:44:10,149 Example #6
2020-03-26 21:44:10,149 	Raw source:     ['37', '44', '14', '8', '3', '24', '4', '15', '27', '44', '41', '0', '44', '0', '28', '1', '46', '18', '10', '48', '9', '2', '22', '45', '6', '12', '37']
2020-03-26 21:44:10,149 	Raw hypothesis: ['37', '12', '6', '45', '22', '2', '9', '48', '10', '18', '46', '1', '28', '0', '44', '0', '41', '44', '27', '15', '4', '24', '3', '44']
2020-03-26 21:44:10,149 	Source:     37 44 14 8 3 24 4 15 27 44 41 0 44 0 28 1 46 18 10 48 9 2 22 45 6 12 37
2020-03-26 21:44:10,149 	Reference:  37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 27 15 4 24 3 8 14 44 37
2020-03-26 21:44:10,149 	Hypothesis: 37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 27 15 4 24 3 44
2020-03-26 21:44:10,149 Validation result (greedy) at epoch   2, step     6000: bleu:  92.72, loss: 6997.3125, ppl:   1.5351, duration: 8.6279s
2020-03-26 21:44:23,305 Epoch   2 Step:     6100 Batch Loss:     0.007262 Tokens per Sec:     1054, Lr: 0.001000
2020-03-26 21:44:32,481 Epoch   2 Step:     6200 Batch Loss:     0.156787 Tokens per Sec:     1529, Lr: 0.001000
2020-03-26 21:44:40,510 Epoch   2 Step:     6300 Batch Loss:     0.072330 Tokens per Sec:     1735, Lr: 0.001000
2020-03-26 21:44:51,447 Epoch   2 Step:     6400 Batch Loss:     2.307767 Tokens per Sec:     1263, Lr: 0.001000
2020-03-26 21:45:02,310 Epoch   2 Step:     6500 Batch Loss:     0.002961 Tokens per Sec:     1293, Lr: 0.001000
2020-03-26 21:45:12,409 Epoch   2 Step:     6600 Batch Loss:     1.248611 Tokens per Sec:     1411, Lr: 0.001000
2020-03-26 21:45:22,649 Epoch   2 Step:     6700 Batch Loss:     0.008347 Tokens per Sec:     1373, Lr: 0.001000
2020-03-26 21:45:33,639 Epoch   2 Step:     6800 Batch Loss:     0.046381 Tokens per Sec:     1240, Lr: 0.001000
2020-03-26 21:45:42,260 Epoch   2 Step:     6900 Batch Loss:     0.003889 Tokens per Sec:     1639, Lr: 0.001000
2020-03-26 21:45:50,392 Epoch   2 Step:     7000 Batch Loss:     0.000830 Tokens per Sec:     1741, Lr: 0.001000
2020-03-26 21:45:58,845 Example #0
2020-03-26 21:45:58,845 	Raw source:     ['1', '2', '3', '4', '5']
2020-03-26 21:45:58,845 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-03-26 21:45:58,845 	Source:     1 2 3 4 5
2020-03-26 21:45:58,845 	Reference:  5 4 3 2 1
2020-03-26 21:45:58,845 	Hypothesis: 5 4 3 2 1
2020-03-26 21:45:58,845 Example #3
2020-03-26 21:45:58,846 	Raw source:     ['22', '11', '39', '17', '45', '8', '9', '5', '49', '38', '46', '6', '0', '24', '11', '17', '0', '6', '36', '9', '49', '6', '35', '2', '25', '6', '27', '49', '10']
2020-03-26 21:45:58,846 	Raw hypothesis: ['10', '49', '27', '6', '25', '2', '35', '6', '49', '9', '36', '6', '0', '17', '11', '24', '0', '6', '46', '38', '9', '8', '22']
2020-03-26 21:45:58,846 	Source:     22 11 39 17 45 8 9 5 49 38 46 6 0 24 11 17 0 6 36 9 49 6 35 2 25 6 27 49 10
2020-03-26 21:45:58,846 	Reference:  10 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 49 5 9 8 45 17 39 11 22
2020-03-26 21:45:58,846 	Hypothesis: 10 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 9 8 22
2020-03-26 21:45:58,846 Example #6
2020-03-26 21:45:58,846 	Raw source:     ['37', '44', '14', '8', '3', '24', '4', '15', '27', '44', '41', '0', '44', '0', '28', '1', '46', '18', '10', '48', '9', '2', '22', '45', '6', '12', '37']
2020-03-26 21:45:58,846 	Raw hypothesis: ['37', '12', '6', '45', '22', '2', '9', '48', '10', '18', '46', '1', '28', '0', '44', '0', '41', '34', '15', '4', '24', '3', '8', '44', '44', '37', '44']
2020-03-26 21:45:58,846 	Source:     37 44 14 8 3 24 4 15 27 44 41 0 44 0 28 1 46 18 10 48 9 2 22 45 6 12 37
2020-03-26 21:45:58,846 	Reference:  37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 27 15 4 24 3 8 14 44 37
2020-03-26 21:45:58,846 	Hypothesis: 37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 34 15 4 24 3 8 44 44 37 44
2020-03-26 21:45:58,847 Validation result (greedy) at epoch   2, step     7000: bleu:  89.85, loss: 13017.2129, ppl:   2.2195, duration: 8.4539s
2020-03-26 21:46:11,637 Epoch   2 Step:     7100 Batch Loss:     0.894334 Tokens per Sec:     1088, Lr: 0.001000
2020-03-26 21:46:21,027 Epoch   2 Step:     7200 Batch Loss:     0.006848 Tokens per Sec:     1501, Lr: 0.001000
2020-03-26 21:46:29,925 Epoch   2 Step:     7300 Batch Loss:     2.137098 Tokens per Sec:     1619, Lr: 0.001000
2020-03-26 21:46:40,041 Epoch   2 Step:     7400 Batch Loss:     0.329116 Tokens per Sec:     1346, Lr: 0.001000
2020-03-26 21:46:47,775 Epoch   2 Step:     7500 Batch Loss:    10.747583 Tokens per Sec:     1828, Lr: 0.001000
2020-03-26 21:46:54,843 Epoch   2 Step:     7600 Batch Loss:     0.133870 Tokens per Sec:     1992, Lr: 0.001000
2020-03-26 21:47:01,753 Epoch   2 Step:     7700 Batch Loss:   149.068878 Tokens per Sec:     2059, Lr: 0.001000
2020-03-26 21:47:11,908 Epoch   2 Step:     7800 Batch Loss:     0.029536 Tokens per Sec:     1381, Lr: 0.001000
2020-03-26 21:47:22,184 Epoch   2 Step:     7900 Batch Loss:     1.240754 Tokens per Sec:     1371, Lr: 0.001000
2020-03-26 21:47:29,808 Epoch   2 Step:     8000 Batch Loss:     0.005701 Tokens per Sec:     1829, Lr: 0.001000
2020-03-26 21:47:36,932 Hooray! New best validation result [eval_metric]!
2020-03-26 21:47:36,932 Saving new checkpoint.
2020-03-26 21:47:36,937 Example #0
2020-03-26 21:47:36,937 	Raw source:     ['1', '2', '3', '4', '5']
2020-03-26 21:47:36,937 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-03-26 21:47:36,938 	Source:     1 2 3 4 5
2020-03-26 21:47:36,938 	Reference:  5 4 3 2 1
2020-03-26 21:47:36,938 	Hypothesis: 5 4 3 2 1
2020-03-26 21:47:36,938 Example #3
2020-03-26 21:47:36,938 	Raw source:     ['22', '11', '39', '17', '45', '8', '9', '5', '49', '38', '46', '6', '0', '24', '11', '17', '0', '6', '36', '9', '49', '6', '35', '2', '25', '6', '27', '49', '10']
2020-03-26 21:47:36,938 	Raw hypothesis: ['11', '49', '27', '6', '25', '2', '35', '6', '49', '9', '36', '6', '0', '17', '11', '24', '0', '6', '46', '38', '46', '29', '9', '40', '39', '11', '22', '22']
2020-03-26 21:47:36,938 	Source:     22 11 39 17 45 8 9 5 49 38 46 6 0 24 11 17 0 6 36 9 49 6 35 2 25 6 27 49 10
2020-03-26 21:47:36,938 	Reference:  10 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 49 5 9 8 45 17 39 11 22
2020-03-26 21:47:36,938 	Hypothesis: 11 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 46 29 9 40 39 11 22 22
2020-03-26 21:47:36,938 Example #6
2020-03-26 21:47:36,938 	Raw source:     ['37', '44', '14', '8', '3', '24', '4', '15', '27', '44', '41', '0', '44', '0', '28', '1', '46', '18', '10', '48', '9', '2', '22', '45', '6', '12', '37']
2020-03-26 21:47:36,938 	Raw hypothesis: ['37', '12', '6', '45', '22', '2', '9', '48', '10', '18', '46', '1', '28', '0', '44', '0', '41', '44', '27', '15', '4', '24', '14', '8', '34', '37']
2020-03-26 21:47:36,938 	Source:     37 44 14 8 3 24 4 15 27 44 41 0 44 0 28 1 46 18 10 48 9 2 22 45 6 12 37
2020-03-26 21:47:36,938 	Reference:  37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 27 15 4 24 3 8 14 44 37
2020-03-26 21:47:36,939 	Hypothesis: 37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 27 15 4 24 14 8 34 37
2020-03-26 21:47:36,939 Validation result (greedy) at epoch   2, step     8000: bleu:  93.09, loss: 7248.4429, ppl:   1.5589, duration: 7.1299s
2020-03-26 21:47:44,826 Epoch   2 Step:     8100 Batch Loss:    13.263878 Tokens per Sec:     1769, Lr: 0.001000
2020-03-26 21:47:54,003 Epoch   2 Step:     8200 Batch Loss:     0.009186 Tokens per Sec:     1502, Lr: 0.001000
2020-03-26 21:48:01,841 Epoch   2 Step:     8300 Batch Loss:    34.140434 Tokens per Sec:     1805, Lr: 0.001000
2020-03-26 21:48:10,497 Epoch   2 Step:     8400 Batch Loss:     2.145791 Tokens per Sec:     1594, Lr: 0.001000
2020-03-26 21:48:20,530 Epoch   2 Step:     8500 Batch Loss:     0.029004 Tokens per Sec:     1415, Lr: 0.001000
2020-03-26 21:48:31,418 Epoch   2 Step:     8600 Batch Loss:     0.006226 Tokens per Sec:     1278, Lr: 0.001000
2020-03-26 21:48:41,005 Epoch   2 Step:     8700 Batch Loss:     7.666923 Tokens per Sec:     1468, Lr: 0.001000
2020-03-26 21:48:51,996 Epoch   2 Step:     8800 Batch Loss:     0.000240 Tokens per Sec:     1271, Lr: 0.001000
2020-03-26 21:48:59,911 Epoch   2 Step:     8900 Batch Loss:    25.515923 Tokens per Sec:     1765, Lr: 0.001000
2020-03-26 21:49:10,157 Epoch   2 Step:     9000 Batch Loss:     0.132391 Tokens per Sec:     1361, Lr: 0.001000
2020-03-26 21:49:17,665 Example #0
2020-03-26 21:49:17,666 	Raw source:     ['1', '2', '3', '4', '5']
2020-03-26 21:49:17,666 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-03-26 21:49:17,666 	Source:     1 2 3 4 5
2020-03-26 21:49:17,666 	Reference:  5 4 3 2 1
2020-03-26 21:49:17,666 	Hypothesis: 5 4 3 2 1
2020-03-26 21:49:17,666 Example #3
2020-03-26 21:49:17,666 	Raw source:     ['22', '11', '39', '17', '45', '8', '9', '5', '49', '38', '46', '6', '0', '24', '11', '17', '0', '6', '36', '9', '49', '6', '35', '2', '25', '6', '27', '49', '10']
2020-03-26 21:49:17,666 	Raw hypothesis: ['10', '49', '27', '6', '25', '2', '35', '6', '49', '9', '36', '6', '0', '17', '11', '24', '0', '6', '46', '38', '9', '8', '39', '22', '22', '22']
2020-03-26 21:49:17,666 	Source:     22 11 39 17 45 8 9 5 49 38 46 6 0 24 11 17 0 6 36 9 49 6 35 2 25 6 27 49 10
2020-03-26 21:49:17,666 	Reference:  10 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 49 5 9 8 45 17 39 11 22
2020-03-26 21:49:17,667 	Hypothesis: 10 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 9 8 39 22 22 22
2020-03-26 21:49:17,667 Example #6
2020-03-26 21:49:17,667 	Raw source:     ['37', '44', '14', '8', '3', '24', '4', '15', '27', '44', '41', '0', '44', '0', '28', '1', '46', '18', '10', '48', '9', '2', '22', '45', '6', '12', '37']
2020-03-26 21:49:17,667 	Raw hypothesis: ['37', '12', '6', '45', '22', '2', '9', '48', '10', '18', '46', '1', '28', '0', '44', '0', '41', '44', '27', '15', '3', '8', '14', '44', '37']
2020-03-26 21:49:17,667 	Source:     37 44 14 8 3 24 4 15 27 44 41 0 44 0 28 1 46 18 10 48 9 2 22 45 6 12 37
2020-03-26 21:49:17,667 	Reference:  37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 27 15 4 24 3 8 14 44 37
2020-03-26 21:49:17,667 	Hypothesis: 37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 27 15 3 8 14 44 37
2020-03-26 21:49:17,667 Validation result (greedy) at epoch   2, step     9000: bleu:  90.19, loss: 15339.2461, ppl:   2.5587, duration: 7.5073s
2020-03-26 21:49:31,256 Epoch   2 Step:     9100 Batch Loss:     0.024635 Tokens per Sec:     1028, Lr: 0.001000
2020-03-26 21:49:44,560 Epoch   2 Step:     9200 Batch Loss:     0.000520 Tokens per Sec:     1072, Lr: 0.001000
2020-03-26 21:49:55,871 Epoch   2 Step:     9300 Batch Loss:     0.040919 Tokens per Sec:     1193, Lr: 0.001000
2020-03-26 21:50:07,409 Epoch   2 Step:     9400 Batch Loss:     0.032499 Tokens per Sec:     1224, Lr: 0.001000
2020-03-26 21:50:16,907 Epoch   2 Step:     9500 Batch Loss:     0.060891 Tokens per Sec:     1461, Lr: 0.001000
2020-03-26 21:50:26,466 Epoch   2 Step:     9600 Batch Loss:     0.022947 Tokens per Sec:     1453, Lr: 0.001000
2020-03-26 21:50:35,880 Epoch   2 Step:     9700 Batch Loss:     0.258238 Tokens per Sec:     1497, Lr: 0.001000
2020-03-26 21:50:44,281 Epoch   2 Step:     9800 Batch Loss:     0.130554 Tokens per Sec:     1648, Lr: 0.001000
2020-03-26 21:50:53,088 Epoch   2 Step:     9900 Batch Loss:     0.002882 Tokens per Sec:     1581, Lr: 0.001000
2020-03-26 21:51:02,655 Epoch   2 Step:    10000 Batch Loss:     1.321933 Tokens per Sec:     1453, Lr: 0.001000
2020-03-26 21:51:11,702 Hooray! New best validation result [eval_metric]!
2020-03-26 21:51:11,703 Saving new checkpoint.
2020-03-26 21:51:11,708 Example #0
2020-03-26 21:51:11,709 	Raw source:     ['1', '2', '3', '4', '5']
2020-03-26 21:51:11,709 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-03-26 21:51:11,709 	Source:     1 2 3 4 5
2020-03-26 21:51:11,709 	Reference:  5 4 3 2 1
2020-03-26 21:51:11,709 	Hypothesis: 5 4 3 2 1
2020-03-26 21:51:11,709 Example #3
2020-03-26 21:51:11,709 	Raw source:     ['22', '11', '39', '17', '45', '8', '9', '5', '49', '38', '46', '6', '0', '24', '11', '17', '0', '6', '36', '9', '49', '6', '35', '2', '25', '6', '27', '49', '10']
2020-03-26 21:51:11,709 	Raw hypothesis: ['10', '49', '27', '6', '25', '2', '35', '6', '49', '9', '36', '6', '0', '17', '11', '24', '0', '6', '46', '38', '49', '5', '9', '8', '45', '11', '22', '22', '22', '22']
2020-03-26 21:51:11,709 	Source:     22 11 39 17 45 8 9 5 49 38 46 6 0 24 11 17 0 6 36 9 49 6 35 2 25 6 27 49 10
2020-03-26 21:51:11,709 	Reference:  10 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 49 5 9 8 45 17 39 11 22
2020-03-26 21:51:11,709 	Hypothesis: 10 49 27 6 25 2 35 6 49 9 36 6 0 17 11 24 0 6 46 38 49 5 9 8 45 11 22 22 22 22
2020-03-26 21:51:11,710 Example #6
2020-03-26 21:51:11,710 	Raw source:     ['37', '44', '14', '8', '3', '24', '4', '15', '27', '44', '41', '0', '44', '0', '28', '1', '46', '18', '10', '48', '9', '2', '22', '45', '6', '12', '37']
2020-03-26 21:51:11,710 	Raw hypothesis: ['37', '12', '6', '45', '22', '2', '9', '48', '10', '18', '46', '1', '28', '0', '44', '0', '41', '44', '27', '15', '4', '24', '3', '8', '14', '37']
2020-03-26 21:51:11,710 	Source:     37 44 14 8 3 24 4 15 27 44 41 0 44 0 28 1 46 18 10 48 9 2 22 45 6 12 37
2020-03-26 21:51:11,710 	Reference:  37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 27 15 4 24 3 8 14 44 37
2020-03-26 21:51:11,710 	Hypothesis: 37 12 6 45 22 2 9 48 10 18 46 1 28 0 44 0 41 44 27 15 4 24 3 8 14 37
2020-03-26 21:51:11,710 Validation result (greedy) at epoch   2, step    10000: bleu:  95.11, loss: 6626.7598, ppl:   1.5006, duration: 9.0541s
2020-03-26 21:51:13,527 Epoch   2: total training loss 26214.86
2020-03-26 21:51:13,527 Training ended after   2 epochs.
2020-03-26 21:51:13,527 Best validation result (greedy) at step    10000:  95.11 eval_metric.
2020-03-26 21:51:19,799  dev bleu:  95.11 [Greedy decoding]
2020-03-26 21:51:19,800 Translations saved to: reverse_model/00010000.hyps.dev
2020-03-26 21:51:24,963 test bleu:  95.31 [Greedy decoding]
2020-03-26 21:51:24,964 Translations saved to: reverse_model/00010000.hyps.test
