Sample size:  256
State size:  24
Action size:  9
bleu_seq
You select the reward based on the sequence accuaracy bleu_seq
EPOCH %d 1
 beam_dqn, egreed, gamma:  1 0.9 0.6

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 7 3]]
Reward:  [1.  0.8] 

tensor([[2, 7]]) [2 7]
0 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 

tensor([[2, 8]]) [2 8]
2 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 5 3]
Eval  :  [[2 5 5 3]]
Reward:  [-1.    0.45  0.6 ] 

tensor([[2, 4, 5]]) [2 4 5]
4 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
5 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
6 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 3]
Eval  :  [[2 4 3]]
Reward:  [1.  0.8] 

tensor([[2, 4]]) [2 4]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 6 3]
Eval  :  [[2 6 3]]
Reward:  [1.  0.8] 

tensor([[2, 6]]) [2 6]
EPOCH %d 2
 beam_dqn, egreed, gamma:  1 0.9 0.6
2183 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2184 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2185 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2186 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2187 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2188 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2189 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 3
 beam_dqn, egreed, gamma:  1 0.9 0.6
4366 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4367 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4368 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4369 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4370 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4371 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4372 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
As referece this first test on dev data. Is maded with the Q networks, initialized randomly : 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9496,  0.6436, -0.7072])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7136, -0.9019])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7502, -0.9271])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9659,  0.7588, -0.9313])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9656,  0.7622, -0.9324])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9653,  0.7638, -0.9328])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7647, -0.9330])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.7346,  0.9592,  0.2728])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9724,  0.9706, -0.6998])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9714, -0.8867])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9876,  0.9712, -0.9122])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9876,  0.9710, -0.9182])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9202])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9210])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]
roptimal:  tensor([[2, 4, 5]]) [[2 4 5 3]]
[1.  0.9 0.6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]
roptimal:  tensor([[2, 7, 6]]) [[2 7 6 3]]
[1.  0.9 0.6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]
roptimal:  tensor([[2, 6]]) [[2 6 3]]
[1.  0.8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]
roptimal:  tensor([[2, 4, 6]]) [[2 4 6 3]]
[1.  0.9 0.6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]
roptimal:  tensor([[2, 7, 5]]) [[2 7 5 3]]
[1.  0.9 0.6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 6, 7]]) [[2 6 7 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 7, 6]]) [[2 7 6 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 6]]) [[2 6 3]]
[1.  0.8]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 8, 8]]) [[2 8 8 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 5, 4]]) [[2 5 4 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 4, 8]]) [[2 4 8 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 7, 8]]) [[2 7 8 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 6, 5]]) [[2 6 5 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 7, 6]]) [[2 7 6 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 4, 7]]) [[2 4 7 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 6]]) [[2 6 3]]
[1.  0.8]
roptimal:  tensor([[2, 8, 6]]) [[2 8 6 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 6, 6]]) [[2 6 6 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 4, 6]]) [[2 4 6 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 6, 8]]) [[2 6 8 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 4, 6]]) [[2 4 6 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 5, 6]]) [[2 5 6 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 6]]) [[2 6 3]]
[1.  0.8]
roptimal:  tensor([[2, 6, 4]]) [[2 6 4 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 6]]) [[2 6 3]]
[1.  0.8]
roptimal:  tensor([[2, 6, 6]]) [[2 6 6 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 5, 7]]) [[2 5 7 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 6, 8]]) [[2 6 8 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 4, 6]]) [[2 4 6 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 4, 7]]) [[2 4 7 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 4, 7]]) [[2 4 7 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 5, 8]]) [[2 5 8 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 5, 5]]) [[2 5 5 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 5, 6]]) [[2 5 6 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 4, 4]]) [[2 4 4 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 6, 7]]) [[2 6 7 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 4, 8]]) [[2 4 8 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 5, 8]]) [[2 5 8 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 8, 6]]) [[2 8 6 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 6]]) [[2 6 3]]
[1.  0.8]
roptimal:  tensor([[2, 5, 6]]) [[2 5 6 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 6]]) [[2 6 3]]
[1.  0.8]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 6, 5]]) [[2 6 5 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 4, 6]]) [[2 4 6 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 8, 8]]) [[2 8 8 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 6, 6]]) [[2 6 6 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 7, 4]]) [[2 7 4 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 5, 7]]) [[2 5 7 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 4, 4]]) [[2 4 4 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 4, 8]]) [[2 4 8 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 6, 6]]) [[2 6 6 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 4, 7]]) [[2 4 7 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 5, 4]]) [[2 5 4 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 4, 7]]) [[2 4 7 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 7, 7]]) [[2 7 7 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 5, 8]]) [[2 5 8 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 8, 6]]) [[2 8 6 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 7, 5]]) [[2 7 5 3]]
[1.  0.9 0.6]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 6]]) [[2 6 3]]
[1.  0.8]
roptimal:  tensor([[2, 7, 6]]) [[2 7 6 3]]
[1.  0.9 0.6]
The optimal reward is:  221.8000000000002
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1']
1  r_total and score:  29.599999999999994 0.0
Current Bleu score is:  0.0
learn step counter:  1
dev_network_count:  1
Using pretraining...
learn step counter:  51
dev_network_count:  1
learn step counter:  101
dev_network_count:  1
learn step counter:  151
dev_network_count:  1
learn step counter:  201
dev_network_count:  1
learn step counter:  251
dev_network_count:  1

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([6])]  the state[:3] is:  tensor([-0.9415,  0.6271, -0.6975])
So far:  [array([2]), array([6]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7119, -0.8979])
So far:  [array([2]), array([6]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7421, -0.9254])
So far:  [array([2]), array([6]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9662,  0.7499, -0.9300])
So far:  [array([2]), array([6]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7530, -0.9312])
So far:  [array([2]), array([6]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7546, -0.9316])
So far:  [array([2]), array([6]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7555, -0.9317])
So far:  [array([2]), array([6]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7561, -0.9318])
So far:  [array([2]), array([6]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7564, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 4 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.6742,  0.9589,  0.3205])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9631,  0.9743, -0.6517])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9858,  0.9713, -0.8813])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9874,  0.9705, -0.9107])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9700, -0.9172])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9191])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9199])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 6 4 4 4 4 4 4 4 4]]
Reward:  [-1.          0.45       -1.25       -0.925      -0.8625     -0.93125
 -1.065625   -1.2328125  -1.41640625 -1.8       ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 6 4 4 4 4 4 4 4 4]]
Reward:  [-1.          0.45       -1.25       -0.925      -0.8625     -0.93125
 -1.065625   -1.2328125  -1.41640625 -1.8       ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 4 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['4 1 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '4 4 1 1 1 1 1 1 1 1', '3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '4 1 1 1 1 1 1 1 1 1', '4 4 1 1 1 1 1 1 1 1', '3 3 3 3 3 3 3 3 3 3', '4 1 3 3 3 3 3 3 3 3']
2  r_total and score:  26.64999999999999 0.0
Current Bleu score is:  0.0
learn step counter:  301
dev_network_count:  2
learn step counter:  351
dev_network_count:  2
learn step counter:  401
dev_network_count:  2
learn step counter:  451
dev_network_count:  2
Starting using Q target net....
learn step counter:  501
dev_network_count:  2
learn step counter:  551
dev_network_count:  2

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.6742,  0.9589,  0.3205])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9631,  0.9743, -0.6517])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9858,  0.9713, -0.8813])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9874,  0.9705, -0.9107])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9700, -0.9172])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9191])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9199])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 6 7 7 7 7 7 7 7 7]]
Reward:  [-1.          0.45       -1.25       -0.925      -0.8625     -0.93125
 -1.065625   -1.2328125  -1.41640625 -1.8       ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 6 7 7 7 7 7 7 7 7]]
Reward:  [-1.          0.45       -1.25       -0.925      -0.8625     -0.93125
 -1.065625   -1.2328125  -1.41640625 -1.8       ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '4 4 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '4 4 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
3  r_total and score:  52.3 0.0
Current Bleu score is:  0.0
learn step counter:  601
dev_network_count:  3
learn step counter:  651
dev_network_count:  3
learn step counter:  701
dev_network_count:  3
EPOCH %d 4
 beam_dqn, egreed, gamma:  1 0.001 0.8991
1549 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1550 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1551 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1552 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1553 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1554 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1555 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  751
dev_network_count:  3
learn step counter:  801
dev_network_count:  3
learn step counter:  851
dev_network_count:  3

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([8])]  the state[:3] is:  tensor([-0.9372,  0.8198, -0.6427])
So far:  [array([2]), array([8]), array([7])]  the state[:3] is:  tensor([-0.9777,  0.8444, -0.9202])
So far:  [array([2]), array([8]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9772,  0.8677, -0.9503])
So far:  [array([2]), array([8]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9762,  0.8716, -0.9553])
So far:  [array([2]), array([8]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8735, -0.9565])
So far:  [array([2]), array([8]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8746, -0.9569])
So far:  [array([2]), array([8]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8752, -0.9570])
So far:  [array([2]), array([8]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([8]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8757, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 8 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.7346,  0.9592,  0.2728])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9696,  0.9716, -0.6869])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9707, -0.8847])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9874,  0.9702, -0.9113])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9699, -0.9174])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9192])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9203])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 6 7 7 7 7 7 7 7 7]]
Reward:  [-1.          0.45       -1.25       -0.925      -0.8625     -0.93125
 -1.065625   -1.2328125  -1.41640625 -1.8       ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 8 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '2 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '4 4 3 3 3 3 3 3 3 3', '2 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 1 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
4  r_total and score:  88.50000000000003 0.0
Current Bleu score is:  0.0
learn step counter:  901
dev_network_count:  4
learn step counter:  951
dev_network_count:  4
learn step counter:  1001
dev_network_count:  4
learn step counter:  1051
dev_network_count:  4
learn step counter:  1101
dev_network_count:  4
learn step counter:  1151
dev_network_count:  4

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.7346,  0.9592,  0.2728])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9696,  0.9716, -0.6869])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9707, -0.8847])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9874,  0.9702, -0.9113])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9699, -0.9174])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9192])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9203])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 4 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '4 1 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 1 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
5  r_total and score:  70.1 0.0
Current Bleu score is:  0.0
learn step counter:  1201
dev_network_count:  5
learn step counter:  1251
dev_network_count:  5
learn step counter:  1301
dev_network_count:  5
learn step counter:  1351
dev_network_count:  5
learn step counter:  1401
dev_network_count:  5
learn step counter:  1451
dev_network_count:  5

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 4 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 1 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
6  r_total and score:  52.85 0.0
Current Bleu score is:  0.0
learn step counter:  1501
dev_network_count:  6
learn step counter:  1551
dev_network_count:  6
learn step counter:  1601
dev_network_count:  6
learn step counter:  1651
dev_network_count:  6
learn step counter:  1701
dev_network_count:  6
EPOCH %d 5
 beam_dqn, egreed, gamma:  1 0.001 0.8982009000000001
3732 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3733 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3734 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3735 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3736 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3737 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3738 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  1751
dev_network_count:  6

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 4 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 1 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
7  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  1801
dev_network_count:  7
learn step counter:  1851
dev_network_count:  7
learn step counter:  1901
dev_network_count:  7
learn step counter:  1951
dev_network_count:  7
learn step counter:  2001
dev_network_count:  7
learn step counter:  2051
dev_network_count:  7

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
8  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  2101
dev_network_count:  8
learn step counter:  2151
dev_network_count:  8
learn step counter:  2201
dev_network_count:  8
learn step counter:  2251
dev_network_count:  8
learn step counter:  2301
dev_network_count:  8
learn step counter:  2351
dev_network_count:  8

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
9  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  2401
dev_network_count:  9
learn step counter:  2451
dev_network_count:  9
learn step counter:  2501
dev_network_count:  9
learn step counter:  2551
dev_network_count:  9
learn step counter:  2601
dev_network_count:  9
learn step counter:  2651
dev_network_count:  9

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
10  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  2701
dev_network_count:  10
EPOCH %d 6
 beam_dqn, egreed, gamma:  1 0.001 0.8973026991
915 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
916 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
917 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
918 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
919 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
920 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
921 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  2751
dev_network_count:  10
learn step counter:  2801
dev_network_count:  10
learn step counter:  2851
dev_network_count:  10
learn step counter:  2901
dev_network_count:  10
learn step counter:  2951
dev_network_count:  10

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
11  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  3001
dev_network_count:  11
learn step counter:  3051
dev_network_count:  11
learn step counter:  3101
dev_network_count:  11
learn step counter:  3151
dev_network_count:  11
learn step counter:  3201
dev_network_count:  11
learn step counter:  3251
dev_network_count:  11

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
12  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  3301
dev_network_count:  12
learn step counter:  3351
dev_network_count:  12
learn step counter:  3401
dev_network_count:  12
learn step counter:  3451
dev_network_count:  12
learn step counter:  3501
dev_network_count:  12
learn step counter:  3551
dev_network_count:  12

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
13  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  3601
dev_network_count:  13
learn step counter:  3651
dev_network_count:  13
learn step counter:  3701
dev_network_count:  13
EPOCH %d 7
 beam_dqn, egreed, gamma:  1 0.001 0.8964053964009
3098 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3099 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3100 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3101 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3102 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3103 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3104 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  3751
dev_network_count:  13
learn step counter:  3801
dev_network_count:  13
learn step counter:  3851
dev_network_count:  13

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
14  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  3901
dev_network_count:  14
learn step counter:  3951
dev_network_count:  14
learn step counter:  4001
dev_network_count:  14
learn step counter:  4051
dev_network_count:  14
learn step counter:  4101
dev_network_count:  14
learn step counter:  4151
dev_network_count:  14

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
15  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  4201
dev_network_count:  15
learn step counter:  4251
dev_network_count:  15
learn step counter:  4301
dev_network_count:  15
learn step counter:  4351
dev_network_count:  15
learn step counter:  4401
dev_network_count:  15
learn step counter:  4451
dev_network_count:  15

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
16  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  4501
dev_network_count:  16
learn step counter:  4551
dev_network_count:  16
learn step counter:  4601
dev_network_count:  16
learn step counter:  4651
dev_network_count:  16
learn step counter:  4701
dev_network_count:  16
EPOCH %d 8
 beam_dqn, egreed, gamma:  1 0.001 0.8955089910044991
281 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
282 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
283 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
284 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
285 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
286 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
287 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  4751
dev_network_count:  16

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
17  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  4801
dev_network_count:  17
learn step counter:  4851
dev_network_count:  17
learn step counter:  4901
dev_network_count:  17
learn step counter:  4951
dev_network_count:  17
learn step counter:  5001
dev_network_count:  17
learn step counter:  5051
dev_network_count:  17

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
18  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  5101
dev_network_count:  18
learn step counter:  5151
dev_network_count:  18
learn step counter:  5201
dev_network_count:  18
learn step counter:  5251
dev_network_count:  18
learn step counter:  5301
dev_network_count:  18
learn step counter:  5351
dev_network_count:  18

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
19  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  5401
dev_network_count:  19
learn step counter:  5451
dev_network_count:  19
learn step counter:  5501
dev_network_count:  19
learn step counter:  5551
dev_network_count:  19
learn step counter:  5601
dev_network_count:  19
learn step counter:  5651
dev_network_count:  19

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
20  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  5701
dev_network_count:  20
EPOCH %d 9
 beam_dqn, egreed, gamma:  1 0.001 0.8946134820134947
2464 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2465 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2466 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2467 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2468 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2469 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2470 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  5751
dev_network_count:  20
learn step counter:  5801
dev_network_count:  20
learn step counter:  5851
dev_network_count:  20
learn step counter:  5901
dev_network_count:  20
learn step counter:  5951
dev_network_count:  20

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
21  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  6001
dev_network_count:  21
learn step counter:  6051
dev_network_count:  21
learn step counter:  6101
dev_network_count:  21
learn step counter:  6151
dev_network_count:  21
learn step counter:  6201
dev_network_count:  21
learn step counter:  6251
dev_network_count:  21

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
22  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  6301
dev_network_count:  22
learn step counter:  6351
dev_network_count:  22
learn step counter:  6401
dev_network_count:  22
learn step counter:  6451
dev_network_count:  22
learn step counter:  6501
dev_network_count:  22
learn step counter:  6551
dev_network_count:  22

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
23  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  6601
dev_network_count:  23
learn step counter:  6651
dev_network_count:  23
learn step counter:  6701
dev_network_count:  23
EPOCH %d 10
 beam_dqn, egreed, gamma:  1 0.001 0.8937188685314812
4647 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4648 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4649 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4650 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4651 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4652 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4653 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  6751
dev_network_count:  23
learn step counter:  6801
dev_network_count:  23
learn step counter:  6851
dev_network_count:  23

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
24  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  6901
dev_network_count:  24
learn step counter:  6951
dev_network_count:  24
learn step counter:  7001
dev_network_count:  24
learn step counter:  7051
dev_network_count:  24
learn step counter:  7101
dev_network_count:  24
learn step counter:  7151
dev_network_count:  24

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
25  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  7201
dev_network_count:  25
learn step counter:  7251
dev_network_count:  25
learn step counter:  7301
dev_network_count:  25
learn step counter:  7351
dev_network_count:  25
learn step counter:  7401
dev_network_count:  25
learn step counter:  7451
dev_network_count:  25

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
26  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  7501
dev_network_count:  26
learn step counter:  7551
dev_network_count:  26
learn step counter:  7601
dev_network_count:  26
learn step counter:  7651
dev_network_count:  26
learn step counter:  7701
dev_network_count:  26
EPOCH %d 11
 beam_dqn, egreed, gamma:  1 0.001 0.8928251496629496
1830 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1831 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1832 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1833 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1834 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1835 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1836 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  7751
dev_network_count:  26

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
27  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  7801
dev_network_count:  27
learn step counter:  7851
dev_network_count:  27
learn step counter:  7901
dev_network_count:  27
learn step counter:  7951
dev_network_count:  27
learn step counter:  8001
dev_network_count:  27
learn step counter:  8051
dev_network_count:  27

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
28  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  8101
dev_network_count:  28
learn step counter:  8151
dev_network_count:  28
learn step counter:  8201
dev_network_count:  28
learn step counter:  8251
dev_network_count:  28
learn step counter:  8301
dev_network_count:  28
learn step counter:  8351
dev_network_count:  28

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
29  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  8401
dev_network_count:  29
learn step counter:  8451
dev_network_count:  29
learn step counter:  8501
dev_network_count:  29
learn step counter:  8551
dev_network_count:  29
learn step counter:  8601
dev_network_count:  29
learn step counter:  8651
dev_network_count:  29

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
30  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  8701
dev_network_count:  30
EPOCH %d 12
 beam_dqn, egreed, gamma:  1 0.001 0.8919323245132866
4013 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4014 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4015 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4016 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4017 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4018 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4019 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  8751
dev_network_count:  30
learn step counter:  8801
dev_network_count:  30
learn step counter:  8851
dev_network_count:  30
learn step counter:  8901
dev_network_count:  30
learn step counter:  8951
dev_network_count:  30

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
31  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  9001
dev_network_count:  31
learn step counter:  9051
dev_network_count:  31
learn step counter:  9101
dev_network_count:  31
learn step counter:  9151
dev_network_count:  31
learn step counter:  9201
dev_network_count:  31
learn step counter:  9251
dev_network_count:  31

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
32  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  9301
dev_network_count:  32
learn step counter:  9351
dev_network_count:  32
learn step counter:  9401
dev_network_count:  32
learn step counter:  9451
dev_network_count:  32
learn step counter:  9501
dev_network_count:  32
learn step counter:  9551
dev_network_count:  32

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
33  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  9601
dev_network_count:  33
learn step counter:  9651
dev_network_count:  33
learn step counter:  9701
dev_network_count:  33
EPOCH %d 13
 beam_dqn, egreed, gamma:  1 0.001 0.8910403921887734
1196 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1197 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1198 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1199 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1200 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1201 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1202 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  9751
dev_network_count:  33
learn step counter:  9801
dev_network_count:  33
learn step counter:  9851
dev_network_count:  33

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
34  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  9901
dev_network_count:  34
learn step counter:  9951
dev_network_count:  34
learn step counter:  10001
dev_network_count:  34
learn step counter:  10051
dev_network_count:  34
learn step counter:  10101
dev_network_count:  34
learn step counter:  10151
dev_network_count:  34

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
35  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  10201
dev_network_count:  35
learn step counter:  10251
dev_network_count:  35
learn step counter:  10301
dev_network_count:  35
learn step counter:  10351
dev_network_count:  35
learn step counter:  10401
dev_network_count:  35
learn step counter:  10451
dev_network_count:  35

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
36  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  10501
dev_network_count:  36
learn step counter:  10551
dev_network_count:  36
learn step counter:  10601
dev_network_count:  36
learn step counter:  10651
dev_network_count:  36
learn step counter:  10701
dev_network_count:  36
EPOCH %d 14
 beam_dqn, egreed, gamma:  1 0.001 0.8901493517965846
3379 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3380 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3381 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3382 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3383 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3384 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3385 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  10751
dev_network_count:  36

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
37  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  10801
dev_network_count:  37
learn step counter:  10851
dev_network_count:  37
learn step counter:  10901
dev_network_count:  37
learn step counter:  10951
dev_network_count:  37
learn step counter:  11001
dev_network_count:  37
learn step counter:  11051
dev_network_count:  37

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
38  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  11101
dev_network_count:  38
learn step counter:  11151
dev_network_count:  38
learn step counter:  11201
dev_network_count:  38
learn step counter:  11251
dev_network_count:  38
learn step counter:  11301
dev_network_count:  38
learn step counter:  11351
dev_network_count:  38

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
39  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  11401
dev_network_count:  39
learn step counter:  11451
dev_network_count:  39
learn step counter:  11501
dev_network_count:  39
learn step counter:  11551
dev_network_count:  39
learn step counter:  11601
dev_network_count:  39
learn step counter:  11651
dev_network_count:  39

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
40  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  11701
dev_network_count:  40
EPOCH %d 15
 beam_dqn, egreed, gamma:  1 0.001 0.8892592024447881
562 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
563 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
564 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
565 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
566 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
567 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
568 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  11751
dev_network_count:  40
learn step counter:  11801
dev_network_count:  40
learn step counter:  11851
dev_network_count:  40
learn step counter:  11901
dev_network_count:  40
learn step counter:  11951
dev_network_count:  40

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
41  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  12001
dev_network_count:  41
learn step counter:  12051
dev_network_count:  41
learn step counter:  12101
dev_network_count:  41
learn step counter:  12151
dev_network_count:  41
learn step counter:  12201
dev_network_count:  41
learn step counter:  12251
dev_network_count:  41

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
42  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  12301
dev_network_count:  42
learn step counter:  12351
dev_network_count:  42
learn step counter:  12401
dev_network_count:  42
learn step counter:  12451
dev_network_count:  42
learn step counter:  12501
dev_network_count:  42
learn step counter:  12551
dev_network_count:  42

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
43  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  12601
dev_network_count:  43
learn step counter:  12651
dev_network_count:  43
learn step counter:  12701
dev_network_count:  43
EPOCH %d 16
 beam_dqn, egreed, gamma:  1 0.001 0.8883699432423433
2745 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2746 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2747 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2748 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2749 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2750 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2751 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  12751
dev_network_count:  43
learn step counter:  12801
dev_network_count:  43
learn step counter:  12851
dev_network_count:  43

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
44  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  12901
dev_network_count:  44
learn step counter:  12951
dev_network_count:  44
learn step counter:  13001
dev_network_count:  44
learn step counter:  13051
dev_network_count:  44
learn step counter:  13101
dev_network_count:  44
learn step counter:  13151
dev_network_count:  44

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
45  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  13201
dev_network_count:  45
learn step counter:  13251
dev_network_count:  45
learn step counter:  13301
dev_network_count:  45
learn step counter:  13351
dev_network_count:  45
learn step counter:  13401
dev_network_count:  45
learn step counter:  13451
dev_network_count:  45

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
46  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  13501
dev_network_count:  46
learn step counter:  13551
dev_network_count:  46
learn step counter:  13601
dev_network_count:  46
learn step counter:  13651
dev_network_count:  46
learn step counter:  13701
dev_network_count:  46
EPOCH %d 17
 beam_dqn, egreed, gamma:  1 0.001 0.8874815732991009
4928 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4929 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4930 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4931 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4932 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4933 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4934 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  13751
dev_network_count:  46

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
47  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  13801
dev_network_count:  47
learn step counter:  13851
dev_network_count:  47
learn step counter:  13901
dev_network_count:  47
learn step counter:  13951
dev_network_count:  47
learn step counter:  14001
dev_network_count:  47
learn step counter:  14051
dev_network_count:  47

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
48  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  14101
dev_network_count:  48
learn step counter:  14151
dev_network_count:  48
learn step counter:  14201
dev_network_count:  48
learn step counter:  14251
dev_network_count:  48
learn step counter:  14301
dev_network_count:  48
learn step counter:  14351
dev_network_count:  48

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
49  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  14401
dev_network_count:  49
learn step counter:  14451
dev_network_count:  49
learn step counter:  14501
dev_network_count:  49
learn step counter:  14551
dev_network_count:  49
learn step counter:  14601
dev_network_count:  49
learn step counter:  14651
dev_network_count:  49

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
50  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  14701
dev_network_count:  50
EPOCH %d 18
 beam_dqn, egreed, gamma:  1 0.001 0.8865940917258017
2111 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2112 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2113 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2114 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2115 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2116 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2117 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  14751
dev_network_count:  50
learn step counter:  14801
dev_network_count:  50
learn step counter:  14851
dev_network_count:  50
learn step counter:  14901
dev_network_count:  50
learn step counter:  14951
dev_network_count:  50

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
51  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  15001
dev_network_count:  51
learn step counter:  15051
dev_network_count:  51
learn step counter:  15101
dev_network_count:  51
learn step counter:  15151
dev_network_count:  51
learn step counter:  15201
dev_network_count:  51
learn step counter:  15251
dev_network_count:  51

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
52  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  15301
dev_network_count:  52
learn step counter:  15351
dev_network_count:  52
learn step counter:  15401
dev_network_count:  52
learn step counter:  15451
dev_network_count:  52
learn step counter:  15501
dev_network_count:  52
learn step counter:  15551
dev_network_count:  52

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
53  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  15601
dev_network_count:  53
learn step counter:  15651
dev_network_count:  53
learn step counter:  15701
dev_network_count:  53
EPOCH %d 19
 beam_dqn, egreed, gamma:  1 0.001 0.885707497634076
4294 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4295 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4296 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4297 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4298 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4299 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4300 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  15751
dev_network_count:  53
learn step counter:  15801
dev_network_count:  53
learn step counter:  15851
dev_network_count:  53

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
54  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  15901
dev_network_count:  54
learn step counter:  15951
dev_network_count:  54
learn step counter:  16001
dev_network_count:  54
learn step counter:  16051
dev_network_count:  54
learn step counter:  16101
dev_network_count:  54
learn step counter:  16151
dev_network_count:  54

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
55  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  16201
dev_network_count:  55
learn step counter:  16251
dev_network_count:  55
learn step counter:  16301
dev_network_count:  55
learn step counter:  16351
dev_network_count:  55
learn step counter:  16401
dev_network_count:  55
learn step counter:  16451
dev_network_count:  55

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
56  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  16501
dev_network_count:  56
learn step counter:  16551
dev_network_count:  56
learn step counter:  16601
dev_network_count:  56
learn step counter:  16651
dev_network_count:  56
learn step counter:  16701
dev_network_count:  56
EPOCH %d 20
 beam_dqn, egreed, gamma:  1 0.001 0.884821790136442
1477 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1478 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1479 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1480 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1481 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1482 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1483 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  16751
dev_network_count:  56

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
57  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  16801
dev_network_count:  57
learn step counter:  16851
dev_network_count:  57
learn step counter:  16901
dev_network_count:  57
learn step counter:  16951
dev_network_count:  57
learn step counter:  17001
dev_network_count:  57
learn step counter:  17051
dev_network_count:  57

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
58  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  17101
dev_network_count:  58
learn step counter:  17151
dev_network_count:  58
learn step counter:  17201
dev_network_count:  58
learn step counter:  17251
dev_network_count:  58
learn step counter:  17301
dev_network_count:  58
learn step counter:  17351
dev_network_count:  58

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
59  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  17401
dev_network_count:  59
learn step counter:  17451
dev_network_count:  59
learn step counter:  17501
dev_network_count:  59
learn step counter:  17551
dev_network_count:  59
learn step counter:  17601
dev_network_count:  59
learn step counter:  17651
dev_network_count:  59

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
60  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  17701
dev_network_count:  60
EPOCH %d 21
 beam_dqn, egreed, gamma:  1 0.001 0.8839369683463054
3660 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3661 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3662 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3663 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3664 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3665 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3666 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  17751
dev_network_count:  60
learn step counter:  17801
dev_network_count:  60
learn step counter:  17851
dev_network_count:  60
learn step counter:  17901
dev_network_count:  60
learn step counter:  17951
dev_network_count:  60

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
61  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  18001
dev_network_count:  61
learn step counter:  18051
dev_network_count:  61
learn step counter:  18101
dev_network_count:  61
learn step counter:  18151
dev_network_count:  61
learn step counter:  18201
dev_network_count:  61
learn step counter:  18251
dev_network_count:  61

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
62  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  18301
dev_network_count:  62
learn step counter:  18351
dev_network_count:  62
learn step counter:  18401
dev_network_count:  62
learn step counter:  18451
dev_network_count:  62
learn step counter:  18501
dev_network_count:  62
learn step counter:  18551
dev_network_count:  62

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
63  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  18601
dev_network_count:  63
learn step counter:  18651
dev_network_count:  63
learn step counter:  18701
dev_network_count:  63
EPOCH %d 22
 beam_dqn, egreed, gamma:  1 0.001 0.8830530313779591
843 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
844 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
845 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
846 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
847 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
848 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
849 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  18751
dev_network_count:  63
learn step counter:  18801
dev_network_count:  63
learn step counter:  18851
dev_network_count:  63

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
64  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  18901
dev_network_count:  64
learn step counter:  18951
dev_network_count:  64
learn step counter:  19001
dev_network_count:  64
learn step counter:  19051
dev_network_count:  64
learn step counter:  19101
dev_network_count:  64
learn step counter:  19151
dev_network_count:  64

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
65  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  19201
dev_network_count:  65
learn step counter:  19251
dev_network_count:  65
learn step counter:  19301
dev_network_count:  65
learn step counter:  19351
dev_network_count:  65
learn step counter:  19401
dev_network_count:  65
learn step counter:  19451
dev_network_count:  65

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
66  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  19501
dev_network_count:  66
learn step counter:  19551
dev_network_count:  66
learn step counter:  19601
dev_network_count:  66
learn step counter:  19651
dev_network_count:  66
learn step counter:  19701
dev_network_count:  66
EPOCH %d 23
 beam_dqn, egreed, gamma:  1 0.001 0.8821699783465813
3026 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3027 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3028 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3029 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3030 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3031 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3032 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  19751
dev_network_count:  66

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
67  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  19801
dev_network_count:  67
learn step counter:  19851
dev_network_count:  67
learn step counter:  19901
dev_network_count:  67
learn step counter:  19951
dev_network_count:  67
learn step counter:  20001
dev_network_count:  67
learn step counter:  20051
dev_network_count:  67

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
68  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  20101
dev_network_count:  68
learn step counter:  20151
dev_network_count:  68
learn step counter:  20201
dev_network_count:  68
learn step counter:  20251
dev_network_count:  68
learn step counter:  20301
dev_network_count:  68
learn step counter:  20351
dev_network_count:  68

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
69  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  20401
dev_network_count:  69
learn step counter:  20451
dev_network_count:  69
learn step counter:  20501
dev_network_count:  69
learn step counter:  20551
dev_network_count:  69
learn step counter:  20601
dev_network_count:  69
learn step counter:  20651
dev_network_count:  69

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
70  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  20701
dev_network_count:  70
EPOCH %d 24
 beam_dqn, egreed, gamma:  1 0.001 0.8812878083682347
209 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
210 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
211 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
212 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
213 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
214 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
215 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  20751
dev_network_count:  70
learn step counter:  20801
dev_network_count:  70
learn step counter:  20851
dev_network_count:  70
learn step counter:  20901
dev_network_count:  70
learn step counter:  20951
dev_network_count:  70

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
71  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  21001
dev_network_count:  71
learn step counter:  21051
dev_network_count:  71
learn step counter:  21101
dev_network_count:  71
learn step counter:  21151
dev_network_count:  71
learn step counter:  21201
dev_network_count:  71
learn step counter:  21251
dev_network_count:  71

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
72  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  21301
dev_network_count:  72
learn step counter:  21351
dev_network_count:  72
learn step counter:  21401
dev_network_count:  72
learn step counter:  21451
dev_network_count:  72
learn step counter:  21501
dev_network_count:  72
learn step counter:  21551
dev_network_count:  72

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
73  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  21601
dev_network_count:  73
learn step counter:  21651
dev_network_count:  73
learn step counter:  21701
dev_network_count:  73
EPOCH %d 25
 beam_dqn, egreed, gamma:  1 0.001 0.8804065205598663
2392 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2393 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2394 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2395 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2396 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2397 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2398 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  21751
dev_network_count:  73
learn step counter:  21801
dev_network_count:  73
learn step counter:  21851
dev_network_count:  73

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
74  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  21901
dev_network_count:  74
learn step counter:  21951
dev_network_count:  74
learn step counter:  22001
dev_network_count:  74
learn step counter:  22051
dev_network_count:  74
learn step counter:  22101
dev_network_count:  74
learn step counter:  22151
dev_network_count:  74

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
75  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  22201
dev_network_count:  75
learn step counter:  22251
dev_network_count:  75
learn step counter:  22301
dev_network_count:  75
learn step counter:  22351
dev_network_count:  75
learn step counter:  22401
dev_network_count:  75
learn step counter:  22451
dev_network_count:  75

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
76  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  22501
dev_network_count:  76
learn step counter:  22551
dev_network_count:  76
learn step counter:  22601
dev_network_count:  76
learn step counter:  22651
dev_network_count:  76
learn step counter:  22701
dev_network_count:  76
EPOCH %d 26
 beam_dqn, egreed, gamma:  1 0.001 0.8795261140393066
4575 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4576 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4577 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4578 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4579 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4580 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4581 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  22751
dev_network_count:  76

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
77  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  22801
dev_network_count:  77
learn step counter:  22851
dev_network_count:  77
learn step counter:  22901
dev_network_count:  77
learn step counter:  22951
dev_network_count:  77
learn step counter:  23001
dev_network_count:  77
learn step counter:  23051
dev_network_count:  77

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
78  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  23101
dev_network_count:  78
learn step counter:  23151
dev_network_count:  78
learn step counter:  23201
dev_network_count:  78
learn step counter:  23251
dev_network_count:  78
learn step counter:  23301
dev_network_count:  78
learn step counter:  23351
dev_network_count:  78

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
79  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  23401
dev_network_count:  79
learn step counter:  23451
dev_network_count:  79
learn step counter:  23501
dev_network_count:  79
learn step counter:  23551
dev_network_count:  79
learn step counter:  23601
dev_network_count:  79
learn step counter:  23651
dev_network_count:  79

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
80  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  23701
dev_network_count:  80
EPOCH %d 27
 beam_dqn, egreed, gamma:  1 0.001 0.8786465879252672
1758 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1759 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1760 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1761 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1762 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1763 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1764 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  23751
dev_network_count:  80
learn step counter:  23801
dev_network_count:  80
learn step counter:  23851
dev_network_count:  80
learn step counter:  23901
dev_network_count:  80
learn step counter:  23951
dev_network_count:  80

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
81  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  24001
dev_network_count:  81
learn step counter:  24051
dev_network_count:  81
learn step counter:  24101
dev_network_count:  81
learn step counter:  24151
dev_network_count:  81
learn step counter:  24201
dev_network_count:  81
learn step counter:  24251
dev_network_count:  81

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
82  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  24301
dev_network_count:  82
learn step counter:  24351
dev_network_count:  82
learn step counter:  24401
dev_network_count:  82
learn step counter:  24451
dev_network_count:  82
learn step counter:  24501
dev_network_count:  82
learn step counter:  24551
dev_network_count:  82

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
83  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  24601
dev_network_count:  83
learn step counter:  24651
dev_network_count:  83
learn step counter:  24701
dev_network_count:  83
EPOCH %d 28
 beam_dqn, egreed, gamma:  1 0.001 0.8777679413373419
3941 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3942 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3943 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3944 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3945 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3946 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3947 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  24751
dev_network_count:  83
learn step counter:  24801
dev_network_count:  83
learn step counter:  24851
dev_network_count:  83

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
84  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  24901
dev_network_count:  84
learn step counter:  24951
dev_network_count:  84
learn step counter:  25001
dev_network_count:  84
learn step counter:  25051
dev_network_count:  84
learn step counter:  25101
dev_network_count:  84
learn step counter:  25151
dev_network_count:  84

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
85  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  25201
dev_network_count:  85
learn step counter:  25251
dev_network_count:  85
learn step counter:  25301
dev_network_count:  85
learn step counter:  25351
dev_network_count:  85
learn step counter:  25401
dev_network_count:  85
learn step counter:  25451
dev_network_count:  85

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
86  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  25501
dev_network_count:  86
learn step counter:  25551
dev_network_count:  86
learn step counter:  25601
dev_network_count:  86
learn step counter:  25651
dev_network_count:  86
learn step counter:  25701
dev_network_count:  86
EPOCH %d 29
 beam_dqn, egreed, gamma:  1 0.001 0.8768901733960046
1124 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1125 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1126 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1127 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1128 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1129 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1130 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  25751
dev_network_count:  86

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
87  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  25801
dev_network_count:  87
learn step counter:  25851
dev_network_count:  87
learn step counter:  25901
dev_network_count:  87
learn step counter:  25951
dev_network_count:  87
learn step counter:  26001
dev_network_count:  87
learn step counter:  26051
dev_network_count:  87

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
88  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  26101
dev_network_count:  88
learn step counter:  26151
dev_network_count:  88
learn step counter:  26201
dev_network_count:  88
learn step counter:  26251
dev_network_count:  88
learn step counter:  26301
dev_network_count:  88
learn step counter:  26351
dev_network_count:  88

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
89  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  26401
dev_network_count:  89
learn step counter:  26451
dev_network_count:  89
learn step counter:  26501
dev_network_count:  89
learn step counter:  26551
dev_network_count:  89
learn step counter:  26601
dev_network_count:  89
learn step counter:  26651
dev_network_count:  89

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
90  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  26701
dev_network_count:  90
EPOCH %d 30
 beam_dqn, egreed, gamma:  1 0.001 0.8760132832226086
3307 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3308 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3309 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3310 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3311 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3312 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3313 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  26751
dev_network_count:  90
learn step counter:  26801
dev_network_count:  90
learn step counter:  26851
dev_network_count:  90
learn step counter:  26901
dev_network_count:  90
learn step counter:  26951
dev_network_count:  90

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
91  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  27001
dev_network_count:  91
learn step counter:  27051
dev_network_count:  91
learn step counter:  27101
dev_network_count:  91
learn step counter:  27151
dev_network_count:  91
learn step counter:  27201
dev_network_count:  91
learn step counter:  27251
dev_network_count:  91

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
92  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  27301
dev_network_count:  92
learn step counter:  27351
dev_network_count:  92
learn step counter:  27401
dev_network_count:  92
learn step counter:  27451
dev_network_count:  92
learn step counter:  27501
dev_network_count:  92
learn step counter:  27551
dev_network_count:  92

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
93  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  27601
dev_network_count:  93
learn step counter:  27651
dev_network_count:  93
learn step counter:  27701
dev_network_count:  93
EPOCH %d 31
 beam_dqn, egreed, gamma:  1 0.001 0.875137269939386
490 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
491 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
492 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
493 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
494 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
495 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
496 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  27751
dev_network_count:  93
learn step counter:  27801
dev_network_count:  93
learn step counter:  27851
dev_network_count:  93

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
94  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  27901
dev_network_count:  94
learn step counter:  27951
dev_network_count:  94
learn step counter:  28001
dev_network_count:  94
learn step counter:  28051
dev_network_count:  94
learn step counter:  28101
dev_network_count:  94
learn step counter:  28151
dev_network_count:  94

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
95  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  28201
dev_network_count:  95
learn step counter:  28251
dev_network_count:  95
learn step counter:  28301
dev_network_count:  95
learn step counter:  28351
dev_network_count:  95
learn step counter:  28401
dev_network_count:  95
learn step counter:  28451
dev_network_count:  95

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
96  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  28501
dev_network_count:  96
learn step counter:  28551
dev_network_count:  96
learn step counter:  28601
dev_network_count:  96
learn step counter:  28651
dev_network_count:  96
learn step counter:  28701
dev_network_count:  96
EPOCH %d 32
 beam_dqn, egreed, gamma:  1 0.001 0.8742621326694466
2673 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2674 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2675 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2676 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2677 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2678 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2679 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  28751
dev_network_count:  96

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9285,  0.8384, -0.6495])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9779,  0.8468, -0.9201])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9774,  0.8689, -0.9504])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9763,  0.8722, -0.9554])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9753,  0.8739, -0.9565])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
97  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  28801
dev_network_count:  97
learn step counter:  28851
dev_network_count:  97
learn step counter:  28901
dev_network_count:  97
learn step counter:  28951
dev_network_count:  97
learn step counter:  29001
dev_network_count:  97
learn step counter:  29051
dev_network_count:  97

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
98  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  29101
dev_network_count:  98
learn step counter:  29151
dev_network_count:  98
learn step counter:  29201
dev_network_count:  98
learn step counter:  29251
dev_network_count:  98
learn step counter:  29301
dev_network_count:  98
learn step counter:  29351
dev_network_count:  98

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
99  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  29401
dev_network_count:  99
learn step counter:  29451
dev_network_count:  99
learn step counter:  29501
dev_network_count:  99
learn step counter:  29551
dev_network_count:  99
learn step counter:  29601
dev_network_count:  99
learn step counter:  29651
dev_network_count:  99

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
100  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  29701
dev_network_count:  100
EPOCH %d 33
 beam_dqn, egreed, gamma:  1 0.001 0.8733878705367772
4856 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4857 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4858 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4859 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4860 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4861 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4862 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  29751
dev_network_count:  100
learn step counter:  29801
dev_network_count:  100
learn step counter:  29851
dev_network_count:  100
learn step counter:  29901
dev_network_count:  100
learn step counter:  29951
dev_network_count:  100

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
101  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  30001
dev_network_count:  101
learn step counter:  30051
dev_network_count:  101
learn step counter:  30101
dev_network_count:  101
learn step counter:  30151
dev_network_count:  101
learn step counter:  30201
dev_network_count:  101
learn step counter:  30251
dev_network_count:  101

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
102  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  30301
dev_network_count:  102
learn step counter:  30351
dev_network_count:  102
learn step counter:  30401
dev_network_count:  102
learn step counter:  30451
dev_network_count:  102
learn step counter:  30501
dev_network_count:  102
learn step counter:  30551
dev_network_count:  102

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
103  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  30601
dev_network_count:  103
learn step counter:  30651
dev_network_count:  103
learn step counter:  30701
dev_network_count:  103
EPOCH %d 34
 beam_dqn, egreed, gamma:  1 0.001 0.8725144826662404
2039 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2040 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2041 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2042 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2043 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2044 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2045 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  30751
dev_network_count:  103
learn step counter:  30801
dev_network_count:  103
learn step counter:  30851
dev_network_count:  103

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
104  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  30901
dev_network_count:  104
learn step counter:  30951
dev_network_count:  104
learn step counter:  31001
dev_network_count:  104
learn step counter:  31051
dev_network_count:  104
learn step counter:  31101
dev_network_count:  104
learn step counter:  31151
dev_network_count:  104

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
105  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  31201
dev_network_count:  105
learn step counter:  31251
dev_network_count:  105
learn step counter:  31301
dev_network_count:  105
learn step counter:  31351
dev_network_count:  105
learn step counter:  31401
dev_network_count:  105
learn step counter:  31451
dev_network_count:  105

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
106  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  31501
dev_network_count:  106
learn step counter:  31551
dev_network_count:  106
learn step counter:  31601
dev_network_count:  106
learn step counter:  31651
dev_network_count:  106
learn step counter:  31701
dev_network_count:  106
EPOCH %d 35
 beam_dqn, egreed, gamma:  1 0.001 0.8716419681835741
4222 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4223 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4224 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4225 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4226 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4227 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4228 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  31751
dev_network_count:  106

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
107  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  31801
dev_network_count:  107
learn step counter:  31851
dev_network_count:  107
learn step counter:  31901
dev_network_count:  107
learn step counter:  31951
dev_network_count:  107
learn step counter:  32001
dev_network_count:  107
learn step counter:  32051
dev_network_count:  107

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
108  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  32101
dev_network_count:  108
learn step counter:  32151
dev_network_count:  108
learn step counter:  32201
dev_network_count:  108
learn step counter:  32251
dev_network_count:  108
learn step counter:  32301
dev_network_count:  108
learn step counter:  32351
dev_network_count:  108

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
109  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  32401
dev_network_count:  109
learn step counter:  32451
dev_network_count:  109
learn step counter:  32501
dev_network_count:  109
learn step counter:  32551
dev_network_count:  109
learn step counter:  32601
dev_network_count:  109
learn step counter:  32651
dev_network_count:  109

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
110  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  32701
dev_network_count:  110
EPOCH %d 36
 beam_dqn, egreed, gamma:  1 0.001 0.8707703262153905
1405 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1406 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1407 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1408 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1409 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1410 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1411 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  32751
dev_network_count:  110
learn step counter:  32801
dev_network_count:  110
learn step counter:  32851
dev_network_count:  110
learn step counter:  32901
dev_network_count:  110
learn step counter:  32951
dev_network_count:  110

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
111  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  33001
dev_network_count:  111
learn step counter:  33051
dev_network_count:  111
learn step counter:  33101
dev_network_count:  111
learn step counter:  33151
dev_network_count:  111
learn step counter:  33201
dev_network_count:  111
learn step counter:  33251
dev_network_count:  111

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
112  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  33301
dev_network_count:  112
learn step counter:  33351
dev_network_count:  112
learn step counter:  33401
dev_network_count:  112
learn step counter:  33451
dev_network_count:  112
learn step counter:  33501
dev_network_count:  112
learn step counter:  33551
dev_network_count:  112

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
113  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  33601
dev_network_count:  113
learn step counter:  33651
dev_network_count:  113
learn step counter:  33701
dev_network_count:  113
EPOCH %d 37
 beam_dqn, egreed, gamma:  1 0.001 0.8698995558891751
3588 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3589 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3590 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3591 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3592 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3593 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3594 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  33751
dev_network_count:  113
learn step counter:  33801
dev_network_count:  113
learn step counter:  33851
dev_network_count:  113

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
114  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  33901
dev_network_count:  114
learn step counter:  33951
dev_network_count:  114
learn step counter:  34001
dev_network_count:  114
learn step counter:  34051
dev_network_count:  114
learn step counter:  34101
dev_network_count:  114
learn step counter:  34151
dev_network_count:  114

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
115  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  34201
dev_network_count:  115
learn step counter:  34251
dev_network_count:  115
learn step counter:  34301
dev_network_count:  115
learn step counter:  34351
dev_network_count:  115
learn step counter:  34401
dev_network_count:  115
learn step counter:  34451
dev_network_count:  115

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
116  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  34501
dev_network_count:  116
learn step counter:  34551
dev_network_count:  116
learn step counter:  34601
dev_network_count:  116
learn step counter:  34651
dev_network_count:  116
learn step counter:  34701
dev_network_count:  116
EPOCH %d 38
 beam_dqn, egreed, gamma:  1 0.001 0.869029656333286
771 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
772 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
773 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
774 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
775 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
776 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
777 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  34751
dev_network_count:  116

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
117  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  34801
dev_network_count:  117
learn step counter:  34851
dev_network_count:  117
learn step counter:  34901
dev_network_count:  117
learn step counter:  34951
dev_network_count:  117
learn step counter:  35001
dev_network_count:  117
learn step counter:  35051
dev_network_count:  117

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
118  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  35101
dev_network_count:  118
learn step counter:  35151
dev_network_count:  118
learn step counter:  35201
dev_network_count:  118
learn step counter:  35251
dev_network_count:  118
learn step counter:  35301
dev_network_count:  118
learn step counter:  35351
dev_network_count:  118

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
119  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  35401
dev_network_count:  119
learn step counter:  35451
dev_network_count:  119
learn step counter:  35501
dev_network_count:  119
learn step counter:  35551
dev_network_count:  119
learn step counter:  35601
dev_network_count:  119
learn step counter:  35651
dev_network_count:  119

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
120  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  35701
dev_network_count:  120
EPOCH %d 39
 beam_dqn, egreed, gamma:  1 0.001 0.8681606266769527
2954 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2955 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2956 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2957 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2958 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2959 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2960 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  35751
dev_network_count:  120
learn step counter:  35801
dev_network_count:  120
learn step counter:  35851
dev_network_count:  120
learn step counter:  35901
dev_network_count:  120
learn step counter:  35951
dev_network_count:  120

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
121  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  36001
dev_network_count:  121
learn step counter:  36051
dev_network_count:  121
learn step counter:  36101
dev_network_count:  121
learn step counter:  36151
dev_network_count:  121
learn step counter:  36201
dev_network_count:  121
learn step counter:  36251
dev_network_count:  121

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
122  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  36301
dev_network_count:  122
learn step counter:  36351
dev_network_count:  122
learn step counter:  36401
dev_network_count:  122
learn step counter:  36451
dev_network_count:  122
learn step counter:  36501
dev_network_count:  122
learn step counter:  36551
dev_network_count:  122

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
123  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  36601
dev_network_count:  123
learn step counter:  36651
dev_network_count:  123
learn step counter:  36701
dev_network_count:  123
EPOCH %d 40
 beam_dqn, egreed, gamma:  1 0.001 0.8672924660502758
137 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
138 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
139 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
140 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
141 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
142 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
143 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  36751
dev_network_count:  123
learn step counter:  36801
dev_network_count:  123
learn step counter:  36851
dev_network_count:  123

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
124  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  36901
dev_network_count:  124
learn step counter:  36951
dev_network_count:  124
learn step counter:  37001
dev_network_count:  124
learn step counter:  37051
dev_network_count:  124
learn step counter:  37101
dev_network_count:  124
learn step counter:  37151
dev_network_count:  124

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
125  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  37201
dev_network_count:  125
learn step counter:  37251
dev_network_count:  125
learn step counter:  37301
dev_network_count:  125
learn step counter:  37351
dev_network_count:  125
learn step counter:  37401
dev_network_count:  125
learn step counter:  37451
dev_network_count:  125

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
126  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  37501
dev_network_count:  126
learn step counter:  37551
dev_network_count:  126
learn step counter:  37601
dev_network_count:  126
learn step counter:  37651
dev_network_count:  126
learn step counter:  37701
dev_network_count:  126
EPOCH %d 41
 beam_dqn, egreed, gamma:  1 0.001 0.8664251735842254
2320 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2321 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2322 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2323 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2324 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2325 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2326 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  37751
dev_network_count:  126

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
127  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  37801
dev_network_count:  127
learn step counter:  37851
dev_network_count:  127
learn step counter:  37901
dev_network_count:  127
learn step counter:  37951
dev_network_count:  127
learn step counter:  38001
dev_network_count:  127
learn step counter:  38051
dev_network_count:  127

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
128  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  38101
dev_network_count:  128
learn step counter:  38151
dev_network_count:  128
learn step counter:  38201
dev_network_count:  128
learn step counter:  38251
dev_network_count:  128
learn step counter:  38301
dev_network_count:  128
learn step counter:  38351
dev_network_count:  128

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
129  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  38401
dev_network_count:  129
learn step counter:  38451
dev_network_count:  129
learn step counter:  38501
dev_network_count:  129
learn step counter:  38551
dev_network_count:  129
learn step counter:  38601
dev_network_count:  129
learn step counter:  38651
dev_network_count:  129

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
130  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  38701
dev_network_count:  130
EPOCH %d 42
 beam_dqn, egreed, gamma:  1 0.001 0.8655587484106413
4503 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4504 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4505 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4506 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4507 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4508 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4509 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  38751
dev_network_count:  130
learn step counter:  38801
dev_network_count:  130
learn step counter:  38851
dev_network_count:  130
learn step counter:  38901
dev_network_count:  130
learn step counter:  38951
dev_network_count:  130

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
131  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  39001
dev_network_count:  131
learn step counter:  39051
dev_network_count:  131
learn step counter:  39101
dev_network_count:  131
learn step counter:  39151
dev_network_count:  131
learn step counter:  39201
dev_network_count:  131
learn step counter:  39251
dev_network_count:  131

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
132  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  39301
dev_network_count:  132
learn step counter:  39351
dev_network_count:  132
learn step counter:  39401
dev_network_count:  132
learn step counter:  39451
dev_network_count:  132
learn step counter:  39501
dev_network_count:  132
learn step counter:  39551
dev_network_count:  132

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
133  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  39601
dev_network_count:  133
learn step counter:  39651
dev_network_count:  133
learn step counter:  39701
dev_network_count:  133
EPOCH %d 43
 beam_dqn, egreed, gamma:  1 0.001 0.8646931896622306
1686 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1687 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1688 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1689 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1690 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1691 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1692 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  39751
dev_network_count:  133
learn step counter:  39801
dev_network_count:  133
learn step counter:  39851
dev_network_count:  133

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
134  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  39901
dev_network_count:  134
learn step counter:  39951
dev_network_count:  134
learn step counter:  40001
dev_network_count:  134
learn step counter:  40051
dev_network_count:  134
learn step counter:  40101
dev_network_count:  134
learn step counter:  40151
dev_network_count:  134

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
135  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  40201
dev_network_count:  135
learn step counter:  40251
dev_network_count:  135
learn step counter:  40301
dev_network_count:  135
learn step counter:  40351
dev_network_count:  135
learn step counter:  40401
dev_network_count:  135
learn step counter:  40451
dev_network_count:  135

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
136  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  40501
dev_network_count:  136
learn step counter:  40551
dev_network_count:  136
learn step counter:  40601
dev_network_count:  136
learn step counter:  40651
dev_network_count:  136
learn step counter:  40701
dev_network_count:  136
EPOCH %d 44
 beam_dqn, egreed, gamma:  1 0.001 0.8638284964725684
3869 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3870 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3871 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3872 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3873 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3874 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3875 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  40751
dev_network_count:  136

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
137  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  40801
dev_network_count:  137
learn step counter:  40851
dev_network_count:  137
learn step counter:  40901
dev_network_count:  137
learn step counter:  40951
dev_network_count:  137
learn step counter:  41001
dev_network_count:  137
learn step counter:  41051
dev_network_count:  137

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
138  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  41101
dev_network_count:  138
learn step counter:  41151
dev_network_count:  138
learn step counter:  41201
dev_network_count:  138
learn step counter:  41251
dev_network_count:  138
learn step counter:  41301
dev_network_count:  138
learn step counter:  41351
dev_network_count:  138

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
139  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  41401
dev_network_count:  139
learn step counter:  41451
dev_network_count:  139
learn step counter:  41501
dev_network_count:  139
learn step counter:  41551
dev_network_count:  139
learn step counter:  41601
dev_network_count:  139
learn step counter:  41651
dev_network_count:  139

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
140  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  41701
dev_network_count:  140
EPOCH %d 45
 beam_dqn, egreed, gamma:  1 0.001 0.8629646679760958
1052 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1053 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1054 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1055 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1056 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1057 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1058 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  41751
dev_network_count:  140
learn step counter:  41801
dev_network_count:  140
learn step counter:  41851
dev_network_count:  140
learn step counter:  41901
dev_network_count:  140
learn step counter:  41951
dev_network_count:  140

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
141  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  42001
dev_network_count:  141
learn step counter:  42051
dev_network_count:  141
learn step counter:  42101
dev_network_count:  141
learn step counter:  42151
dev_network_count:  141
learn step counter:  42201
dev_network_count:  141
learn step counter:  42251
dev_network_count:  141

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
142  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  42301
dev_network_count:  142
learn step counter:  42351
dev_network_count:  142
learn step counter:  42401
dev_network_count:  142
learn step counter:  42451
dev_network_count:  142
learn step counter:  42501
dev_network_count:  142
learn step counter:  42551
dev_network_count:  142

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
143  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  42601
dev_network_count:  143
learn step counter:  42651
dev_network_count:  143
learn step counter:  42701
dev_network_count:  143
EPOCH %d 46
 beam_dqn, egreed, gamma:  1 0.001 0.8621017033081196
3235 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3236 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3237 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3238 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3239 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3240 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3241 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  42751
dev_network_count:  143
learn step counter:  42801
dev_network_count:  143
learn step counter:  42851
dev_network_count:  143

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
144  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  42901
dev_network_count:  144
learn step counter:  42951
dev_network_count:  144
learn step counter:  43001
dev_network_count:  144
learn step counter:  43051
dev_network_count:  144
learn step counter:  43101
dev_network_count:  144
learn step counter:  43151
dev_network_count:  144

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
145  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  43201
dev_network_count:  145
learn step counter:  43251
dev_network_count:  145
learn step counter:  43301
dev_network_count:  145
learn step counter:  43351
dev_network_count:  145
learn step counter:  43401
dev_network_count:  145
learn step counter:  43451
dev_network_count:  145

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
146  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  43501
dev_network_count:  146
learn step counter:  43551
dev_network_count:  146
learn step counter:  43601
dev_network_count:  146
learn step counter:  43651
dev_network_count:  146
learn step counter:  43701
dev_network_count:  146
EPOCH %d 47
 beam_dqn, egreed, gamma:  1 0.001 0.8612396016048116
418 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
419 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
420 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
421 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
422 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
423 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
424 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  43751
dev_network_count:  146

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
147  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  43801
dev_network_count:  147
learn step counter:  43851
dev_network_count:  147
learn step counter:  43901
dev_network_count:  147
learn step counter:  43951
dev_network_count:  147
learn step counter:  44001
dev_network_count:  147
learn step counter:  44051
dev_network_count:  147

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
148  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  44101
dev_network_count:  148
learn step counter:  44151
dev_network_count:  148
learn step counter:  44201
dev_network_count:  148
learn step counter:  44251
dev_network_count:  148
learn step counter:  44301
dev_network_count:  148
learn step counter:  44351
dev_network_count:  148

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
149  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  44401
dev_network_count:  149
learn step counter:  44451
dev_network_count:  149
learn step counter:  44501
dev_network_count:  149
learn step counter:  44551
dev_network_count:  149
learn step counter:  44601
dev_network_count:  149
learn step counter:  44651
dev_network_count:  149

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
150  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  44701
dev_network_count:  150
EPOCH %d 48
 beam_dqn, egreed, gamma:  1 0.001 0.8603783620032067
2601 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2602 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2603 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2604 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2605 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2606 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2607 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  44751
dev_network_count:  150
learn step counter:  44801
dev_network_count:  150
learn step counter:  44851
dev_network_count:  150
learn step counter:  44901
dev_network_count:  150
learn step counter:  44951
dev_network_count:  150

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
151  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  45001
dev_network_count:  151
learn step counter:  45051
dev_network_count:  151
learn step counter:  45101
dev_network_count:  151
learn step counter:  45151
dev_network_count:  151
learn step counter:  45201
dev_network_count:  151
learn step counter:  45251
dev_network_count:  151

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
152  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  45301
dev_network_count:  152
learn step counter:  45351
dev_network_count:  152
learn step counter:  45401
dev_network_count:  152
learn step counter:  45451
dev_network_count:  152
learn step counter:  45501
dev_network_count:  152
learn step counter:  45551
dev_network_count:  152

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
153  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  45601
dev_network_count:  153
learn step counter:  45651
dev_network_count:  153
learn step counter:  45701
dev_network_count:  153
EPOCH %d 49
 beam_dqn, egreed, gamma:  1 0.001 0.8595179836412036
4784 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4785 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4786 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4787 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4788 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4789 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4790 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  45751
dev_network_count:  153
learn step counter:  45801
dev_network_count:  153
learn step counter:  45851
dev_network_count:  153

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
154  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  45901
dev_network_count:  154
learn step counter:  45951
dev_network_count:  154
learn step counter:  46001
dev_network_count:  154
learn step counter:  46051
dev_network_count:  154
learn step counter:  46101
dev_network_count:  154
learn step counter:  46151
dev_network_count:  154

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
155  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  46201
dev_network_count:  155
learn step counter:  46251
dev_network_count:  155
learn step counter:  46301
dev_network_count:  155
learn step counter:  46351
dev_network_count:  155
learn step counter:  46401
dev_network_count:  155
learn step counter:  46451
dev_network_count:  155

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
156  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  46501
dev_network_count:  156
learn step counter:  46551
dev_network_count:  156
learn step counter:  46601
dev_network_count:  156
learn step counter:  46651
dev_network_count:  156
learn step counter:  46701
dev_network_count:  156
EPOCH %d 50
 beam_dqn, egreed, gamma:  1 0.001 0.8586584656575623
1967 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1968 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1969 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1970 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1971 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1972 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1973 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  46751
dev_network_count:  156

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
157  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  46801
dev_network_count:  157
learn step counter:  46851
dev_network_count:  157
learn step counter:  46901
dev_network_count:  157
learn step counter:  46951
dev_network_count:  157
learn step counter:  47001
dev_network_count:  157
learn step counter:  47051
dev_network_count:  157

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
158  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  47101
dev_network_count:  158
learn step counter:  47151
dev_network_count:  158
learn step counter:  47201
dev_network_count:  158
learn step counter:  47251
dev_network_count:  158
learn step counter:  47301
dev_network_count:  158
learn step counter:  47351
dev_network_count:  158

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
159  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  47401
dev_network_count:  159
learn step counter:  47451
dev_network_count:  159
learn step counter:  47501
dev_network_count:  159
learn step counter:  47551
dev_network_count:  159
learn step counter:  47601
dev_network_count:  159
learn step counter:  47651
dev_network_count:  159

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
160  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  47701
dev_network_count:  160
EPOCH %d 51
 beam_dqn, egreed, gamma:  1 0.001 0.8577998071919049
4150 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4151 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4152 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4153 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4154 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4155 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4156 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  47751
dev_network_count:  160
learn step counter:  47801
dev_network_count:  160
learn step counter:  47851
dev_network_count:  160
learn step counter:  47901
dev_network_count:  160
learn step counter:  47951
dev_network_count:  160

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
161  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  48001
dev_network_count:  161
learn step counter:  48051
dev_network_count:  161
learn step counter:  48101
dev_network_count:  161
learn step counter:  48151
dev_network_count:  161
learn step counter:  48201
dev_network_count:  161
learn step counter:  48251
dev_network_count:  161

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
162  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  48301
dev_network_count:  162
learn step counter:  48351
dev_network_count:  162
learn step counter:  48401
dev_network_count:  162
learn step counter:  48451
dev_network_count:  162
learn step counter:  48501
dev_network_count:  162
learn step counter:  48551
dev_network_count:  162

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
163  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  48601
dev_network_count:  163
learn step counter:  48651
dev_network_count:  163
learn step counter:  48701
dev_network_count:  163
EPOCH %d 52
 beam_dqn, egreed, gamma:  1 0.001 0.8569420073847129
1333 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1334 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1335 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1336 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1337 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1338 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1339 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  48751
dev_network_count:  163
learn step counter:  48801
dev_network_count:  163
learn step counter:  48851
dev_network_count:  163

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
164  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  48901
dev_network_count:  164
learn step counter:  48951
dev_network_count:  164
learn step counter:  49001
dev_network_count:  164
learn step counter:  49051
dev_network_count:  164
learn step counter:  49101
dev_network_count:  164
learn step counter:  49151
dev_network_count:  164

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
165  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  49201
dev_network_count:  165
learn step counter:  49251
dev_network_count:  165
learn step counter:  49301
dev_network_count:  165
learn step counter:  49351
dev_network_count:  165
learn step counter:  49401
dev_network_count:  165
learn step counter:  49451
dev_network_count:  165

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
166  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  49501
dev_network_count:  166
learn step counter:  49551
dev_network_count:  166
learn step counter:  49601
dev_network_count:  166
learn step counter:  49651
dev_network_count:  166
learn step counter:  49701
dev_network_count:  166
EPOCH %d 53
 beam_dqn, egreed, gamma:  1 0.001 0.8560850653773282
3516 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3517 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3518 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3519 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3520 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3521 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3522 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  49751
dev_network_count:  166

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
167  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  49801
dev_network_count:  167
learn step counter:  49851
dev_network_count:  167
learn step counter:  49901
dev_network_count:  167
learn step counter:  49951
dev_network_count:  167
learn step counter:  50001
dev_network_count:  167
learn step counter:  50051
dev_network_count:  167

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
168  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  50101
dev_network_count:  168
learn step counter:  50151
dev_network_count:  168
learn step counter:  50201
dev_network_count:  168
learn step counter:  50251
dev_network_count:  168
learn step counter:  50301
dev_network_count:  168
learn step counter:  50351
dev_network_count:  168

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
169  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  50401
dev_network_count:  169
learn step counter:  50451
dev_network_count:  169
learn step counter:  50501
dev_network_count:  169
learn step counter:  50551
dev_network_count:  169
learn step counter:  50601
dev_network_count:  169
learn step counter:  50651
dev_network_count:  169

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
170  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  50701
dev_network_count:  170
EPOCH %d 54
 beam_dqn, egreed, gamma:  1 0.001 0.8552289803119509
699 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
700 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
701 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
702 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
703 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
704 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
705 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  50751
dev_network_count:  170
learn step counter:  50801
dev_network_count:  170
learn step counter:  50851
dev_network_count:  170
learn step counter:  50901
dev_network_count:  170
learn step counter:  50951
dev_network_count:  170

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
171  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  51001
dev_network_count:  171
learn step counter:  51051
dev_network_count:  171
learn step counter:  51101
dev_network_count:  171
learn step counter:  51151
dev_network_count:  171
learn step counter:  51201
dev_network_count:  171
learn step counter:  51251
dev_network_count:  171

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
172  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  51301
dev_network_count:  172
learn step counter:  51351
dev_network_count:  172
learn step counter:  51401
dev_network_count:  172
learn step counter:  51451
dev_network_count:  172
learn step counter:  51501
dev_network_count:  172
learn step counter:  51551
dev_network_count:  172

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
173  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  51601
dev_network_count:  173
learn step counter:  51651
dev_network_count:  173
learn step counter:  51701
dev_network_count:  173
EPOCH %d 55
 beam_dqn, egreed, gamma:  1 0.001 0.8543737513316388
2882 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2883 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2884 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2885 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2886 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2887 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2888 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  51751
dev_network_count:  173
learn step counter:  51801
dev_network_count:  173
learn step counter:  51851
dev_network_count:  173

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
174  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  51901
dev_network_count:  174
learn step counter:  51951
dev_network_count:  174
learn step counter:  52001
dev_network_count:  174
learn step counter:  52051
dev_network_count:  174
learn step counter:  52101
dev_network_count:  174
learn step counter:  52151
dev_network_count:  174

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
175  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  52201
dev_network_count:  175
learn step counter:  52251
dev_network_count:  175
learn step counter:  52301
dev_network_count:  175
learn step counter:  52351
dev_network_count:  175
learn step counter:  52401
dev_network_count:  175
learn step counter:  52451
dev_network_count:  175

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
176  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  52501
dev_network_count:  176
learn step counter:  52551
dev_network_count:  176
learn step counter:  52601
dev_network_count:  176
learn step counter:  52651
dev_network_count:  176
learn step counter:  52701
dev_network_count:  176
EPOCH %d 56
 beam_dqn, egreed, gamma:  1 0.001 0.8535193775803073
65 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
66 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
67 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
68 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
69 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
70 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
71 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  52751
dev_network_count:  176

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
177  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  52801
dev_network_count:  177
learn step counter:  52851
dev_network_count:  177
learn step counter:  52901
dev_network_count:  177
learn step counter:  52951
dev_network_count:  177
learn step counter:  53001
dev_network_count:  177
learn step counter:  53051
dev_network_count:  177

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
178  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  53101
dev_network_count:  178
learn step counter:  53151
dev_network_count:  178
learn step counter:  53201
dev_network_count:  178
learn step counter:  53251
dev_network_count:  178
learn step counter:  53301
dev_network_count:  178
learn step counter:  53351
dev_network_count:  178

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
179  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  53401
dev_network_count:  179
learn step counter:  53451
dev_network_count:  179
learn step counter:  53501
dev_network_count:  179
learn step counter:  53551
dev_network_count:  179
learn step counter:  53601
dev_network_count:  179
learn step counter:  53651
dev_network_count:  179

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
180  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  53701
dev_network_count:  180
EPOCH %d 57
 beam_dqn, egreed, gamma:  1 0.001 0.852665858202727
2248 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2249 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2250 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2251 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2252 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2253 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2254 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  53751
dev_network_count:  180
learn step counter:  53801
dev_network_count:  180
learn step counter:  53851
dev_network_count:  180
learn step counter:  53901
dev_network_count:  180
learn step counter:  53951
dev_network_count:  180

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
181  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  54001
dev_network_count:  181
learn step counter:  54051
dev_network_count:  181
learn step counter:  54101
dev_network_count:  181
learn step counter:  54151
dev_network_count:  181
learn step counter:  54201
dev_network_count:  181
learn step counter:  54251
dev_network_count:  181

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
182  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  54301
dev_network_count:  182
learn step counter:  54351
dev_network_count:  182
learn step counter:  54401
dev_network_count:  182
learn step counter:  54451
dev_network_count:  182
learn step counter:  54501
dev_network_count:  182
learn step counter:  54551
dev_network_count:  182

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
183  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  54601
dev_network_count:  183
learn step counter:  54651
dev_network_count:  183
learn step counter:  54701
dev_network_count:  183
EPOCH %d 58
 beam_dqn, egreed, gamma:  1 0.001 0.8518131923445242
4431 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4432 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4433 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4434 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4435 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4436 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4437 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  54751
dev_network_count:  183
learn step counter:  54801
dev_network_count:  183
learn step counter:  54851
dev_network_count:  183

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
184  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  54901
dev_network_count:  184
learn step counter:  54951
dev_network_count:  184
learn step counter:  55001
dev_network_count:  184
learn step counter:  55051
dev_network_count:  184
learn step counter:  55101
dev_network_count:  184
learn step counter:  55151
dev_network_count:  184

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
185  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  55201
dev_network_count:  185
learn step counter:  55251
dev_network_count:  185
learn step counter:  55301
dev_network_count:  185
learn step counter:  55351
dev_network_count:  185
learn step counter:  55401
dev_network_count:  185
learn step counter:  55451
dev_network_count:  185

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
186  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  55501
dev_network_count:  186
learn step counter:  55551
dev_network_count:  186
learn step counter:  55601
dev_network_count:  186
learn step counter:  55651
dev_network_count:  186
learn step counter:  55701
dev_network_count:  186
EPOCH %d 59
 beam_dqn, egreed, gamma:  1 0.001 0.8509613791521797
1614 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1615 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1616 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1617 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1618 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1619 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1620 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  55751
dev_network_count:  186

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
187  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  55801
dev_network_count:  187
learn step counter:  55851
dev_network_count:  187
learn step counter:  55901
dev_network_count:  187
learn step counter:  55951
dev_network_count:  187
learn step counter:  56001
dev_network_count:  187
learn step counter:  56051
dev_network_count:  187

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
188  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  56101
dev_network_count:  188
learn step counter:  56151
dev_network_count:  188
learn step counter:  56201
dev_network_count:  188
learn step counter:  56251
dev_network_count:  188
learn step counter:  56301
dev_network_count:  188
learn step counter:  56351
dev_network_count:  188

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
189  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  56401
dev_network_count:  189
learn step counter:  56451
dev_network_count:  189
learn step counter:  56501
dev_network_count:  189
learn step counter:  56551
dev_network_count:  189
learn step counter:  56601
dev_network_count:  189
learn step counter:  56651
dev_network_count:  189

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
190  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  56701
dev_network_count:  190
EPOCH %d 60
 beam_dqn, egreed, gamma:  1 0.001 0.8501104177730275
3797 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3798 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3799 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3800 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3801 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3802 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3803 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  56751
dev_network_count:  190
learn step counter:  56801
dev_network_count:  190
learn step counter:  56851
dev_network_count:  190
learn step counter:  56901
dev_network_count:  190
learn step counter:  56951
dev_network_count:  190

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
191  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  57001
dev_network_count:  191
learn step counter:  57051
dev_network_count:  191
learn step counter:  57101
dev_network_count:  191
learn step counter:  57151
dev_network_count:  191
learn step counter:  57201
dev_network_count:  191
learn step counter:  57251
dev_network_count:  191

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
192  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  57301
dev_network_count:  192
learn step counter:  57351
dev_network_count:  192
learn step counter:  57401
dev_network_count:  192
learn step counter:  57451
dev_network_count:  192
learn step counter:  57501
dev_network_count:  192
learn step counter:  57551
dev_network_count:  192

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
193  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  57601
dev_network_count:  193
learn step counter:  57651
dev_network_count:  193
learn step counter:  57701
dev_network_count:  193
EPOCH %d 61
 beam_dqn, egreed, gamma:  1 0.001 0.8492603073552545
980 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
981 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
982 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
983 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
984 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
985 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
986 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  57751
dev_network_count:  193
learn step counter:  57801
dev_network_count:  193
learn step counter:  57851
dev_network_count:  193

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
194  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  57901
dev_network_count:  194
learn step counter:  57951
dev_network_count:  194
learn step counter:  58001
dev_network_count:  194
learn step counter:  58051
dev_network_count:  194
learn step counter:  58101
dev_network_count:  194
learn step counter:  58151
dev_network_count:  194

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
195  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  58201
dev_network_count:  195
learn step counter:  58251
dev_network_count:  195
learn step counter:  58301
dev_network_count:  195
learn step counter:  58351
dev_network_count:  195
learn step counter:  58401
dev_network_count:  195
learn step counter:  58451
dev_network_count:  195

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
196  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  58501
dev_network_count:  196
learn step counter:  58551
dev_network_count:  196
learn step counter:  58601
dev_network_count:  196
learn step counter:  58651
dev_network_count:  196
learn step counter:  58701
dev_network_count:  196
EPOCH %d 62
 beam_dqn, egreed, gamma:  1 0.001 0.8484110470478993
3163 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3164 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3165 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3166 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3167 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3168 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3169 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  58751
dev_network_count:  196

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
197  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  58801
dev_network_count:  197
learn step counter:  58851
dev_network_count:  197
learn step counter:  58901
dev_network_count:  197
learn step counter:  58951
dev_network_count:  197
learn step counter:  59001
dev_network_count:  197
learn step counter:  59051
dev_network_count:  197

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
198  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  59101
dev_network_count:  198
learn step counter:  59151
dev_network_count:  198
learn step counter:  59201
dev_network_count:  198
learn step counter:  59251
dev_network_count:  198
learn step counter:  59301
dev_network_count:  198
learn step counter:  59351
dev_network_count:  198

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
199  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  59401
dev_network_count:  199
learn step counter:  59451
dev_network_count:  199
learn step counter:  59501
dev_network_count:  199
learn step counter:  59551
dev_network_count:  199
learn step counter:  59601
dev_network_count:  199
learn step counter:  59651
dev_network_count:  199

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
200  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  59701
dev_network_count:  200
EPOCH %d 63
 beam_dqn, egreed, gamma:  1 0.001 0.8475626360008514
346 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
347 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
348 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
349 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
350 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
351 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
352 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  59751
dev_network_count:  200
learn step counter:  59801
dev_network_count:  200
learn step counter:  59851
dev_network_count:  200
learn step counter:  59901
dev_network_count:  200
learn step counter:  59951
dev_network_count:  200

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
201  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  60001
dev_network_count:  201
learn step counter:  60051
dev_network_count:  201
learn step counter:  60101
dev_network_count:  201
learn step counter:  60151
dev_network_count:  201
learn step counter:  60201
dev_network_count:  201
learn step counter:  60251
dev_network_count:  201

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
202  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  60301
dev_network_count:  202
learn step counter:  60351
dev_network_count:  202
learn step counter:  60401
dev_network_count:  202
learn step counter:  60451
dev_network_count:  202
learn step counter:  60501
dev_network_count:  202
learn step counter:  60551
dev_network_count:  202

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
203  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  60601
dev_network_count:  203
learn step counter:  60651
dev_network_count:  203
learn step counter:  60701
dev_network_count:  203
EPOCH %d 64
 beam_dqn, egreed, gamma:  1 0.001 0.8467150733648504
2529 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2530 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2531 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2532 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2533 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2534 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2535 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  60751
dev_network_count:  203
learn step counter:  60801
dev_network_count:  203
learn step counter:  60851
dev_network_count:  203

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
204  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  60901
dev_network_count:  204
learn step counter:  60951
dev_network_count:  204
learn step counter:  61001
dev_network_count:  204
learn step counter:  61051
dev_network_count:  204
learn step counter:  61101
dev_network_count:  204
learn step counter:  61151
dev_network_count:  204

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
205  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  61201
dev_network_count:  205
learn step counter:  61251
dev_network_count:  205
learn step counter:  61301
dev_network_count:  205
learn step counter:  61351
dev_network_count:  205
learn step counter:  61401
dev_network_count:  205
learn step counter:  61451
dev_network_count:  205

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
206  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  61501
dev_network_count:  206
learn step counter:  61551
dev_network_count:  206
learn step counter:  61601
dev_network_count:  206
learn step counter:  61651
dev_network_count:  206
learn step counter:  61701
dev_network_count:  206
EPOCH %d 65
 beam_dqn, egreed, gamma:  1 0.001 0.8458683582914857
4712 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4713 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4714 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4715 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4716 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4717 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4718 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  61751
dev_network_count:  206

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
207  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  61801
dev_network_count:  207
learn step counter:  61851
dev_network_count:  207
learn step counter:  61901
dev_network_count:  207
learn step counter:  61951
dev_network_count:  207
learn step counter:  62001
dev_network_count:  207
learn step counter:  62051
dev_network_count:  207

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
208  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  62101
dev_network_count:  208
learn step counter:  62151
dev_network_count:  208
learn step counter:  62201
dev_network_count:  208
learn step counter:  62251
dev_network_count:  208
learn step counter:  62301
dev_network_count:  208
learn step counter:  62351
dev_network_count:  208

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
209  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  62401
dev_network_count:  209
learn step counter:  62451
dev_network_count:  209
learn step counter:  62501
dev_network_count:  209
learn step counter:  62551
dev_network_count:  209
learn step counter:  62601
dev_network_count:  209
learn step counter:  62651
dev_network_count:  209

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
210  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  62701
dev_network_count:  210
EPOCH %d 66
 beam_dqn, egreed, gamma:  1 0.001 0.8450224899331942
1895 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1896 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1897 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1898 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1899 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1900 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1901 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  62751
dev_network_count:  210
learn step counter:  62801
dev_network_count:  210
learn step counter:  62851
dev_network_count:  210
learn step counter:  62901
dev_network_count:  210
learn step counter:  62951
dev_network_count:  210

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
211  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  63001
dev_network_count:  211
learn step counter:  63051
dev_network_count:  211
learn step counter:  63101
dev_network_count:  211
learn step counter:  63151
dev_network_count:  211
learn step counter:  63201
dev_network_count:  211
learn step counter:  63251
dev_network_count:  211

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
212  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  63301
dev_network_count:  212
learn step counter:  63351
dev_network_count:  212
learn step counter:  63401
dev_network_count:  212
learn step counter:  63451
dev_network_count:  212
learn step counter:  63501
dev_network_count:  212
learn step counter:  63551
dev_network_count:  212

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
213  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  63601
dev_network_count:  213
learn step counter:  63651
dev_network_count:  213
learn step counter:  63701
dev_network_count:  213
EPOCH %d 67
 beam_dqn, egreed, gamma:  1 0.001 0.8441774674432609
4078 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4079 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4080 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4081 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4082 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4083 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4084 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  63751
dev_network_count:  213
learn step counter:  63801
dev_network_count:  213
learn step counter:  63851
dev_network_count:  213

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
214  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  63901
dev_network_count:  214
learn step counter:  63951
dev_network_count:  214
learn step counter:  64001
dev_network_count:  214
learn step counter:  64051
dev_network_count:  214
learn step counter:  64101
dev_network_count:  214
learn step counter:  64151
dev_network_count:  214

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
215  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  64201
dev_network_count:  215
learn step counter:  64251
dev_network_count:  215
learn step counter:  64301
dev_network_count:  215
learn step counter:  64351
dev_network_count:  215
learn step counter:  64401
dev_network_count:  215
learn step counter:  64451
dev_network_count:  215

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
216  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  64501
dev_network_count:  216
learn step counter:  64551
dev_network_count:  216
learn step counter:  64601
dev_network_count:  216
learn step counter:  64651
dev_network_count:  216
learn step counter:  64701
dev_network_count:  216
EPOCH %d 68
 beam_dqn, egreed, gamma:  1 0.001 0.8433332899758177
1261 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1262 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1263 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1264 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1265 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1266 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1267 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  64751
dev_network_count:  216

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
217  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  64801
dev_network_count:  217
learn step counter:  64851
dev_network_count:  217
learn step counter:  64901
dev_network_count:  217
learn step counter:  64951
dev_network_count:  217
learn step counter:  65001
dev_network_count:  217
learn step counter:  65051
dev_network_count:  217

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
218  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  65101
dev_network_count:  218
learn step counter:  65151
dev_network_count:  218
learn step counter:  65201
dev_network_count:  218
learn step counter:  65251
dev_network_count:  218
learn step counter:  65301
dev_network_count:  218
learn step counter:  65351
dev_network_count:  218

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
219  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  65401
dev_network_count:  219
learn step counter:  65451
dev_network_count:  219
learn step counter:  65501
dev_network_count:  219
learn step counter:  65551
dev_network_count:  219
learn step counter:  65601
dev_network_count:  219
learn step counter:  65651
dev_network_count:  219

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
220  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  65701
dev_network_count:  220
EPOCH %d 69
 beam_dqn, egreed, gamma:  1 0.001 0.8424899566858419
3444 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3445 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3446 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3447 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3448 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3449 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3450 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  65751
dev_network_count:  220
learn step counter:  65801
dev_network_count:  220
learn step counter:  65851
dev_network_count:  220
learn step counter:  65901
dev_network_count:  220
learn step counter:  65951
dev_network_count:  220

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
221  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  66001
dev_network_count:  221
learn step counter:  66051
dev_network_count:  221
learn step counter:  66101
dev_network_count:  221
learn step counter:  66151
dev_network_count:  221
learn step counter:  66201
dev_network_count:  221
learn step counter:  66251
dev_network_count:  221

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
222  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  66301
dev_network_count:  222
learn step counter:  66351
dev_network_count:  222
learn step counter:  66401
dev_network_count:  222
learn step counter:  66451
dev_network_count:  222
learn step counter:  66501
dev_network_count:  222
learn step counter:  66551
dev_network_count:  222

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
223  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  66601
dev_network_count:  223
learn step counter:  66651
dev_network_count:  223
learn step counter:  66701
dev_network_count:  223
EPOCH %d 70
 beam_dqn, egreed, gamma:  1 0.001 0.841647466729156
627 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
628 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
629 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
630 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
631 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
632 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
633 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  66751
dev_network_count:  223
learn step counter:  66801
dev_network_count:  223
learn step counter:  66851
dev_network_count:  223

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
224  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  66901
dev_network_count:  224
learn step counter:  66951
dev_network_count:  224
learn step counter:  67001
dev_network_count:  224
learn step counter:  67051
dev_network_count:  224
learn step counter:  67101
dev_network_count:  224
learn step counter:  67151
dev_network_count:  224

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
225  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  67201
dev_network_count:  225
learn step counter:  67251
dev_network_count:  225
learn step counter:  67301
dev_network_count:  225
learn step counter:  67351
dev_network_count:  225
learn step counter:  67401
dev_network_count:  225
learn step counter:  67451
dev_network_count:  225

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
226  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  67501
dev_network_count:  226
learn step counter:  67551
dev_network_count:  226
learn step counter:  67601
dev_network_count:  226
learn step counter:  67651
dev_network_count:  226
learn step counter:  67701
dev_network_count:  226
EPOCH %d 71
 beam_dqn, egreed, gamma:  1 0.001 0.8408058192624269
2810 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2811 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2812 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2813 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2814 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2815 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2816 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  67751
dev_network_count:  226

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
227  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  67801
dev_network_count:  227
learn step counter:  67851
dev_network_count:  227
learn step counter:  67901
dev_network_count:  227
learn step counter:  67951
dev_network_count:  227
learn step counter:  68001
dev_network_count:  227
learn step counter:  68051
dev_network_count:  227

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
228  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  68101
dev_network_count:  228
learn step counter:  68151
dev_network_count:  228
learn step counter:  68201
dev_network_count:  228
learn step counter:  68251
dev_network_count:  228
learn step counter:  68301
dev_network_count:  228
learn step counter:  68351
dev_network_count:  228

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
229  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  68401
dev_network_count:  229
learn step counter:  68451
dev_network_count:  229
learn step counter:  68501
dev_network_count:  229
learn step counter:  68551
dev_network_count:  229
learn step counter:  68601
dev_network_count:  229
learn step counter:  68651
dev_network_count:  229

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
230  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  68701
dev_network_count:  230
EPOCH %d 72
 beam_dqn, egreed, gamma:  1 0.001 0.8399650134431644
4993 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4994 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4995 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4996 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4997 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4998 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4999 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  68751
dev_network_count:  230
learn step counter:  68801
dev_network_count:  230
learn step counter:  68851
dev_network_count:  230
learn step counter:  68901
dev_network_count:  230
learn step counter:  68951
dev_network_count:  230

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
231  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  69001
dev_network_count:  231
learn step counter:  69051
dev_network_count:  231
learn step counter:  69101
dev_network_count:  231
learn step counter:  69151
dev_network_count:  231
learn step counter:  69201
dev_network_count:  231
learn step counter:  69251
dev_network_count:  231

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
232  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  69301
dev_network_count:  232
learn step counter:  69351
dev_network_count:  232
learn step counter:  69401
dev_network_count:  232
learn step counter:  69451
dev_network_count:  232
learn step counter:  69501
dev_network_count:  232
learn step counter:  69551
dev_network_count:  232

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
233  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  69601
dev_network_count:  233
learn step counter:  69651
dev_network_count:  233
learn step counter:  69701
dev_network_count:  233
EPOCH %d 73
 beam_dqn, egreed, gamma:  1 0.001 0.8391250484297214
2176 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2177 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2178 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2179 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2180 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2181 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2182 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  69751
dev_network_count:  233
learn step counter:  69801
dev_network_count:  233
learn step counter:  69851
dev_network_count:  233

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
234  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  69901
dev_network_count:  234
learn step counter:  69951
dev_network_count:  234
learn step counter:  70001
dev_network_count:  234
learn step counter:  70051
dev_network_count:  234
learn step counter:  70101
dev_network_count:  234
learn step counter:  70151
dev_network_count:  234

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
235  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  70201
dev_network_count:  235
learn step counter:  70251
dev_network_count:  235
learn step counter:  70301
dev_network_count:  235
learn step counter:  70351
dev_network_count:  235
learn step counter:  70401
dev_network_count:  235
learn step counter:  70451
dev_network_count:  235

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
236  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  70501
dev_network_count:  236
learn step counter:  70551
dev_network_count:  236
learn step counter:  70601
dev_network_count:  236
learn step counter:  70651
dev_network_count:  236
learn step counter:  70701
dev_network_count:  236
EPOCH %d 74
 beam_dqn, egreed, gamma:  1 0.001 0.8382859233812916
4359 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4360 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4361 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4362 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4363 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4364 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4365 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  70751
dev_network_count:  236

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
237  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  70801
dev_network_count:  237
learn step counter:  70851
dev_network_count:  237
learn step counter:  70901
dev_network_count:  237
learn step counter:  70951
dev_network_count:  237
learn step counter:  71001
dev_network_count:  237
learn step counter:  71051
dev_network_count:  237

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
238  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  71101
dev_network_count:  238
learn step counter:  71151
dev_network_count:  238
learn step counter:  71201
dev_network_count:  238
learn step counter:  71251
dev_network_count:  238
learn step counter:  71301
dev_network_count:  238
learn step counter:  71351
dev_network_count:  238

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
239  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  71401
dev_network_count:  239
learn step counter:  71451
dev_network_count:  239
learn step counter:  71501
dev_network_count:  239
learn step counter:  71551
dev_network_count:  239
learn step counter:  71601
dev_network_count:  239
learn step counter:  71651
dev_network_count:  239

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
240  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  71701
dev_network_count:  240
EPOCH %d 75
 beam_dqn, egreed, gamma:  1 0.001 0.8374476374579103
1542 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1543 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1544 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1545 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1546 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1547 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1548 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  71751
dev_network_count:  240
learn step counter:  71801
dev_network_count:  240
learn step counter:  71851
dev_network_count:  240
learn step counter:  71901
dev_network_count:  240
learn step counter:  71951
dev_network_count:  240

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
241  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  72001
dev_network_count:  241
learn step counter:  72051
dev_network_count:  241
learn step counter:  72101
dev_network_count:  241
learn step counter:  72151
dev_network_count:  241
learn step counter:  72201
dev_network_count:  241
learn step counter:  72251
dev_network_count:  241

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
242  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  72301
dev_network_count:  242
learn step counter:  72351
dev_network_count:  242
learn step counter:  72401
dev_network_count:  242
learn step counter:  72451
dev_network_count:  242
learn step counter:  72501
dev_network_count:  242
learn step counter:  72551
dev_network_count:  242

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
243  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  72601
dev_network_count:  243
learn step counter:  72651
dev_network_count:  243
learn step counter:  72701
dev_network_count:  243
EPOCH %d 76
 beam_dqn, egreed, gamma:  1 0.001 0.8366101898204523
3725 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3726 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3727 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3728 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3729 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3730 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3731 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  72751
dev_network_count:  243
learn step counter:  72801
dev_network_count:  243
learn step counter:  72851
dev_network_count:  243

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
244  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  72901
dev_network_count:  244
learn step counter:  72951
dev_network_count:  244
learn step counter:  73001
dev_network_count:  244
learn step counter:  73051
dev_network_count:  244
learn step counter:  73101
dev_network_count:  244
learn step counter:  73151
dev_network_count:  244

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
245  r_total and score:  56.35 0.0
Current Bleu score is:  0.0
learn step counter:  73201
dev_network_count:  245
learn step counter:  73251
dev_network_count:  245
learn step counter:  73301
dev_network_count:  245
learn step counter:  73351
dev_network_count:  245
learn step counter:  73401
dev_network_count:  245
learn step counter:  73451
dev_network_count:  245

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
246  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  73501
dev_network_count:  246
learn step counter:  73551
dev_network_count:  246
learn step counter:  73601
dev_network_count:  246
learn step counter:  73651
dev_network_count:  246
learn step counter:  73701
dev_network_count:  246
EPOCH %d 77
 beam_dqn, egreed, gamma:  1 0.001 0.8357735796306319
908 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
909 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
910 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
911 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
912 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
913 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
914 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  73751
dev_network_count:  246

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
247  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  73801
dev_network_count:  247
learn step counter:  73851
dev_network_count:  247
learn step counter:  73901
dev_network_count:  247
learn step counter:  73951
dev_network_count:  247
learn step counter:  74001
dev_network_count:  247
learn step counter:  74051
dev_network_count:  247

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
248  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  74101
dev_network_count:  248
learn step counter:  74151
dev_network_count:  248
learn step counter:  74201
dev_network_count:  248
learn step counter:  74251
dev_network_count:  248
learn step counter:  74301
dev_network_count:  248
learn step counter:  74351
dev_network_count:  248

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
249  r_total and score:  53.85 0.0
Current Bleu score is:  0.0
learn step counter:  74401
dev_network_count:  249
learn step counter:  74451
dev_network_count:  249
learn step counter:  74501
dev_network_count:  249
learn step counter:  74551
dev_network_count:  249
learn step counter:  74601
dev_network_count:  249
learn step counter:  74651
dev_network_count:  249

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
250  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  74701
dev_network_count:  250
EPOCH %d 78
 beam_dqn, egreed, gamma:  1 0.001 0.8349378060510013
3091 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3092 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3093 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3094 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3095 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3096 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3097 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  74751
dev_network_count:  250
learn step counter:  74801
dev_network_count:  250
learn step counter:  74851
dev_network_count:  250
learn step counter:  74901
dev_network_count:  250
learn step counter:  74951
dev_network_count:  250

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
251  r_total and score:  57.449999999999996 0.0
Current Bleu score is:  0.0
learn step counter:  75001
dev_network_count:  251
learn step counter:  75051
dev_network_count:  251
learn step counter:  75101
dev_network_count:  251
learn step counter:  75151
dev_network_count:  251
learn step counter:  75201
dev_network_count:  251
learn step counter:  75251
dev_network_count:  251

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
252  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  75301
dev_network_count:  252
learn step counter:  75351
dev_network_count:  252
learn step counter:  75401
dev_network_count:  252
learn step counter:  75451
dev_network_count:  252
learn step counter:  75501
dev_network_count:  252
learn step counter:  75551
dev_network_count:  252

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
253  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  75601
dev_network_count:  253
learn step counter:  75651
dev_network_count:  253
learn step counter:  75701
dev_network_count:  253
EPOCH %d 79
 beam_dqn, egreed, gamma:  1 0.001 0.8341028682449503
274 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
275 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
276 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
277 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
278 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
279 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
280 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  75751
dev_network_count:  253
learn step counter:  75801
dev_network_count:  253
learn step counter:  75851
dev_network_count:  253

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
254  r_total and score:  56.35 0.0
Current Bleu score is:  0.0
learn step counter:  75901
dev_network_count:  254
learn step counter:  75951
dev_network_count:  254
learn step counter:  76001
dev_network_count:  254
learn step counter:  76051
dev_network_count:  254
learn step counter:  76101
dev_network_count:  254
learn step counter:  76151
dev_network_count:  254

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
255  r_total and score:  56.35 0.0
Current Bleu score is:  0.0
learn step counter:  76201
dev_network_count:  255
learn step counter:  76251
dev_network_count:  255
learn step counter:  76301
dev_network_count:  255
learn step counter:  76351
dev_network_count:  255
learn step counter:  76401
dev_network_count:  255
learn step counter:  76451
dev_network_count:  255

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
256  r_total and score:  56.35 0.0
Current Bleu score is:  0.0
learn step counter:  76501
dev_network_count:  256
learn step counter:  76551
dev_network_count:  256
learn step counter:  76601
dev_network_count:  256
learn step counter:  76651
dev_network_count:  256
learn step counter:  76701
dev_network_count:  256
EPOCH %d 80
 beam_dqn, egreed, gamma:  1 0.001 0.8332687653767054
2457 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2458 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2459 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2460 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2461 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2462 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2463 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  76751
dev_network_count:  256

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
257  r_total and score:  56.35 0.0
Current Bleu score is:  0.0
learn step counter:  76801
dev_network_count:  257
learn step counter:  76851
dev_network_count:  257
learn step counter:  76901
dev_network_count:  257
learn step counter:  76951
dev_network_count:  257
learn step counter:  77001
dev_network_count:  257
learn step counter:  77051
dev_network_count:  257

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
258  r_total and score:  56.35 0.0
Current Bleu score is:  0.0
learn step counter:  77101
dev_network_count:  258
learn step counter:  77151
dev_network_count:  258
learn step counter:  77201
dev_network_count:  258
learn step counter:  77251
dev_network_count:  258
learn step counter:  77301
dev_network_count:  258
learn step counter:  77351
dev_network_count:  258

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
259  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  77401
dev_network_count:  259
learn step counter:  77451
dev_network_count:  259
learn step counter:  77501
dev_network_count:  259
learn step counter:  77551
dev_network_count:  259
learn step counter:  77601
dev_network_count:  259
learn step counter:  77651
dev_network_count:  259

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
260  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  77701
dev_network_count:  260
EPOCH %d 81
 beam_dqn, egreed, gamma:  1 0.001 0.8324354966113285
4640 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4641 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4642 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4643 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4644 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4645 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4646 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  77751
dev_network_count:  260
learn step counter:  77801
dev_network_count:  260
learn step counter:  77851
dev_network_count:  260
learn step counter:  77901
dev_network_count:  260
learn step counter:  77951
dev_network_count:  260

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
261  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  78001
dev_network_count:  261
learn step counter:  78051
dev_network_count:  261
learn step counter:  78101
dev_network_count:  261
learn step counter:  78151
dev_network_count:  261
learn step counter:  78201
dev_network_count:  261
learn step counter:  78251
dev_network_count:  261

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
262  r_total and score:  56.35 0.0
Current Bleu score is:  0.0
learn step counter:  78301
dev_network_count:  262
learn step counter:  78351
dev_network_count:  262
learn step counter:  78401
dev_network_count:  262
learn step counter:  78451
dev_network_count:  262
learn step counter:  78501
dev_network_count:  262
learn step counter:  78551
dev_network_count:  262

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
263  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  78601
dev_network_count:  263
learn step counter:  78651
dev_network_count:  263
learn step counter:  78701
dev_network_count:  263
EPOCH %d 82
 beam_dqn, egreed, gamma:  1 0.001 0.8316030611147173
1823 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1824 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1825 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1826 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1827 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1828 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1829 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  78751
dev_network_count:  263
learn step counter:  78801
dev_network_count:  263
learn step counter:  78851
dev_network_count:  263

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
264  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  78901
dev_network_count:  264
learn step counter:  78951
dev_network_count:  264
learn step counter:  79001
dev_network_count:  264
learn step counter:  79051
dev_network_count:  264
learn step counter:  79101
dev_network_count:  264
learn step counter:  79151
dev_network_count:  264

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
265  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  79201
dev_network_count:  265
learn step counter:  79251
dev_network_count:  265
learn step counter:  79301
dev_network_count:  265
learn step counter:  79351
dev_network_count:  265
learn step counter:  79401
dev_network_count:  265
learn step counter:  79451
dev_network_count:  265

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
266  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  79501
dev_network_count:  266
learn step counter:  79551
dev_network_count:  266
learn step counter:  79601
dev_network_count:  266
learn step counter:  79651
dev_network_count:  266
learn step counter:  79701
dev_network_count:  266
EPOCH %d 83
 beam_dqn, egreed, gamma:  1 0.001 0.8307714580536025
4006 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4007 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4008 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4009 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4010 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4011 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4012 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  79751
dev_network_count:  266

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
267  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  79801
dev_network_count:  267
learn step counter:  79851
dev_network_count:  267
learn step counter:  79901
dev_network_count:  267
learn step counter:  79951
dev_network_count:  267
learn step counter:  80001
dev_network_count:  267
learn step counter:  80051
dev_network_count:  267

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
268  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  80101
dev_network_count:  268
learn step counter:  80151
dev_network_count:  268
learn step counter:  80201
dev_network_count:  268
learn step counter:  80251
dev_network_count:  268
learn step counter:  80301
dev_network_count:  268
learn step counter:  80351
dev_network_count:  268

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
269  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  80401
dev_network_count:  269
learn step counter:  80451
dev_network_count:  269
learn step counter:  80501
dev_network_count:  269
learn step counter:  80551
dev_network_count:  269
learn step counter:  80601
dev_network_count:  269
learn step counter:  80651
dev_network_count:  269

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
270  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  80701
dev_network_count:  270
EPOCH %d 84
 beam_dqn, egreed, gamma:  1 0.001 0.829940686595549
1189 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1190 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1191 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1192 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1193 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1194 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1195 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  80751
dev_network_count:  270
learn step counter:  80801
dev_network_count:  270
learn step counter:  80851
dev_network_count:  270
learn step counter:  80901
dev_network_count:  270
learn step counter:  80951
dev_network_count:  270

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
271  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  81001
dev_network_count:  271
learn step counter:  81051
dev_network_count:  271
learn step counter:  81101
dev_network_count:  271
learn step counter:  81151
dev_network_count:  271
learn step counter:  81201
dev_network_count:  271
learn step counter:  81251
dev_network_count:  271

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
272  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  81301
dev_network_count:  272
learn step counter:  81351
dev_network_count:  272
learn step counter:  81401
dev_network_count:  272
learn step counter:  81451
dev_network_count:  272
learn step counter:  81501
dev_network_count:  272
learn step counter:  81551
dev_network_count:  272

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
273  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  81601
dev_network_count:  273
learn step counter:  81651
dev_network_count:  273
learn step counter:  81701
dev_network_count:  273
EPOCH %d 85
 beam_dqn, egreed, gamma:  1 0.001 0.8291107459089534
3372 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3373 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3374 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3375 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3376 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3377 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3378 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  81751
dev_network_count:  273
learn step counter:  81801
dev_network_count:  273
learn step counter:  81851
dev_network_count:  273

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
274  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  81901
dev_network_count:  274
learn step counter:  81951
dev_network_count:  274
learn step counter:  82001
dev_network_count:  274
learn step counter:  82051
dev_network_count:  274
learn step counter:  82101
dev_network_count:  274
learn step counter:  82151
dev_network_count:  274

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
275  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  82201
dev_network_count:  275
learn step counter:  82251
dev_network_count:  275
learn step counter:  82301
dev_network_count:  275
learn step counter:  82351
dev_network_count:  275
learn step counter:  82401
dev_network_count:  275
learn step counter:  82451
dev_network_count:  275

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
276  r_total and score:  57.25000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  82501
dev_network_count:  276
learn step counter:  82551
dev_network_count:  276
learn step counter:  82601
dev_network_count:  276
learn step counter:  82651
dev_network_count:  276
learn step counter:  82701
dev_network_count:  276
EPOCH %d 86
 beam_dqn, egreed, gamma:  1 0.001 0.8282816351630444
555 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
556 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
557 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
558 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
559 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
560 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
561 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  82751
dev_network_count:  276

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
277  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  82801
dev_network_count:  277
learn step counter:  82851
dev_network_count:  277
learn step counter:  82901
dev_network_count:  277
learn step counter:  82951
dev_network_count:  277
learn step counter:  83001
dev_network_count:  277
learn step counter:  83051
dev_network_count:  277

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 3 3 3 3 3 3 3', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 3 3 3 3 3 3 3', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
278  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  83101
dev_network_count:  278
learn step counter:  83151
dev_network_count:  278
learn step counter:  83201
dev_network_count:  278
learn step counter:  83251
dev_network_count:  278
learn step counter:  83301
dev_network_count:  278
learn step counter:  83351
dev_network_count:  278

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
279  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  83401
dev_network_count:  279
learn step counter:  83451
dev_network_count:  279
learn step counter:  83501
dev_network_count:  279
learn step counter:  83551
dev_network_count:  279
learn step counter:  83601
dev_network_count:  279
learn step counter:  83651
dev_network_count:  279

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
280  r_total and score:  56.35 0.0
Current Bleu score is:  0.0
learn step counter:  83701
dev_network_count:  280
EPOCH %d 87
 beam_dqn, egreed, gamma:  1 0.001 0.8274533535278814
2738 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2739 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2740 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2741 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2742 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2743 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2744 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  83751
dev_network_count:  280
learn step counter:  83801
dev_network_count:  280
learn step counter:  83851
dev_network_count:  280
learn step counter:  83901
dev_network_count:  280
learn step counter:  83951
dev_network_count:  280

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
281  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  84001
dev_network_count:  281
learn step counter:  84051
dev_network_count:  281
learn step counter:  84101
dev_network_count:  281
learn step counter:  84151
dev_network_count:  281
learn step counter:  84201
dev_network_count:  281
learn step counter:  84251
dev_network_count:  281

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9860,  0.9705, -0.8829])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9873,  0.9702, -0.9107])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
282  r_total and score:  57.25000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  84301
dev_network_count:  282
learn step counter:  84351
dev_network_count:  282
learn step counter:  84401
dev_network_count:  282
learn step counter:  84451
dev_network_count:  282
learn step counter:  84501
dev_network_count:  282
learn step counter:  84551
dev_network_count:  282

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
283  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  84601
dev_network_count:  283
learn step counter:  84651
dev_network_count:  283
learn step counter:  84701
dev_network_count:  283
EPOCH %d 88
 beam_dqn, egreed, gamma:  1 0.001 0.8266259001743534
4921 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4922 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4923 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4924 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4925 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4926 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4927 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  84751
dev_network_count:  283
learn step counter:  84801
dev_network_count:  283
learn step counter:  84851
dev_network_count:  283

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
284  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  84901
dev_network_count:  284
learn step counter:  84951
dev_network_count:  284
learn step counter:  85001
dev_network_count:  284
learn step counter:  85051
dev_network_count:  284
learn step counter:  85101
dev_network_count:  284
learn step counter:  85151
dev_network_count:  284

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
285  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  85201
dev_network_count:  285
learn step counter:  85251
dev_network_count:  285
learn step counter:  85301
dev_network_count:  285
learn step counter:  85351
dev_network_count:  285
learn step counter:  85401
dev_network_count:  285
learn step counter:  85451
dev_network_count:  285

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
286  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  85501
dev_network_count:  286
learn step counter:  85551
dev_network_count:  286
learn step counter:  85601
dev_network_count:  286
learn step counter:  85651
dev_network_count:  286
learn step counter:  85701
dev_network_count:  286
EPOCH %d 89
 beam_dqn, egreed, gamma:  1 0.001 0.8257992742741792
2104 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2105 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2106 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2107 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2108 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2109 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2110 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  85751
dev_network_count:  286

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
287  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  85801
dev_network_count:  287
learn step counter:  85851
dev_network_count:  287
learn step counter:  85901
dev_network_count:  287
learn step counter:  85951
dev_network_count:  287
learn step counter:  86001
dev_network_count:  287
learn step counter:  86051
dev_network_count:  287

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
288  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  86101
dev_network_count:  288
learn step counter:  86151
dev_network_count:  288
learn step counter:  86201
dev_network_count:  288
learn step counter:  86251
dev_network_count:  288
learn step counter:  86301
dev_network_count:  288
learn step counter:  86351
dev_network_count:  288

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
289  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  86401
dev_network_count:  289
learn step counter:  86451
dev_network_count:  289
learn step counter:  86501
dev_network_count:  289
learn step counter:  86551
dev_network_count:  289
learn step counter:  86601
dev_network_count:  289
learn step counter:  86651
dev_network_count:  289

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
290  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  86701
dev_network_count:  290
EPOCH %d 90
 beam_dqn, egreed, gamma:  1 0.001 0.824973474999905
4287 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4288 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4289 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4290 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4291 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4292 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4293 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  86751
dev_network_count:  290
learn step counter:  86801
dev_network_count:  290
learn step counter:  86851
dev_network_count:  290
learn step counter:  86901
dev_network_count:  290
learn step counter:  86951
dev_network_count:  290

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
291  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  87001
dev_network_count:  291
learn step counter:  87051
dev_network_count:  291
learn step counter:  87101
dev_network_count:  291
learn step counter:  87151
dev_network_count:  291
learn step counter:  87201
dev_network_count:  291
learn step counter:  87251
dev_network_count:  291

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
292  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  87301
dev_network_count:  292
learn step counter:  87351
dev_network_count:  292
learn step counter:  87401
dev_network_count:  292
learn step counter:  87451
dev_network_count:  292
learn step counter:  87501
dev_network_count:  292
learn step counter:  87551
dev_network_count:  292

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.7346,  0.9592,  0.2728])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9696,  0.9716, -0.6869])
So far:  [array([2]), array([4]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9715, -0.8858])
So far:  [array([2]), array([4]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9121])
So far:  [array([2]), array([4]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9876,  0.9710, -0.9182])
So far:  [array([2]), array([4]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9202])
So far:  [array([2]), array([4]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9210])
So far:  [array([2]), array([4]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([4]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
293  r_total and score:  53.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  87601
dev_network_count:  293
learn step counter:  87651
dev_network_count:  293
learn step counter:  87701
dev_network_count:  293
EPOCH %d 91
 beam_dqn, egreed, gamma:  1 0.001 0.8241485015249052
1470 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1471 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1472 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1473 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1474 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1475 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1476 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  87751
dev_network_count:  293
learn step counter:  87801
dev_network_count:  293
learn step counter:  87851
dev_network_count:  293

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
294  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  87901
dev_network_count:  294
learn step counter:  87951
dev_network_count:  294
learn step counter:  88001
dev_network_count:  294
learn step counter:  88051
dev_network_count:  294
learn step counter:  88101
dev_network_count:  294
learn step counter:  88151
dev_network_count:  294

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
295  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  88201
dev_network_count:  295
learn step counter:  88251
dev_network_count:  295
learn step counter:  88301
dev_network_count:  295
learn step counter:  88351
dev_network_count:  295
learn step counter:  88401
dev_network_count:  295
learn step counter:  88451
dev_network_count:  295

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
296  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  88501
dev_network_count:  296
learn step counter:  88551
dev_network_count:  296
learn step counter:  88601
dev_network_count:  296
learn step counter:  88651
dev_network_count:  296
learn step counter:  88701
dev_network_count:  296
EPOCH %d 92
 beam_dqn, egreed, gamma:  1 0.001 0.8233243530233803
3653 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3654 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3655 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3656 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3657 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3658 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3659 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  88751
dev_network_count:  296

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
297  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  88801
dev_network_count:  297
learn step counter:  88851
dev_network_count:  297
learn step counter:  88901
dev_network_count:  297
learn step counter:  88951
dev_network_count:  297
learn step counter:  89001
dev_network_count:  297
learn step counter:  89051
dev_network_count:  297

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
298  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  89101
dev_network_count:  298
learn step counter:  89151
dev_network_count:  298
learn step counter:  89201
dev_network_count:  298
learn step counter:  89251
dev_network_count:  298
learn step counter:  89301
dev_network_count:  298
learn step counter:  89351
dev_network_count:  298

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
299  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  89401
dev_network_count:  299
learn step counter:  89451
dev_network_count:  299
learn step counter:  89501
dev_network_count:  299
learn step counter:  89551
dev_network_count:  299
learn step counter:  89601
dev_network_count:  299
learn step counter:  89651
dev_network_count:  299

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
300  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  89701
dev_network_count:  300
EPOCH %d 93
 beam_dqn, egreed, gamma:  1 0.001 0.8225010286703568
836 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
837 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
838 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
839 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
840 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
841 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
842 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  89751
dev_network_count:  300
learn step counter:  89801
dev_network_count:  300
learn step counter:  89851
dev_network_count:  300
learn step counter:  89901
dev_network_count:  300
learn step counter:  89951
dev_network_count:  300

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
301  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  90001
dev_network_count:  301
learn step counter:  90051
dev_network_count:  301
learn step counter:  90101
dev_network_count:  301
learn step counter:  90151
dev_network_count:  301
learn step counter:  90201
dev_network_count:  301
learn step counter:  90251
dev_network_count:  301

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([7])]  the state[:3] is:  tensor([-0.9707,  0.9703, -0.6776])
So far:  [array([2]), array([5]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9713, -0.8840])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9115])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
302  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  90301
dev_network_count:  302
learn step counter:  90351
dev_network_count:  302
learn step counter:  90401
dev_network_count:  302
learn step counter:  90451
dev_network_count:  302
learn step counter:  90501
dev_network_count:  302
learn step counter:  90551
dev_network_count:  302

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.7346,  0.9592,  0.2728])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9696,  0.9716, -0.6869])
So far:  [array([2]), array([4]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9862,  0.9715, -0.8858])
So far:  [array([2]), array([4]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9713, -0.9121])
So far:  [array([2]), array([4]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9876,  0.9710, -0.9182])
So far:  [array([2]), array([4]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9202])
So far:  [array([2]), array([4]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9210])
So far:  [array([2]), array([4]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([4]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 3 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
303  r_total and score:  54.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  90601
dev_network_count:  303
learn step counter:  90651
dev_network_count:  303
learn step counter:  90701
dev_network_count:  303
EPOCH %d 94
 beam_dqn, egreed, gamma:  1 0.001 0.8216785276416865
3019 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3020 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3021 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3022 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3023 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3024 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3025 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  90751
dev_network_count:  303
learn step counter:  90801
dev_network_count:  303
learn step counter:  90851
dev_network_count:  303

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
304  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  90901
dev_network_count:  304
learn step counter:  90951
dev_network_count:  304
learn step counter:  91001
dev_network_count:  304
learn step counter:  91051
dev_network_count:  304
learn step counter:  91101
dev_network_count:  304
learn step counter:  91151
dev_network_count:  304

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
305  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  91201
dev_network_count:  305
learn step counter:  91251
dev_network_count:  305
learn step counter:  91301
dev_network_count:  305
learn step counter:  91351
dev_network_count:  305
learn step counter:  91401
dev_network_count:  305
learn step counter:  91451
dev_network_count:  305

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
306  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  91501
dev_network_count:  306
learn step counter:  91551
dev_network_count:  306
learn step counter:  91601
dev_network_count:  306
learn step counter:  91651
dev_network_count:  306
learn step counter:  91701
dev_network_count:  306
EPOCH %d 95
 beam_dqn, egreed, gamma:  1 0.001 0.8208568491140448
202 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
203 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
204 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
205 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
206 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
207 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
208 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  91751
dev_network_count:  306

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
307  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  91801
dev_network_count:  307
learn step counter:  91851
dev_network_count:  307
learn step counter:  91901
dev_network_count:  307
learn step counter:  91951
dev_network_count:  307
learn step counter:  92001
dev_network_count:  307
learn step counter:  92051
dev_network_count:  307

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
308  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  92101
dev_network_count:  308
learn step counter:  92151
dev_network_count:  308
learn step counter:  92201
dev_network_count:  308
learn step counter:  92251
dev_network_count:  308
learn step counter:  92301
dev_network_count:  308
learn step counter:  92351
dev_network_count:  308

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
309  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  92401
dev_network_count:  309
learn step counter:  92451
dev_network_count:  309
learn step counter:  92501
dev_network_count:  309
learn step counter:  92551
dev_network_count:  309
learn step counter:  92601
dev_network_count:  309
learn step counter:  92651
dev_network_count:  309

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
310  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  92701
dev_network_count:  310
EPOCH %d 96
 beam_dqn, egreed, gamma:  1 0.001 0.8200359922649307
2385 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2386 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2387 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2388 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2389 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2390 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2391 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  92751
dev_network_count:  310
learn step counter:  92801
dev_network_count:  310
learn step counter:  92851
dev_network_count:  310
learn step counter:  92901
dev_network_count:  310
learn step counter:  92951
dev_network_count:  310

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
311  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  93001
dev_network_count:  311
learn step counter:  93051
dev_network_count:  311
learn step counter:  93101
dev_network_count:  311
learn step counter:  93151
dev_network_count:  311
learn step counter:  93201
dev_network_count:  311
learn step counter:  93251
dev_network_count:  311

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
312  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  93301
dev_network_count:  312
learn step counter:  93351
dev_network_count:  312
learn step counter:  93401
dev_network_count:  312
learn step counter:  93451
dev_network_count:  312
learn step counter:  93501
dev_network_count:  312
learn step counter:  93551
dev_network_count:  312

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
313  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  93601
dev_network_count:  313
learn step counter:  93651
dev_network_count:  313
learn step counter:  93701
dev_network_count:  313
EPOCH %d 97
 beam_dqn, egreed, gamma:  1 0.001 0.8192159562726659
4568 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4569 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4570 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4571 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4572 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4573 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4574 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  93751
dev_network_count:  313
learn step counter:  93801
dev_network_count:  313
learn step counter:  93851
dev_network_count:  313

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
314  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  93901
dev_network_count:  314
learn step counter:  93951
dev_network_count:  314
learn step counter:  94001
dev_network_count:  314
learn step counter:  94051
dev_network_count:  314
learn step counter:  94101
dev_network_count:  314
learn step counter:  94151
dev_network_count:  314

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
315  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  94201
dev_network_count:  315
learn step counter:  94251
dev_network_count:  315
learn step counter:  94301
dev_network_count:  315
learn step counter:  94351
dev_network_count:  315
learn step counter:  94401
dev_network_count:  315
learn step counter:  94451
dev_network_count:  315

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
316  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  94501
dev_network_count:  316
learn step counter:  94551
dev_network_count:  316
learn step counter:  94601
dev_network_count:  316
learn step counter:  94651
dev_network_count:  316
learn step counter:  94701
dev_network_count:  316
EPOCH %d 98
 beam_dqn, egreed, gamma:  1 0.001 0.8183967403163932
1751 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1752 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1753 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1754 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1755 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1756 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1757 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  94751
dev_network_count:  316

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
317  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  94801
dev_network_count:  317
learn step counter:  94851
dev_network_count:  317
learn step counter:  94901
dev_network_count:  317
learn step counter:  94951
dev_network_count:  317
learn step counter:  95001
dev_network_count:  317
learn step counter:  95051
dev_network_count:  317

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
318  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  95101
dev_network_count:  318
learn step counter:  95151
dev_network_count:  318
learn step counter:  95201
dev_network_count:  318
learn step counter:  95251
dev_network_count:  318
learn step counter:  95301
dev_network_count:  318
learn step counter:  95351
dev_network_count:  318

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
319  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  95401
dev_network_count:  319
learn step counter:  95451
dev_network_count:  319
learn step counter:  95501
dev_network_count:  319
learn step counter:  95551
dev_network_count:  319
learn step counter:  95601
dev_network_count:  319
learn step counter:  95651
dev_network_count:  319

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
320  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  95701
dev_network_count:  320
EPOCH %d 99
 beam_dqn, egreed, gamma:  1 0.001 0.8175783435760767
3934 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3935 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3936 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3937 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3938 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3939 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3940 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  95751
dev_network_count:  320
learn step counter:  95801
dev_network_count:  320
learn step counter:  95851
dev_network_count:  320
learn step counter:  95901
dev_network_count:  320
learn step counter:  95951
dev_network_count:  320

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
321  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  96001
dev_network_count:  321
learn step counter:  96051
dev_network_count:  321
learn step counter:  96101
dev_network_count:  321
learn step counter:  96151
dev_network_count:  321
learn step counter:  96201
dev_network_count:  321
learn step counter:  96251
dev_network_count:  321

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.7346,  0.9592,  0.2728])
So far:  [array([2]), array([4]), array([5])]  the state[:3] is:  tensor([-0.9743,  0.9669, -0.6933])
So far:  [array([2]), array([4]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9710, -0.8859])
So far:  [array([2]), array([4]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9876,  0.9711, -0.9119])
So far:  [array([2]), array([4]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9876,  0.9709, -0.9181])
So far:  [array([2]), array([4]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9708, -0.9201])
So far:  [array([2]), array([4]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9210])
So far:  [array([2]), array([4]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([4]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 4 5 4 4 4 4 4 4 4 4]]
Reward:  [ 1.          0.9        -1.25       -0.925      -0.8625     -0.93125
 -1.065625   -1.2328125  -1.41640625 -1.8       ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 0 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
322  r_total and score:  54.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  96301
dev_network_count:  322
learn step counter:  96351
dev_network_count:  322
learn step counter:  96401
dev_network_count:  322
learn step counter:  96451
dev_network_count:  322
learn step counter:  96501
dev_network_count:  322
learn step counter:  96551
dev_network_count:  322

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
323  r_total and score:  50.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  96601
dev_network_count:  323
learn step counter:  96651
dev_network_count:  323
learn step counter:  96701
dev_network_count:  323
EPOCH %d 100
 beam_dqn, egreed, gamma:  1 0.001 0.8167607652325006
1117 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1118 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1119 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1120 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1121 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1122 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1123 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  96751
dev_network_count:  323
learn step counter:  96801
dev_network_count:  323
learn step counter:  96851
dev_network_count:  323

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 1 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
324  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  96901
dev_network_count:  324
learn step counter:  96951
dev_network_count:  324
learn step counter:  97001
dev_network_count:  324
learn step counter:  97051
dev_network_count:  324
learn step counter:  97101
dev_network_count:  324
learn step counter:  97151
dev_network_count:  324

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9862,  0.9704, -0.8840])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9874,  0.9701, -0.9108])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 1 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 1 1 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
325  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  97201
dev_network_count:  325
learn step counter:  97251
dev_network_count:  325
learn step counter:  97301
dev_network_count:  325
learn step counter:  97351
dev_network_count:  325
learn step counter:  97401
dev_network_count:  325
learn step counter:  97451
dev_network_count:  325

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9862,  0.9704, -0.8840])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9874,  0.9701, -0.9108])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 1 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
326  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  97501
dev_network_count:  326
learn step counter:  97551
dev_network_count:  326
learn step counter:  97601
dev_network_count:  326
learn step counter:  97651
dev_network_count:  326
learn step counter:  97701
dev_network_count:  326
EPOCH %d 101
 beam_dqn, egreed, gamma:  1 0.001 0.8159440044672681
3300 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
3301 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
3302 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
3303 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
3304 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
3305 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
3306 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  97751
dev_network_count:  326

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9862,  0.9704, -0.8840])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9874,  0.9701, -0.9108])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 1 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
327  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  97801
dev_network_count:  327
learn step counter:  97851
dev_network_count:  327
learn step counter:  97901
dev_network_count:  327
learn step counter:  97951
dev_network_count:  327
learn step counter:  98001
dev_network_count:  327
learn step counter:  98051
dev_network_count:  327

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
328  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  98101
dev_network_count:  328
learn step counter:  98151
dev_network_count:  328
learn step counter:  98201
dev_network_count:  328
learn step counter:  98251
dev_network_count:  328
learn step counter:  98301
dev_network_count:  328
learn step counter:  98351
dev_network_count:  328

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
329  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  98401
dev_network_count:  329
learn step counter:  98451
dev_network_count:  329
learn step counter:  98501
dev_network_count:  329
learn step counter:  98551
dev_network_count:  329
learn step counter:  98601
dev_network_count:  329
learn step counter:  98651
dev_network_count:  329

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
330  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  98701
dev_network_count:  330
EPOCH %d 102
 beam_dqn, egreed, gamma:  1 0.001 0.815128060462801
483 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
484 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
485 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
486 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
487 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
488 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
489 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  98751
dev_network_count:  330
learn step counter:  98801
dev_network_count:  330
learn step counter:  98851
dev_network_count:  330
learn step counter:  98901
dev_network_count:  330
learn step counter:  98951
dev_network_count:  330

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9666,  0.7398, -0.9257])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9663,  0.7491, -0.9300])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9658,  0.7526, -0.9312])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9656,  0.7544, -0.9316])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9654,  0.7554, -0.9317])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9653,  0.7560, -0.9318])
So far:  [array([2]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9652,  0.7563, -0.9318])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9776,  0.8473, -0.9230])
So far:  [array([2]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9770,  0.8688, -0.9507])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9761,  0.8722, -0.9554])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9752,  0.8738, -0.9565])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9747,  0.8748, -0.9569])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9744,  0.8753, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9742,  0.8756, -0.9570])
So far:  [array([2]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9741,  0.8758, -0.9571])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9862,  0.9704, -0.8840])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9874,  0.9701, -0.9108])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9698, -0.9171])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9697, -0.9191])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9199])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9696, -0.9202])
So far:  [array([2]), array([5]), array([4]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9875,  0.9695, -0.9204])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 7 7 7 7 7 7 7 7]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 7 7 7 7 7 7 7]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 3 3 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 1 3 3 3 3 3 3 3 3', '4 3 3 1 3 3 3 3 3 3', '1 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '4 3 1 1 1 1 1 1 1 1', '3 3 3 3 3 3 3 3 3 3', '0 3 3 3 3 3 3 3 3 3', '3 3 3 3 3 3 3 3 3 3']
331  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  99001
dev_network_count:  331
learn step counter:  99051
dev_network_count:  331
learn step counter:  99101
dev_network_count:  331
learn step counter:  99151
dev_network_count:  331
learn step counter:  99201
dev_network_count:  331
learn step counter:  99251
dev_network_count:  331

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
332  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  99301
dev_network_count:  332
learn step counter:  99351
dev_network_count:  332
learn step counter:  99401
dev_network_count:  332
learn step counter:  99451
dev_network_count:  332
learn step counter:  99501
dev_network_count:  332
learn step counter:  99551
dev_network_count:  332

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
333  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  99601
dev_network_count:  333
learn step counter:  99651
dev_network_count:  333
learn step counter:  99701
dev_network_count:  333
EPOCH %d 103
 beam_dqn, egreed, gamma:  1 0.001 0.814312932402338
2666 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2667 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2668 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2669 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2670 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2671 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2672 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  99751
dev_network_count:  333
learn step counter:  99801
dev_network_count:  333
learn step counter:  99851
dev_network_count:  333

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
334  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  99901
dev_network_count:  334
learn step counter:  99951
dev_network_count:  334
learn step counter:  100001
dev_network_count:  334
learn step counter:  100051
dev_network_count:  334
learn step counter:  100101
dev_network_count:  334
learn step counter:  100151
dev_network_count:  334

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
335  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  100201
dev_network_count:  335
learn step counter:  100251
dev_network_count:  335
learn step counter:  100301
dev_network_count:  335
learn step counter:  100351
dev_network_count:  335
learn step counter:  100401
dev_network_count:  335
learn step counter:  100451
dev_network_count:  335

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
336  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  100501
dev_network_count:  336
learn step counter:  100551
dev_network_count:  336
learn step counter:  100601
dev_network_count:  336
learn step counter:  100651
dev_network_count:  336
learn step counter:  100701
dev_network_count:  336
EPOCH %d 104
 beam_dqn, egreed, gamma:  1 0.001 0.8134986194699357
4849 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4850 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4851 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4852 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4853 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4854 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4855 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  100751
dev_network_count:  336

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
337  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  100801
dev_network_count:  337
learn step counter:  100851
dev_network_count:  337
learn step counter:  100901
dev_network_count:  337
learn step counter:  100951
dev_network_count:  337
learn step counter:  101001
dev_network_count:  337
learn step counter:  101051
dev_network_count:  337

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
338  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  101101
dev_network_count:  338
learn step counter:  101151
dev_network_count:  338
learn step counter:  101201
dev_network_count:  338
learn step counter:  101251
dev_network_count:  338
learn step counter:  101301
dev_network_count:  338
learn step counter:  101351
dev_network_count:  338

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
339  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  101401
dev_network_count:  339
learn step counter:  101451
dev_network_count:  339
learn step counter:  101501
dev_network_count:  339
learn step counter:  101551
dev_network_count:  339
learn step counter:  101601
dev_network_count:  339
learn step counter:  101651
dev_network_count:  339

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
340  r_total and score:  52.75000000000001 0.0
Current Bleu score is:  0.0
learn step counter:  101701
dev_network_count:  340
EPOCH %d 105
 beam_dqn, egreed, gamma:  1 0.001 0.8126851208504657
2032 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
2033 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
2034 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
2035 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
2036 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
2037 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
2038 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  101751
dev_network_count:  340
learn step counter:  101801
dev_network_count:  340
learn step counter:  101851
dev_network_count:  340
learn step counter:  101901
dev_network_count:  340
learn step counter:  101951
dev_network_count:  340

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
341  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  102001
dev_network_count:  341
learn step counter:  102051
dev_network_count:  341
learn step counter:  102101
dev_network_count:  341
learn step counter:  102151
dev_network_count:  341
learn step counter:  102201
dev_network_count:  341
learn step counter:  102251
dev_network_count:  341

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
342  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  102301
dev_network_count:  342
learn step counter:  102351
dev_network_count:  342
learn step counter:  102401
dev_network_count:  342
learn step counter:  102451
dev_network_count:  342
learn step counter:  102501
dev_network_count:  342
learn step counter:  102551
dev_network_count:  342

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
343  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  102601
dev_network_count:  343
learn step counter:  102651
dev_network_count:  343
learn step counter:  102701
dev_network_count:  343
EPOCH %d 106
 beam_dqn, egreed, gamma:  1 0.001 0.8118724357296153
4215 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
4216 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
4217 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
4218 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
4219 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
4220 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
4221 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  102751
dev_network_count:  343
learn step counter:  102801
dev_network_count:  343
learn step counter:  102851
dev_network_count:  343

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 1 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 1 1 1 1 1 1 1 1 1']
344  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  102901
dev_network_count:  344
learn step counter:  102951
dev_network_count:  344
learn step counter:  103001
dev_network_count:  344
learn step counter:  103051
dev_network_count:  344
learn step counter:  103101
dev_network_count:  344
learn step counter:  103151
dev_network_count:  344

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
345  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  103201
dev_network_count:  345
learn step counter:  103251
dev_network_count:  345
learn step counter:  103301
dev_network_count:  345
learn step counter:  103351
dev_network_count:  345
learn step counter:  103401
dev_network_count:  345
learn step counter:  103451
dev_network_count:  345

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
346  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  103501
dev_network_count:  346
learn step counter:  103551
dev_network_count:  346
learn step counter:  103601
dev_network_count:  346
learn step counter:  103651
dev_network_count:  346
learn step counter:  103701
dev_network_count:  346
EPOCH %d 107
 beam_dqn, egreed, gamma:  1 0.001 0.8110605632938858
1398 7 1.0 3 1  ... s[:3]:  [-0.7991797   0.42775002 -0.13903086]  ... s_[:5]:  [-0.94761     0.63485456 -0.7048073 ]
1399 3 0.8 0 0  ... s[:3]:  [-0.94761     0.63485456 -0.7048073 ]  ... s_[:5]:  [0. 0. 0.]
1400 8 1.0 3 1  ... s[:3]:  [-0.5415327   0.748504   -0.08645818]  ... s_[:5]:  [-0.9372362  0.8197782 -0.6427076]
1401 3 0.8 0 0  ... s[:3]:  [-0.9372362  0.8197782 -0.6427076]  ... s_[:5]:  [0. 0. 0.]
1402 5 -1.0 5 1  ... s[:3]:  [-0.00302794  0.8733366   0.6254632 ]  ... s_[:5]:  [-0.74317926  0.95347786  0.2886426 ]
1403 5 0.44999999999999996 3 1  ... s[:3]:  [-0.74317926  0.95347786  0.2886426 ]  ... s_[:5]:  [-0.9747595  0.9659831 -0.6857204]
1404 3 0.6 0 0  ... s[:3]:  [-0.9747595  0.9659831 -0.6857204]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  103751
dev_network_count:  346

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
347  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  103801
dev_network_count:  347
learn step counter:  103851
dev_network_count:  347
learn step counter:  103901
dev_network_count:  347
learn step counter:  103951
dev_network_count:  347
learn step counter:  104001
dev_network_count:  347
learn step counter:  104051
dev_network_count:  347

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
348  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  104101
dev_network_count:  348
learn step counter:  104151
dev_network_count:  348
learn step counter:  104201
dev_network_count:  348
learn step counter:  104251
dev_network_count:  348
learn step counter:  104301
dev_network_count:  348
learn step counter:  104351
dev_network_count:  348

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([7])]  the state[:3] is:  tensor([-0.9668,  0.7055, -0.8976])
So far:  [array([2]), array([7]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9663,  0.7486, -0.9267])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9661,  0.7588, -0.9311])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9323])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7639, -0.9328])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9733,  0.9694, -0.6916])
So far:  [array([2]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9864,  0.9713, -0.8851])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9712, -0.9117])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9710, -0.9180])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9709, -0.9201])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9708, -0.9209])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9214])
So far:  [array([2]), array([5]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9874,  0.9707, -0.9216])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 5]]) [2 4 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 6]]) [2 7 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 5 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 5]]) [2 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 6 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 6]]) [2 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 7 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 4, 6]]) [2 4 6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 5 7 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7, 5]]) [2 7 5]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 7 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3 3 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 3 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '0 1 1 1 1 1 1 1 1 1', '4 3 1 1 1 1 1 1 1 1', '3 3 3 1 1 1 1 1 1 1', '0 3 1 1 1 1 1 1 1 1', '3 3 1 1 1 1 1 1 1 1']
349  r_total and score:  53.650000000000006 0.0
Current Bleu score is:  0.0
learn step counter:  104401
dev_network_count:  349
learn step counter:  104451
dev_network_count:  349
learn step counter:  104501
dev_network_count:  349
learn step counter:  104551
dev_network_count:  349
learn step counter:  104601
dev_network_count:  349
learn step counter:  104651
dev_network_count:  349

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7992,  0.4278, -0.1390])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9476,  0.6349, -0.7048])
So far:  [array([2]), array([7]), array([4])]  the state[:3] is:  tensor([-0.9670,  0.7128, -0.8992])
So far:  [array([2]), array([7]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9665,  0.7497, -0.9268])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9662,  0.7588, -0.9312])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9657,  0.7622, -0.9324])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9654,  0.7638, -0.9328])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9652,  0.7647, -0.9330])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9651,  0.7652, -0.9331])
So far:  [array([2]), array([7]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9650,  0.7655, -0.9331])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 7 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 7]]) [2 7]
So far:  [array([2])]  the state[:3] is:  tensor([-0.5415,  0.7485, -0.0865])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9369,  0.8345, -0.6667])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9780,  0.8501, -0.9241])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9773,  0.8736, -0.9513])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9762,  0.8773, -0.9560])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9752,  0.8791, -0.9572])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9746,  0.8801, -0.9576])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9742,  0.8806, -0.9577])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9740,  0.8809, -0.9578])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9739,  0.8810, -0.9579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.        -0.6       -0.5       -0.55      -0.675     -0.8375
 -1.01875   -1.209375  -1.4046875 -1.8      ] 

tensor([[2, 8]]) [2 8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.0030,  0.8733,  0.6255])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.7432,  0.9535,  0.2886])
So far:  [array([2]), array([5]), array([5])]  the state[:3] is:  tensor([-0.9748,  0.9660, -0.6857])
So far:  [array([2]), array([5]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9863,  0.9710, -0.8845])
So far:  [array([2]), array([5]), array([5]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9875,  0.9711, -0.9115])