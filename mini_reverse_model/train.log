2020-04-02 16:47:05,587 Hello! This is Joey-NMT.
2020-04-02 16:47:07,601 Total params: 109024
2020-04-02 16:47:07,602 Trainable parameters: ['decoder.att_vector_layer.bias', 'decoder.att_vector_layer.weight', 'decoder.attention.key_layer.weight', 'decoder.bridge_layer.bias', 'decoder.bridge_layer.weight', 'decoder.output_layer.weight', 'decoder.rnn.bias_hh_l0', 'decoder.rnn.bias_ih_l0', 'decoder.rnn.weight_hh_l0', 'decoder.rnn.weight_ih_l0', 'encoder.rnn.bias_hh_l0', 'encoder.rnn.bias_hh_l0_reverse', 'encoder.rnn.bias_ih_l0', 'encoder.rnn.bias_ih_l0_reverse', 'encoder.rnn.weight_hh_l0', 'encoder.rnn.weight_hh_l0_reverse', 'encoder.rnn.weight_ih_l0', 'encoder.rnn.weight_ih_l0_reverse', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-04-02 16:47:07,602 cfg.name                           : mini_reverse_model
2020-04-02 16:47:07,602 cfg.data.src                       : src
2020-04-02 16:47:07,602 cfg.data.trg                       : trg
2020-04-02 16:47:07,602 cfg.data.train                     : test/data/mini_reverse/train
2020-04-02 16:47:07,603 cfg.data.dev                       : test/data/mini_reverse/dev
2020-04-02 16:47:07,603 cfg.data.test                      : test/data/mini_reverse/test
2020-04-02 16:47:07,603 cfg.data.level                     : word
2020-04-02 16:47:07,603 cfg.data.lowercase                 : False
2020-04-02 16:47:07,603 cfg.data.max_sent_length           : 25
2020-04-02 16:47:07,603 cfg.data.src_voc_min_freq          : 0
2020-04-02 16:47:07,603 cfg.data.src_voc_limit             : 100
2020-04-02 16:47:07,603 cfg.data.trg_voc_min_freq          : 0
2020-04-02 16:47:07,603 cfg.data.trg_voc_limit             : 100
2020-04-02 16:47:07,603 cfg.testing.beam_size              : 1
2020-04-02 16:47:07,603 cfg.testing.alpha                  : 1.0
2020-04-02 16:47:07,603 cfg.training.random_seed           : 42
2020-04-02 16:47:07,603 cfg.training.optimizer             : adam
2020-04-02 16:47:07,603 cfg.training.learning_rate         : 0.001
2020-04-02 16:47:07,603 cfg.training.learning_rate_min     : 0.0002
2020-04-02 16:47:07,603 cfg.training.weight_decay          : 0.0
2020-04-02 16:47:07,603 cfg.training.clip_grad_norm        : 1.0
2020-04-02 16:47:07,603 cfg.training.batch_size            : 10
2020-04-02 16:47:07,603 cfg.training.batch_type            : sentence
2020-04-02 16:47:07,604 cfg.training.scheduling            : plateau
2020-04-02 16:47:07,604 cfg.training.patience              : 5
2020-04-02 16:47:07,604 cfg.training.decrease_factor       : 0.5
2020-04-02 16:47:07,604 cfg.training.early_stopping_metric : eval_metric
2020-04-02 16:47:07,604 cfg.training.epochs                : 50
2020-04-02 16:47:07,604 cfg.training.validation_freq       : 10
2020-04-02 16:47:07,604 cfg.training.logging_freq          : 10
2020-04-02 16:47:07,604 cfg.training.eval_metric           : bleu
2020-04-02 16:47:07,604 cfg.training.model_dir             : mini_reverse_model
2020-04-02 16:47:07,604 cfg.training.overwrite             : True
2020-04-02 16:47:07,604 cfg.training.shuffle               : True
2020-04-02 16:47:07,604 cfg.training.use_cuda              : False
2020-04-02 16:47:07,604 cfg.training.max_output_length     : 30
2020-04-02 16:47:07,604 cfg.training.print_valid_sents     : [0, 3, 6]
2020-04-02 16:47:07,604 cfg.training.keep_last_ckpts       : 2
2020-04-02 16:47:07,604 cfg.model.initializer              : xavier
2020-04-02 16:47:07,604 cfg.model.embed_initializer        : normal
2020-04-02 16:47:07,604 cfg.model.embed_init_weight        : 0.1
2020-04-02 16:47:07,604 cfg.model.bias_initializer         : zeros
2020-04-02 16:47:07,604 cfg.model.init_rnn_orthogonal      : False
2020-04-02 16:47:07,605 cfg.model.lstm_forget_gate         : 0.0
2020-04-02 16:47:07,605 cfg.model.encoder.rnn_type         : lstm
2020-04-02 16:47:07,605 cfg.model.encoder.embeddings.embedding_dim : 16
2020-04-02 16:47:07,605 cfg.model.encoder.embeddings.scale : False
2020-04-02 16:47:07,605 cfg.model.encoder.hidden_size      : 64
2020-04-02 16:47:07,605 cfg.model.encoder.bidirectional    : True
2020-04-02 16:47:07,605 cfg.model.encoder.dropout          : 0.1
2020-04-02 16:47:07,605 cfg.model.encoder.num_layers       : 1
2020-04-02 16:47:07,605 cfg.model.decoder.rnn_type         : lstm
2020-04-02 16:47:07,605 cfg.model.decoder.embeddings.embedding_dim : 16
2020-04-02 16:47:07,605 cfg.model.decoder.embeddings.scale : False
2020-04-02 16:47:07,605 cfg.model.decoder.hidden_size      : 64
2020-04-02 16:47:07,605 cfg.model.decoder.dropout          : 0.1
2020-04-02 16:47:07,605 cfg.model.decoder.hidden_dropout   : 0.1
2020-04-02 16:47:07,605 cfg.model.decoder.num_layers       : 1
2020-04-02 16:47:07,605 cfg.model.decoder.input_feeding    : True
2020-04-02 16:47:07,605 cfg.model.decoder.init_hidden      : bridge
2020-04-02 16:47:07,605 cfg.model.decoder.attention        : luong
2020-04-02 16:47:07,605 cfg.dqn.epochs                     : 2000
2020-04-02 16:47:07,605 cfg.dqn.sample_size                : 256
2020-04-02 16:47:07,605 cfg.dqn.lr                         : 0.01
2020-04-02 16:47:07,605 cfg.dqn.egreed_max                 : 0.9
2020-04-02 16:47:07,606 cfg.dqn.egreed_min                 : 0.001
2020-04-02 16:47:07,606 cfg.dqn.gamma_max                  : 0.9
2020-04-02 16:47:07,606 cfg.dqn.gamma_min                  : 0.3
2020-04-02 16:47:07,606 cfg.dqn.nu_iter                    : 300
2020-04-02 16:47:07,606 cfg.dqn.mem_cap                    : 5000
2020-04-02 16:47:07,606 cfg.dqn.beam_min                   : 1
2020-04-02 16:47:07,606 cfg.dqn.beam_max                   : 50
2020-04-02 16:47:07,606 cfg.dqn.state_type                 : hidden
2020-04-02 16:47:07,606 cfg.dqn.reward_type                : bleu_diff
2020-04-02 16:47:07,606 Data set sizes: 
	train 100,
	valid 10,
	test 10
2020-04-02 16:47:07,606 First training example:
	[SRC] 3
	[TRG] 3
2020-04-02 16:47:07,606 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) 3 (5) 4 (6) 0 (7) 2 (8) 1
2020-04-02 16:47:07,606 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) 3 (5) 4 (6) 0 (7) 2 (8) 1
2020-04-02 16:47:07,606 Number of Src words (types): 9
2020-04-02 16:47:07,607 Number of Trg words (types): 9
2020-04-02 16:47:07,607 Model(
	encoder=RecurrentEncoder(LSTM(16, 64, batch_first=True, bidirectional=True)),
	decoder=RecurrentDecoder(rnn=LSTM(80, 64, batch_first=True), attention=LuongAttention),
	src_embed=Embeddings(embedding_dim=16, vocab_size=9),
	trg_embed=Embeddings(embedding_dim=16, vocab_size=9))
2020-04-02 16:47:07,607 EPOCH 1
2020-04-02 16:47:07,750 Epoch   1 Step:       10 Batch Loss:     4.087533 Tokens per Sec:     1718, Lr: 0.001000
2020-04-02 16:47:07,758 Hooray! New best validation result [eval_metric]!
2020-04-02 16:47:07,758 Saving new checkpoint.
2020-04-02 16:47:07,762 Example #0
2020-04-02 16:47:07,762 	Raw source:     ['2', '3']
2020-04-02 16:47:07,762 	Raw hypothesis: []
2020-04-02 16:47:07,762 	Source:     2 3
2020-04-02 16:47:07,762 	Reference:  3 2
2020-04-02 16:47:07,762 	Hypothesis: 
2020-04-02 16:47:07,762 Example #3
2020-04-02 16:47:07,762 	Raw source:     ['3', '0']
2020-04-02 16:47:07,762 	Raw hypothesis: []
2020-04-02 16:47:07,762 	Source:     3 0
2020-04-02 16:47:07,762 	Reference:  0 3
2020-04-02 16:47:07,762 	Hypothesis: 
2020-04-02 16:47:07,762 Example #6
2020-04-02 16:47:07,762 	Raw source:     ['0', '0']
2020-04-02 16:47:07,762 	Raw hypothesis: []
2020-04-02 16:47:07,763 	Source:     0 0
2020-04-02 16:47:07,763 	Reference:  0 0
2020-04-02 16:47:07,763 	Hypothesis: 
2020-04-02 16:47:07,763 Validation result (greedy) at epoch   1, step       10: bleu:   0.00, loss:  52.7685, ppl:   7.6107, duration: 0.0123s
2020-04-02 16:47:08,097 Epoch   1: total training loss 52.54
2020-04-02 16:47:08,097 EPOCH 2
2020-04-02 16:47:08,255 Epoch   2 Step:       20 Batch Loss:     5.369887 Tokens per Sec:     1575, Lr: 0.001000
2020-04-02 16:47:08,260 Example #0
2020-04-02 16:47:08,260 	Raw source:     ['2', '3']
2020-04-02 16:47:08,260 	Raw hypothesis: []
2020-04-02 16:47:08,260 	Source:     2 3
2020-04-02 16:47:08,260 	Reference:  3 2
2020-04-02 16:47:08,260 	Hypothesis: 
2020-04-02 16:47:08,261 Example #3
2020-04-02 16:47:08,261 	Raw source:     ['3', '0']
2020-04-02 16:47:08,261 	Raw hypothesis: []
2020-04-02 16:47:08,261 	Source:     3 0
2020-04-02 16:47:08,261 	Reference:  0 3
2020-04-02 16:47:08,261 	Hypothesis: 
2020-04-02 16:47:08,261 Example #6
2020-04-02 16:47:08,261 	Raw source:     ['0', '0']
2020-04-02 16:47:08,261 	Raw hypothesis: []
2020-04-02 16:47:08,261 	Source:     0 0
2020-04-02 16:47:08,261 	Reference:  0 0
2020-04-02 16:47:08,261 	Hypothesis: 
2020-04-02 16:47:08,261 Validation result (greedy) at epoch   2, step       20: bleu:   0.00, loss:  43.4769, ppl:   5.3238, duration: 0.0062s
2020-04-02 16:47:08,475 Epoch   2: total training loss 46.04
2020-04-02 16:47:08,478 EPOCH 3
2020-04-02 16:47:08,613 Epoch   3 Step:       30 Batch Loss:     5.411564 Tokens per Sec:     1832, Lr: 0.001000
2020-04-02 16:47:08,618 Example #0
2020-04-02 16:47:08,618 	Raw source:     ['2', '3']
2020-04-02 16:47:08,618 	Raw hypothesis: []
2020-04-02 16:47:08,618 	Source:     2 3
2020-04-02 16:47:08,618 	Reference:  3 2
2020-04-02 16:47:08,618 	Hypothesis: 
2020-04-02 16:47:08,618 Example #3
2020-04-02 16:47:08,618 	Raw source:     ['3', '0']
2020-04-02 16:47:08,618 	Raw hypothesis: []
2020-04-02 16:47:08,618 	Source:     3 0
2020-04-02 16:47:08,618 	Reference:  0 3
2020-04-02 16:47:08,618 	Hypothesis: 
2020-04-02 16:47:08,618 Example #6
2020-04-02 16:47:08,618 	Raw source:     ['0', '0']
2020-04-02 16:47:08,618 	Raw hypothesis: []
2020-04-02 16:47:08,618 	Source:     0 0
2020-04-02 16:47:08,618 	Reference:  0 0
2020-04-02 16:47:08,618 	Hypothesis: 
2020-04-02 16:47:08,619 Validation result (greedy) at epoch   3, step       30: bleu:   0.00, loss:  43.2636, ppl:   5.2803, duration: 0.0056s
2020-04-02 16:47:08,847 Epoch   3: total training loss 39.02
2020-04-02 16:47:08,848 EPOCH 4
2020-04-02 16:47:09,001 Epoch   4 Step:       40 Batch Loss:     3.892067 Tokens per Sec:     1611, Lr: 0.001000
2020-04-02 16:47:09,007 Hooray! New best validation result [eval_metric]!
2020-04-02 16:47:09,007 Saving new checkpoint.
2020-04-02 16:47:09,010 Example #0
2020-04-02 16:47:09,010 	Raw source:     ['2', '3']
2020-04-02 16:47:09,010 	Raw hypothesis: ['3']
2020-04-02 16:47:09,010 	Source:     2 3
2020-04-02 16:47:09,010 	Reference:  3 2
2020-04-02 16:47:09,010 	Hypothesis: 3
2020-04-02 16:47:09,010 Example #3
2020-04-02 16:47:09,010 	Raw source:     ['3', '0']
2020-04-02 16:47:09,010 	Raw hypothesis: ['3']
2020-04-02 16:47:09,011 	Source:     3 0
2020-04-02 16:47:09,011 	Reference:  0 3
2020-04-02 16:47:09,011 	Hypothesis: 3
2020-04-02 16:47:09,011 Example #6
2020-04-02 16:47:09,011 	Raw source:     ['0', '0']
2020-04-02 16:47:09,011 	Raw hypothesis: ['3']
2020-04-02 16:47:09,011 	Source:     0 0
2020-04-02 16:47:09,011 	Reference:  0 0
2020-04-02 16:47:09,011 	Hypothesis: 3
2020-04-02 16:47:09,011 Validation result (greedy) at epoch   4, step       40: bleu:  16.46, loss:  37.5076, ppl:   4.2317, duration: 0.0099s
2020-04-02 16:47:09,395 Epoch   4: total training loss 35.25
2020-04-02 16:47:09,397 EPOCH 5
2020-04-02 16:47:09,550 Epoch   5 Step:       50 Batch Loss:     2.096468 Tokens per Sec:     1611, Lr: 0.001000
2020-04-02 16:47:09,557 Example #0
2020-04-02 16:47:09,557 	Raw source:     ['2', '3']
2020-04-02 16:47:09,557 	Raw hypothesis: ['3', '3']
2020-04-02 16:47:09,557 	Source:     2 3
2020-04-02 16:47:09,557 	Reference:  3 2
2020-04-02 16:47:09,557 	Hypothesis: 3 3
2020-04-02 16:47:09,557 Example #3
2020-04-02 16:47:09,557 	Raw source:     ['3', '0']
2020-04-02 16:47:09,557 	Raw hypothesis: ['3']
2020-04-02 16:47:09,557 	Source:     3 0
2020-04-02 16:47:09,558 	Reference:  0 3
2020-04-02 16:47:09,558 	Hypothesis: 3
2020-04-02 16:47:09,558 Example #6
2020-04-02 16:47:09,558 	Raw source:     ['0', '0']
2020-04-02 16:47:09,558 	Raw hypothesis: ['3']
2020-04-02 16:47:09,558 	Source:     0 0
2020-04-02 16:47:09,558 	Reference:  0 0
2020-04-02 16:47:09,558 	Hypothesis: 3
2020-04-02 16:47:09,558 Validation result (greedy) at epoch   5, step       50: bleu:   0.00, loss:  31.9819, ppl:   3.4215, duration: 0.0075s
2020-04-02 16:47:10,043 Epoch   5: total training loss 29.11
2020-04-02 16:47:10,047 EPOCH 6
2020-04-02 16:47:10,201 Epoch   6 Step:       60 Batch Loss:     2.739680 Tokens per Sec:     1598, Lr: 0.001000
2020-04-02 16:47:10,208 Example #0
2020-04-02 16:47:10,208 	Raw source:     ['2', '3']
2020-04-02 16:47:10,208 	Raw hypothesis: ['3', '3']
2020-04-02 16:47:10,208 	Source:     2 3
2020-04-02 16:47:10,208 	Reference:  3 2
2020-04-02 16:47:10,208 	Hypothesis: 3 3
2020-04-02 16:47:10,208 Example #3
2020-04-02 16:47:10,208 	Raw source:     ['3', '0']
2020-04-02 16:47:10,208 	Raw hypothesis: ['3', '3']
2020-04-02 16:47:10,208 	Source:     3 0
2020-04-02 16:47:10,208 	Reference:  0 3
2020-04-02 16:47:10,209 	Hypothesis: 3 3
2020-04-02 16:47:10,209 Example #6
2020-04-02 16:47:10,209 	Raw source:     ['0', '0']
2020-04-02 16:47:10,209 	Raw hypothesis: ['0']
2020-04-02 16:47:10,209 	Source:     0 0
2020-04-02 16:47:10,209 	Reference:  0 0
2020-04-02 16:47:10,209 	Hypothesis: 0
2020-04-02 16:47:10,209 Validation result (greedy) at epoch   6, step       60: bleu:   0.00, loss:  29.7558, ppl:   3.1407, duration: 0.0075s
2020-04-02 16:47:10,682 Epoch   6: total training loss 27.82
2020-04-02 16:47:10,684 EPOCH 7
2020-04-02 16:47:10,836 Epoch   7 Step:       70 Batch Loss:     1.859731 Tokens per Sec:     1614, Lr: 0.001000
2020-04-02 16:47:10,842 Hooray! New best validation result [eval_metric]!
2020-04-02 16:47:10,842 Saving new checkpoint.
2020-04-02 16:47:10,845 Example #0
2020-04-02 16:47:10,846 	Raw source:     ['2', '3']
2020-04-02 16:47:10,846 	Raw hypothesis: ['3']
2020-04-02 16:47:10,846 	Source:     2 3
2020-04-02 16:47:10,846 	Reference:  3 2
2020-04-02 16:47:10,846 	Hypothesis: 3
2020-04-02 16:47:10,846 Example #3
2020-04-02 16:47:10,846 	Raw source:     ['3', '0']
2020-04-02 16:47:10,846 	Raw hypothesis: ['3']
2020-04-02 16:47:10,846 	Source:     3 0
2020-04-02 16:47:10,846 	Reference:  0 3
2020-04-02 16:47:10,846 	Hypothesis: 3
2020-04-02 16:47:10,846 Example #6
2020-04-02 16:47:10,846 	Raw source:     ['0', '0']
2020-04-02 16:47:10,846 	Raw hypothesis: ['0']
2020-04-02 16:47:10,846 	Source:     0 0
2020-04-02 16:47:10,846 	Reference:  0 0
2020-04-02 16:47:10,846 	Hypothesis: 0
2020-04-02 16:47:10,846 Validation result (greedy) at epoch   7, step       70: bleu:  21.95, loss:  29.1073, ppl:   3.0634, duration: 0.0102s
2020-04-02 16:47:11,221 Epoch   7: total training loss 24.26
2020-04-02 16:47:11,226 EPOCH 8
2020-04-02 16:47:11,376 Epoch   8 Step:       80 Batch Loss:     1.421091 Tokens per Sec:     1643, Lr: 0.001000
2020-04-02 16:47:11,383 Example #0
2020-04-02 16:47:11,383 	Raw source:     ['2', '3']
2020-04-02 16:47:11,383 	Raw hypothesis: ['3', '3']
2020-04-02 16:47:11,383 	Source:     2 3
2020-04-02 16:47:11,383 	Reference:  3 2
2020-04-02 16:47:11,383 	Hypothesis: 3 3
2020-04-02 16:47:11,383 Example #3
2020-04-02 16:47:11,383 	Raw source:     ['3', '0']
2020-04-02 16:47:11,383 	Raw hypothesis: ['3', '3']
2020-04-02 16:47:11,383 	Source:     3 0
2020-04-02 16:47:11,383 	Reference:  0 3
2020-04-02 16:47:11,383 	Hypothesis: 3 3
2020-04-02 16:47:11,383 Example #6
2020-04-02 16:47:11,383 	Raw source:     ['0', '0']
2020-04-02 16:47:11,383 	Raw hypothesis: ['0']
2020-04-02 16:47:11,383 	Source:     0 0
2020-04-02 16:47:11,383 	Reference:  0 0
2020-04-02 16:47:11,384 	Hypothesis: 0
2020-04-02 16:47:11,384 Validation result (greedy) at epoch   8, step       80: bleu:   0.00, loss:  24.3319, ppl:   2.5494, duration: 0.0075s
2020-04-02 16:47:11,859 Epoch   8: total training loss 21.80
2020-04-02 16:47:11,863 EPOCH 9
2020-04-02 16:47:12,015 Epoch   9 Step:       90 Batch Loss:     3.113510 Tokens per Sec:     1619, Lr: 0.001000
2020-04-02 16:47:12,022 Hooray! New best validation result [eval_metric]!
2020-04-02 16:47:12,022 Saving new checkpoint.
2020-04-02 16:47:12,025 Example #0
2020-04-02 16:47:12,025 	Raw source:     ['2', '3']
2020-04-02 16:47:12,025 	Raw hypothesis: ['3', '3']
2020-04-02 16:47:12,025 	Source:     2 3
2020-04-02 16:47:12,026 	Reference:  3 2
2020-04-02 16:47:12,026 	Hypothesis: 3 3
2020-04-02 16:47:12,026 Example #3
2020-04-02 16:47:12,026 	Raw source:     ['3', '0']
2020-04-02 16:47:12,026 	Raw hypothesis: ['3', '3']
2020-04-02 16:47:12,026 	Source:     3 0
2020-04-02 16:47:12,026 	Reference:  0 3
2020-04-02 16:47:12,026 	Hypothesis: 3 3
2020-04-02 16:47:12,026 Example #6
2020-04-02 16:47:12,026 	Raw source:     ['0', '0']
2020-04-02 16:47:12,026 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:12,026 	Source:     0 0
2020-04-02 16:47:12,026 	Reference:  0 0
2020-04-02 16:47:12,026 	Hypothesis: 0 0
2020-04-02 16:47:12,026 Validation result (greedy) at epoch   9, step       90: bleu:  40.20, loss:  20.4472, ppl:   2.1955, duration: 0.0105s
2020-04-02 16:47:12,562 Epoch   9: total training loss 18.29
2020-04-02 16:47:12,564 EPOCH 10
2020-04-02 16:47:12,709 Epoch  10 Step:      100 Batch Loss:     0.944002 Tokens per Sec:     1701, Lr: 0.001000
2020-04-02 16:47:12,716 Example #0
2020-04-02 16:47:12,716 	Raw source:     ['2', '3']
2020-04-02 16:47:12,716 	Raw hypothesis: ['3', '3']
2020-04-02 16:47:12,716 	Source:     2 3
2020-04-02 16:47:12,716 	Reference:  3 2
2020-04-02 16:47:12,716 	Hypothesis: 3 3
2020-04-02 16:47:12,716 Example #3
2020-04-02 16:47:12,716 	Raw source:     ['3', '0']
2020-04-02 16:47:12,716 	Raw hypothesis: ['3', '3']
2020-04-02 16:47:12,716 	Source:     3 0
2020-04-02 16:47:12,716 	Reference:  0 3
2020-04-02 16:47:12,716 	Hypothesis: 3 3
2020-04-02 16:47:12,716 Example #6
2020-04-02 16:47:12,716 	Raw source:     ['0', '0']
2020-04-02 16:47:12,716 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:12,716 	Source:     0 0
2020-04-02 16:47:12,716 	Reference:  0 0
2020-04-02 16:47:12,716 	Hypothesis: 0 0
2020-04-02 16:47:12,717 Validation result (greedy) at epoch  10, step      100: bleu:  35.83, loss:  17.2438, ppl:   1.9410, duration: 0.0075s
2020-04-02 16:47:13,296 Epoch  10: total training loss 15.55
2020-04-02 16:47:13,301 EPOCH 11
2020-04-02 16:47:13,426 Epoch  11 Step:      110 Batch Loss:     1.606183 Tokens per Sec:     1967, Lr: 0.001000
2020-04-02 16:47:13,432 Example #0
2020-04-02 16:47:13,432 	Raw source:     ['2', '3']
2020-04-02 16:47:13,432 	Raw hypothesis: ['3', '3']
2020-04-02 16:47:13,433 	Source:     2 3
2020-04-02 16:47:13,433 	Reference:  3 2
2020-04-02 16:47:13,433 	Hypothesis: 3 3
2020-04-02 16:47:13,433 Example #3
2020-04-02 16:47:13,433 	Raw source:     ['3', '0']
2020-04-02 16:47:13,433 	Raw hypothesis: ['3', '3']
2020-04-02 16:47:13,433 	Source:     3 0
2020-04-02 16:47:13,433 	Reference:  0 3
2020-04-02 16:47:13,433 	Hypothesis: 3 3
2020-04-02 16:47:13,433 Example #6
2020-04-02 16:47:13,433 	Raw source:     ['0', '0']
2020-04-02 16:47:13,433 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:13,433 	Source:     0 0
2020-04-02 16:47:13,433 	Reference:  0 0
2020-04-02 16:47:13,433 	Hypothesis: 0 0
2020-04-02 16:47:13,433 Validation result (greedy) at epoch  11, step      110: bleu:  33.85, loss:  14.5011, ppl:   1.7467, duration: 0.0067s
2020-04-02 16:47:13,952 Epoch  11: total training loss 12.74
2020-04-02 16:47:13,954 EPOCH 12
2020-04-02 16:47:14,096 Epoch  12 Step:      120 Batch Loss:     0.566430 Tokens per Sec:     1743, Lr: 0.001000
2020-04-02 16:47:14,102 Hooray! New best validation result [eval_metric]!
2020-04-02 16:47:14,102 Saving new checkpoint.
2020-04-02 16:47:14,104 Example #0
2020-04-02 16:47:14,104 	Raw source:     ['2', '3']
2020-04-02 16:47:14,105 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:14,105 	Source:     2 3
2020-04-02 16:47:14,105 	Reference:  3 2
2020-04-02 16:47:14,105 	Hypothesis: 3 2
2020-04-02 16:47:14,105 Example #3
2020-04-02 16:47:14,105 	Raw source:     ['3', '0']
2020-04-02 16:47:14,105 	Raw hypothesis: ['3', '3']
2020-04-02 16:47:14,105 	Source:     3 0
2020-04-02 16:47:14,105 	Reference:  0 3
2020-04-02 16:47:14,105 	Hypothesis: 3 3
2020-04-02 16:47:14,105 Example #6
2020-04-02 16:47:14,105 	Raw source:     ['0', '0']
2020-04-02 16:47:14,105 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:14,105 	Source:     0 0
2020-04-02 16:47:14,105 	Reference:  0 0
2020-04-02 16:47:14,105 	Hypothesis: 0 0
2020-04-02 16:47:14,105 Validation result (greedy) at epoch  12, step      120: bleu:  50.00, loss:  11.0860, ppl:   1.5317, duration: 0.0095s
2020-04-02 16:47:14,623 Epoch  12: total training loss 10.08
2020-04-02 16:47:14,624 EPOCH 13
2020-04-02 16:47:14,771 Epoch  13 Step:      130 Batch Loss:     0.752528 Tokens per Sec:     1682, Lr: 0.001000
2020-04-02 16:47:14,778 Hooray! New best validation result [eval_metric]!
2020-04-02 16:47:14,778 Saving new checkpoint.
2020-04-02 16:47:14,781 Example #0
2020-04-02 16:47:14,781 	Raw source:     ['2', '3']
2020-04-02 16:47:14,781 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:14,781 	Source:     2 3
2020-04-02 16:47:14,781 	Reference:  3 2
2020-04-02 16:47:14,781 	Hypothesis: 3 2
2020-04-02 16:47:14,781 Example #3
2020-04-02 16:47:14,781 	Raw source:     ['3', '0']
2020-04-02 16:47:14,781 	Raw hypothesis: ['3', '3']
2020-04-02 16:47:14,782 	Source:     3 0
2020-04-02 16:47:14,782 	Reference:  0 3
2020-04-02 16:47:14,782 	Hypothesis: 3 3
2020-04-02 16:47:14,782 Example #6
2020-04-02 16:47:14,782 	Raw source:     ['0', '0']
2020-04-02 16:47:14,782 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:14,782 	Source:     0 0
2020-04-02 16:47:14,782 	Reference:  0 0
2020-04-02 16:47:14,782 	Hypothesis: 0 0
2020-04-02 16:47:14,782 Validation result (greedy) at epoch  13, step      130: bleu:  76.38, loss:   8.5006, ppl:   1.3867, duration: 0.0109s
2020-04-02 16:47:15,311 Epoch  13: total training loss 7.42
2020-04-02 16:47:15,313 EPOCH 14
2020-04-02 16:47:15,458 Epoch  14 Step:      140 Batch Loss:     0.147868 Tokens per Sec:     1697, Lr: 0.001000
2020-04-02 16:47:15,465 Hooray! New best validation result [eval_metric]!
2020-04-02 16:47:15,465 Saving new checkpoint.
2020-04-02 16:47:15,469 Example #0
2020-04-02 16:47:15,469 	Raw source:     ['2', '3']
2020-04-02 16:47:15,469 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:15,469 	Source:     2 3
2020-04-02 16:47:15,469 	Reference:  3 2
2020-04-02 16:47:15,469 	Hypothesis: 3 2
2020-04-02 16:47:15,469 Example #3
2020-04-02 16:47:15,469 	Raw source:     ['3', '0']
2020-04-02 16:47:15,469 	Raw hypothesis: ['3', '3']
2020-04-02 16:47:15,469 	Source:     3 0
2020-04-02 16:47:15,469 	Reference:  0 3
2020-04-02 16:47:15,469 	Hypothesis: 3 3
2020-04-02 16:47:15,469 Example #6
2020-04-02 16:47:15,469 	Raw source:     ['0', '0']
2020-04-02 16:47:15,469 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:15,469 	Source:     0 0
2020-04-02 16:47:15,469 	Reference:  0 0
2020-04-02 16:47:15,469 	Hypothesis: 0 0
2020-04-02 16:47:15,469 Validation result (greedy) at epoch  14, step      140: bleu:  88.39, loss:   5.8152, ppl:   1.2506, duration: 0.0106s
2020-04-02 16:47:16,061 Epoch  14: total training loss 5.03
2020-04-02 16:47:16,063 EPOCH 15
2020-04-02 16:47:16,210 Epoch  15 Step:      150 Batch Loss:     0.081281 Tokens per Sec:     1668, Lr: 0.001000
2020-04-02 16:47:16,217 Hooray! New best validation result [eval_metric]!
2020-04-02 16:47:16,217 Saving new checkpoint.
2020-04-02 16:47:16,220 Example #0
2020-04-02 16:47:16,221 	Raw source:     ['2', '3']
2020-04-02 16:47:16,221 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:16,221 	Source:     2 3
2020-04-02 16:47:16,221 	Reference:  3 2
2020-04-02 16:47:16,221 	Hypothesis: 3 2
2020-04-02 16:47:16,221 Example #3
2020-04-02 16:47:16,221 	Raw source:     ['3', '0']
2020-04-02 16:47:16,221 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:16,221 	Source:     3 0
2020-04-02 16:47:16,221 	Reference:  0 3
2020-04-02 16:47:16,221 	Hypothesis: 0 3
2020-04-02 16:47:16,221 Example #6
2020-04-02 16:47:16,221 	Raw source:     ['0', '0']
2020-04-02 16:47:16,221 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:16,221 	Source:     0 0
2020-04-02 16:47:16,222 	Reference:  0 0
2020-04-02 16:47:16,222 	Hypothesis: 0 0
2020-04-02 16:47:16,222 Validation result (greedy) at epoch  15, step      150: bleu: 100.00, loss:   4.2292, ppl:   1.1766, duration: 0.0111s
2020-04-02 16:47:16,743 Epoch  15: total training loss 3.43
2020-04-02 16:47:16,745 EPOCH 16
2020-04-02 16:47:16,891 Epoch  16 Step:      160 Batch Loss:     0.044133 Tokens per Sec:     1692, Lr: 0.001000
2020-04-02 16:47:16,898 Example #0
2020-04-02 16:47:16,898 	Raw source:     ['2', '3']
2020-04-02 16:47:16,898 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:16,898 	Source:     2 3
2020-04-02 16:47:16,898 	Reference:  3 2
2020-04-02 16:47:16,898 	Hypothesis: 3 2
2020-04-02 16:47:16,898 Example #3
2020-04-02 16:47:16,898 	Raw source:     ['3', '0']
2020-04-02 16:47:16,898 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:16,898 	Source:     3 0
2020-04-02 16:47:16,898 	Reference:  0 3
2020-04-02 16:47:16,898 	Hypothesis: 0 3
2020-04-02 16:47:16,898 Example #6
2020-04-02 16:47:16,898 	Raw source:     ['0', '0']
2020-04-02 16:47:16,898 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:16,898 	Source:     0 0
2020-04-02 16:47:16,898 	Reference:  0 0
2020-04-02 16:47:16,898 	Hypothesis: 0 0
2020-04-02 16:47:16,898 Validation result (greedy) at epoch  16, step      160: bleu: 100.00, loss:   3.1578, ppl:   1.1291, duration: 0.0075s
2020-04-02 16:47:17,422 Epoch  16: total training loss 2.71
2020-04-02 16:47:17,424 EPOCH 17
2020-04-02 16:47:17,571 Epoch  17 Step:      170 Batch Loss:     0.025508 Tokens per Sec:     1674, Lr: 0.001000
2020-04-02 16:47:17,578 Example #0
2020-04-02 16:47:17,578 	Raw source:     ['2', '3']
2020-04-02 16:47:17,579 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:17,579 	Source:     2 3
2020-04-02 16:47:17,579 	Reference:  3 2
2020-04-02 16:47:17,579 	Hypothesis: 3 2
2020-04-02 16:47:17,579 Example #3
2020-04-02 16:47:17,579 	Raw source:     ['3', '0']
2020-04-02 16:47:17,579 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:17,579 	Source:     3 0
2020-04-02 16:47:17,579 	Reference:  0 3
2020-04-02 16:47:17,579 	Hypothesis: 0 3
2020-04-02 16:47:17,579 Example #6
2020-04-02 16:47:17,579 	Raw source:     ['0', '0']
2020-04-02 16:47:17,579 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:17,579 	Source:     0 0
2020-04-02 16:47:17,579 	Reference:  0 0
2020-04-02 16:47:17,579 	Hypothesis: 0 0
2020-04-02 16:47:17,579 Validation result (greedy) at epoch  17, step      170: bleu: 100.00, loss:   2.0784, ppl:   1.0832, duration: 0.0077s
2020-04-02 16:47:18,106 Epoch  17: total training loss 2.20
2020-04-02 16:47:18,110 EPOCH 18
2020-04-02 16:47:18,263 Epoch  18 Step:      180 Batch Loss:     0.030482 Tokens per Sec:     1617, Lr: 0.001000
2020-04-02 16:47:18,269 Example #0
2020-04-02 16:47:18,269 	Raw source:     ['2', '3']
2020-04-02 16:47:18,270 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:18,270 	Source:     2 3
2020-04-02 16:47:18,270 	Reference:  3 2
2020-04-02 16:47:18,270 	Hypothesis: 3 2
2020-04-02 16:47:18,270 Example #3
2020-04-02 16:47:18,270 	Raw source:     ['3', '0']
2020-04-02 16:47:18,270 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:18,270 	Source:     3 0
2020-04-02 16:47:18,270 	Reference:  0 3
2020-04-02 16:47:18,270 	Hypothesis: 0 3
2020-04-02 16:47:18,270 Example #6
2020-04-02 16:47:18,270 	Raw source:     ['0', '0']
2020-04-02 16:47:18,270 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:18,270 	Source:     0 0
2020-04-02 16:47:18,270 	Reference:  0 0
2020-04-02 16:47:18,270 	Hypothesis: 0 0
2020-04-02 16:47:18,270 Validation result (greedy) at epoch  18, step      180: bleu: 100.00, loss:   1.2699, ppl:   1.0501, duration: 0.0075s
2020-04-02 16:47:18,854 Epoch  18: total training loss 1.29
2020-04-02 16:47:18,856 EPOCH 19
2020-04-02 16:47:19,000 Epoch  19 Step:      190 Batch Loss:     0.022853 Tokens per Sec:     1709, Lr: 0.001000
2020-04-02 16:47:19,007 Example #0
2020-04-02 16:47:19,007 	Raw source:     ['2', '3']
2020-04-02 16:47:19,007 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:19,007 	Source:     2 3
2020-04-02 16:47:19,007 	Reference:  3 2
2020-04-02 16:47:19,007 	Hypothesis: 3 2
2020-04-02 16:47:19,007 Example #3
2020-04-02 16:47:19,007 	Raw source:     ['3', '0']
2020-04-02 16:47:19,007 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:19,007 	Source:     3 0
2020-04-02 16:47:19,007 	Reference:  0 3
2020-04-02 16:47:19,007 	Hypothesis: 0 3
2020-04-02 16:47:19,007 Example #6
2020-04-02 16:47:19,007 	Raw source:     ['0', '0']
2020-04-02 16:47:19,007 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:19,008 	Source:     0 0
2020-04-02 16:47:19,008 	Reference:  0 0
2020-04-02 16:47:19,008 	Hypothesis: 0 0
2020-04-02 16:47:19,008 Validation result (greedy) at epoch  19, step      190: bleu: 100.00, loss:   1.0151, ppl:   1.0398, duration: 0.0074s
2020-04-02 16:47:19,529 Epoch  19: total training loss 1.01
2020-04-02 16:47:19,531 EPOCH 20
2020-04-02 16:47:19,681 Epoch  20 Step:      200 Batch Loss:     0.016893 Tokens per Sec:     1648, Lr: 0.001000
2020-04-02 16:47:19,688 Example #0
2020-04-02 16:47:19,688 	Raw source:     ['2', '3']
2020-04-02 16:47:19,688 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:19,688 	Source:     2 3
2020-04-02 16:47:19,688 	Reference:  3 2
2020-04-02 16:47:19,688 	Hypothesis: 3 2
2020-04-02 16:47:19,688 Example #3
2020-04-02 16:47:19,688 	Raw source:     ['3', '0']
2020-04-02 16:47:19,688 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:19,688 	Source:     3 0
2020-04-02 16:47:19,688 	Reference:  0 3
2020-04-02 16:47:19,688 	Hypothesis: 0 3
2020-04-02 16:47:19,688 Example #6
2020-04-02 16:47:19,688 	Raw source:     ['0', '0']
2020-04-02 16:47:19,689 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:19,689 	Source:     0 0
2020-04-02 16:47:19,689 	Reference:  0 0
2020-04-02 16:47:19,689 	Hypothesis: 0 0
2020-04-02 16:47:19,689 Validation result (greedy) at epoch  20, step      200: bleu: 100.00, loss:   0.7187, ppl:   1.0280, duration: 0.0075s
2020-04-02 16:47:20,220 Epoch  20: total training loss 0.65
2020-04-02 16:47:20,225 EPOCH 21
2020-04-02 16:47:20,367 Epoch  21 Step:      210 Batch Loss:     0.045303 Tokens per Sec:     1733, Lr: 0.001000
2020-04-02 16:47:20,374 Example #0
2020-04-02 16:47:20,374 	Raw source:     ['2', '3']
2020-04-02 16:47:20,374 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:20,374 	Source:     2 3
2020-04-02 16:47:20,374 	Reference:  3 2
2020-04-02 16:47:20,374 	Hypothesis: 3 2
2020-04-02 16:47:20,374 Example #3
2020-04-02 16:47:20,374 	Raw source:     ['3', '0']
2020-04-02 16:47:20,374 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:20,374 	Source:     3 0
2020-04-02 16:47:20,374 	Reference:  0 3
2020-04-02 16:47:20,374 	Hypothesis: 0 3
2020-04-02 16:47:20,374 Example #6
2020-04-02 16:47:20,374 	Raw source:     ['0', '0']
2020-04-02 16:47:20,374 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:20,374 	Source:     0 0
2020-04-02 16:47:20,374 	Reference:  0 0
2020-04-02 16:47:20,374 	Hypothesis: 0 0
2020-04-02 16:47:20,375 Validation result (greedy) at epoch  21, step      210: bleu: 100.00, loss:   0.5400, ppl:   1.0210, duration: 0.0075s
2020-04-02 16:47:20,893 Epoch  21: total training loss 0.45
2020-04-02 16:47:20,895 EPOCH 22
2020-04-02 16:47:21,046 Epoch  22 Step:      220 Batch Loss:     0.054981 Tokens per Sec:     1636, Lr: 0.000500
2020-04-02 16:47:21,053 Example #0
2020-04-02 16:47:21,053 	Raw source:     ['2', '3']
2020-04-02 16:47:21,053 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:21,053 	Source:     2 3
2020-04-02 16:47:21,053 	Reference:  3 2
2020-04-02 16:47:21,053 	Hypothesis: 3 2
2020-04-02 16:47:21,053 Example #3
2020-04-02 16:47:21,053 	Raw source:     ['3', '0']
2020-04-02 16:47:21,053 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:21,053 	Source:     3 0
2020-04-02 16:47:21,053 	Reference:  0 3
2020-04-02 16:47:21,053 	Hypothesis: 0 3
2020-04-02 16:47:21,053 Example #6
2020-04-02 16:47:21,053 	Raw source:     ['0', '0']
2020-04-02 16:47:21,053 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:21,053 	Source:     0 0
2020-04-02 16:47:21,053 	Reference:  0 0
2020-04-02 16:47:21,053 	Hypothesis: 0 0
2020-04-02 16:47:21,053 Validation result (greedy) at epoch  22, step      220: bleu: 100.00, loss:   0.5070, ppl:   1.0197, duration: 0.0075s
2020-04-02 16:47:21,581 Epoch  22: total training loss 0.47
2020-04-02 16:47:21,586 EPOCH 23
2020-04-02 16:47:21,741 Epoch  23 Step:      230 Batch Loss:     0.009092 Tokens per Sec:     1583, Lr: 0.000500
2020-04-02 16:47:21,749 Example #0
2020-04-02 16:47:21,749 	Raw source:     ['2', '3']
2020-04-02 16:47:21,749 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:21,749 	Source:     2 3
2020-04-02 16:47:21,749 	Reference:  3 2
2020-04-02 16:47:21,749 	Hypothesis: 3 2
2020-04-02 16:47:21,749 Example #3
2020-04-02 16:47:21,749 	Raw source:     ['3', '0']
2020-04-02 16:47:21,749 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:21,749 	Source:     3 0
2020-04-02 16:47:21,749 	Reference:  0 3
2020-04-02 16:47:21,749 	Hypothesis: 0 3
2020-04-02 16:47:21,749 Example #6
2020-04-02 16:47:21,749 	Raw source:     ['0', '0']
2020-04-02 16:47:21,749 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:21,749 	Source:     0 0
2020-04-02 16:47:21,749 	Reference:  0 0
2020-04-02 16:47:21,749 	Hypothesis: 0 0
2020-04-02 16:47:21,749 Validation result (greedy) at epoch  23, step      230: bleu: 100.00, loss:   0.4377, ppl:   1.0170, duration: 0.0077s
2020-04-02 16:47:22,324 Epoch  23: total training loss 0.41
2020-04-02 16:47:22,326 EPOCH 24
2020-04-02 16:47:22,474 Epoch  24 Step:      240 Batch Loss:     0.054796 Tokens per Sec:     1655, Lr: 0.000500
2020-04-02 16:47:22,481 Example #0
2020-04-02 16:47:22,481 	Raw source:     ['2', '3']
2020-04-02 16:47:22,481 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:22,481 	Source:     2 3
2020-04-02 16:47:22,481 	Reference:  3 2
2020-04-02 16:47:22,481 	Hypothesis: 3 2
2020-04-02 16:47:22,481 Example #3
2020-04-02 16:47:22,482 	Raw source:     ['3', '0']
2020-04-02 16:47:22,482 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:22,482 	Source:     3 0
2020-04-02 16:47:22,482 	Reference:  0 3
2020-04-02 16:47:22,482 	Hypothesis: 0 3
2020-04-02 16:47:22,482 Example #6
2020-04-02 16:47:22,482 	Raw source:     ['0', '0']
2020-04-02 16:47:22,482 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:22,482 	Source:     0 0
2020-04-02 16:47:22,482 	Reference:  0 0
2020-04-02 16:47:22,482 	Hypothesis: 0 0
2020-04-02 16:47:22,482 Validation result (greedy) at epoch  24, step      240: bleu: 100.00, loss:   0.4027, ppl:   1.0156, duration: 0.0074s
2020-04-02 16:47:23,001 Epoch  24: total training loss 0.28
2020-04-02 16:47:23,003 EPOCH 25
2020-04-02 16:47:23,136 Epoch  25 Step:      250 Batch Loss:     0.008292 Tokens per Sec:     1847, Lr: 0.000500
2020-04-02 16:47:23,143 Example #0
2020-04-02 16:47:23,143 	Raw source:     ['2', '3']
2020-04-02 16:47:23,143 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:23,143 	Source:     2 3
2020-04-02 16:47:23,143 	Reference:  3 2
2020-04-02 16:47:23,143 	Hypothesis: 3 2
2020-04-02 16:47:23,143 Example #3
2020-04-02 16:47:23,143 	Raw source:     ['3', '0']
2020-04-02 16:47:23,143 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:23,143 	Source:     3 0
2020-04-02 16:47:23,143 	Reference:  0 3
2020-04-02 16:47:23,143 	Hypothesis: 0 3
2020-04-02 16:47:23,143 Example #6
2020-04-02 16:47:23,143 	Raw source:     ['0', '0']
2020-04-02 16:47:23,143 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:23,143 	Source:     0 0
2020-04-02 16:47:23,143 	Reference:  0 0
2020-04-02 16:47:23,143 	Hypothesis: 0 0
2020-04-02 16:47:23,143 Validation result (greedy) at epoch  25, step      250: bleu: 100.00, loss:   0.3693, ppl:   1.0143, duration: 0.0070s
2020-04-02 16:47:23,667 Epoch  25: total training loss 0.34
2020-04-02 16:47:23,669 EPOCH 26
2020-04-02 16:47:23,820 Epoch  26 Step:      260 Batch Loss:     0.035991 Tokens per Sec:     1632, Lr: 0.000500
2020-04-02 16:47:23,827 Example #0
2020-04-02 16:47:23,827 	Raw source:     ['2', '3']
2020-04-02 16:47:23,827 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:23,827 	Source:     2 3
2020-04-02 16:47:23,827 	Reference:  3 2
2020-04-02 16:47:23,827 	Hypothesis: 3 2
2020-04-02 16:47:23,827 Example #3
2020-04-02 16:47:23,827 	Raw source:     ['3', '0']
2020-04-02 16:47:23,827 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:23,828 	Source:     3 0
2020-04-02 16:47:23,828 	Reference:  0 3
2020-04-02 16:47:23,828 	Hypothesis: 0 3
2020-04-02 16:47:23,828 Example #6
2020-04-02 16:47:23,828 	Raw source:     ['0', '0']
2020-04-02 16:47:23,828 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:23,828 	Source:     0 0
2020-04-02 16:47:23,828 	Reference:  0 0
2020-04-02 16:47:23,828 	Hypothesis: 0 0
2020-04-02 16:47:23,828 Validation result (greedy) at epoch  26, step      260: bleu: 100.00, loss:   0.3219, ppl:   1.0125, duration: 0.0076s
2020-04-02 16:47:24,347 Epoch  26: total training loss 0.24
2020-04-02 16:47:24,349 EPOCH 27
2020-04-02 16:47:24,500 Epoch  27 Step:      270 Batch Loss:     0.007415 Tokens per Sec:     1627, Lr: 0.000500
2020-04-02 16:47:24,507 Example #0
2020-04-02 16:47:24,507 	Raw source:     ['2', '3']
2020-04-02 16:47:24,507 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:24,507 	Source:     2 3
2020-04-02 16:47:24,507 	Reference:  3 2
2020-04-02 16:47:24,507 	Hypothesis: 3 2
2020-04-02 16:47:24,507 Example #3
2020-04-02 16:47:24,507 	Raw source:     ['3', '0']
2020-04-02 16:47:24,507 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:24,507 	Source:     3 0
2020-04-02 16:47:24,507 	Reference:  0 3
2020-04-02 16:47:24,508 	Hypothesis: 0 3
2020-04-02 16:47:24,508 Example #6
2020-04-02 16:47:24,508 	Raw source:     ['0', '0']
2020-04-02 16:47:24,508 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:24,508 	Source:     0 0
2020-04-02 16:47:24,508 	Reference:  0 0
2020-04-02 16:47:24,508 	Hypothesis: 0 0
2020-04-02 16:47:24,508 Validation result (greedy) at epoch  27, step      270: bleu: 100.00, loss:   0.2974, ppl:   1.0115, duration: 0.0074s
2020-04-02 16:47:25,111 Epoch  27: total training loss 0.32
2020-04-02 16:47:25,115 EPOCH 28
2020-04-02 16:47:25,263 Epoch  28 Step:      280 Batch Loss:     0.051297 Tokens per Sec:     1669, Lr: 0.000250
2020-04-02 16:47:25,270 Example #0
2020-04-02 16:47:25,270 	Raw source:     ['2', '3']
2020-04-02 16:47:25,270 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:25,270 	Source:     2 3
2020-04-02 16:47:25,270 	Reference:  3 2
2020-04-02 16:47:25,270 	Hypothesis: 3 2
2020-04-02 16:47:25,270 Example #3
2020-04-02 16:47:25,270 	Raw source:     ['3', '0']
2020-04-02 16:47:25,270 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:25,270 	Source:     3 0
2020-04-02 16:47:25,270 	Reference:  0 3
2020-04-02 16:47:25,271 	Hypothesis: 0 3
2020-04-02 16:47:25,271 Example #6
2020-04-02 16:47:25,271 	Raw source:     ['0', '0']
2020-04-02 16:47:25,271 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:25,271 	Source:     0 0
2020-04-02 16:47:25,271 	Reference:  0 0
2020-04-02 16:47:25,271 	Hypothesis: 0 0
2020-04-02 16:47:25,271 Validation result (greedy) at epoch  28, step      280: bleu: 100.00, loss:   0.2789, ppl:   1.0108, duration: 0.0076s
2020-04-02 16:47:25,799 Epoch  28: total training loss 0.28
2020-04-02 16:47:25,803 EPOCH 29
2020-04-02 16:47:25,936 Epoch  29 Step:      290 Batch Loss:     0.030575 Tokens per Sec:     1849, Lr: 0.000250
2020-04-02 16:47:25,942 Example #0
2020-04-02 16:47:25,943 	Raw source:     ['2', '3']
2020-04-02 16:47:25,943 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:25,943 	Source:     2 3
2020-04-02 16:47:25,943 	Reference:  3 2
2020-04-02 16:47:25,943 	Hypothesis: 3 2
2020-04-02 16:47:25,943 Example #3
2020-04-02 16:47:25,943 	Raw source:     ['3', '0']
2020-04-02 16:47:25,943 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:25,943 	Source:     3 0
2020-04-02 16:47:25,943 	Reference:  0 3
2020-04-02 16:47:25,943 	Hypothesis: 0 3
2020-04-02 16:47:25,943 Example #6
2020-04-02 16:47:25,943 	Raw source:     ['0', '0']
2020-04-02 16:47:25,943 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:25,943 	Source:     0 0
2020-04-02 16:47:25,943 	Reference:  0 0
2020-04-02 16:47:25,943 	Hypothesis: 0 0
2020-04-02 16:47:25,943 Validation result (greedy) at epoch  29, step      290: bleu: 100.00, loss:   0.2602, ppl:   1.0101, duration: 0.0066s
2020-04-02 16:47:26,462 Epoch  29: total training loss 0.20
2020-04-02 16:47:26,463 EPOCH 30
2020-04-02 16:47:26,620 Epoch  30 Step:      300 Batch Loss:     0.007027 Tokens per Sec:     1572, Lr: 0.000250
2020-04-02 16:47:26,627 Example #0
2020-04-02 16:47:26,627 	Raw source:     ['2', '3']
2020-04-02 16:47:26,627 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:26,627 	Source:     2 3
2020-04-02 16:47:26,627 	Reference:  3 2
2020-04-02 16:47:26,627 	Hypothesis: 3 2
2020-04-02 16:47:26,627 Example #3
2020-04-02 16:47:26,627 	Raw source:     ['3', '0']
2020-04-02 16:47:26,627 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:26,627 	Source:     3 0
2020-04-02 16:47:26,627 	Reference:  0 3
2020-04-02 16:47:26,628 	Hypothesis: 0 3
2020-04-02 16:47:26,628 Example #6
2020-04-02 16:47:26,628 	Raw source:     ['0', '0']
2020-04-02 16:47:26,628 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:26,628 	Source:     0 0
2020-04-02 16:47:26,628 	Reference:  0 0
2020-04-02 16:47:26,628 	Hypothesis: 0 0
2020-04-02 16:47:26,628 Validation result (greedy) at epoch  30, step      300: bleu: 100.00, loss:   0.2496, ppl:   1.0096, duration: 0.0076s
2020-04-02 16:47:27,170 Epoch  30: total training loss 0.20
2020-04-02 16:47:27,175 EPOCH 31
2020-04-02 16:47:27,322 Epoch  31 Step:      310 Batch Loss:     0.024566 Tokens per Sec:     1672, Lr: 0.000250
2020-04-02 16:47:27,329 Example #0
2020-04-02 16:47:27,329 	Raw source:     ['2', '3']
2020-04-02 16:47:27,329 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:27,329 	Source:     2 3
2020-04-02 16:47:27,329 	Reference:  3 2
2020-04-02 16:47:27,330 	Hypothesis: 3 2
2020-04-02 16:47:27,330 Example #3
2020-04-02 16:47:27,330 	Raw source:     ['3', '0']
2020-04-02 16:47:27,330 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:27,330 	Source:     3 0
2020-04-02 16:47:27,330 	Reference:  0 3
2020-04-02 16:47:27,330 	Hypothesis: 0 3
2020-04-02 16:47:27,330 Example #6
2020-04-02 16:47:27,330 	Raw source:     ['0', '0']
2020-04-02 16:47:27,330 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:27,330 	Source:     0 0
2020-04-02 16:47:27,330 	Reference:  0 0
2020-04-02 16:47:27,330 	Hypothesis: 0 0
2020-04-02 16:47:27,330 Validation result (greedy) at epoch  31, step      310: bleu: 100.00, loss:   0.2426, ppl:   1.0094, duration: 0.0075s
2020-04-02 16:47:27,921 Epoch  31: total training loss 0.20
2020-04-02 16:47:27,923 EPOCH 32
2020-04-02 16:47:28,072 Epoch  32 Step:      320 Batch Loss:     0.026154 Tokens per Sec:     1659, Lr: 0.000250
2020-04-02 16:47:28,078 Example #0
2020-04-02 16:47:28,079 	Raw source:     ['2', '3']
2020-04-02 16:47:28,079 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:28,079 	Source:     2 3
2020-04-02 16:47:28,079 	Reference:  3 2
2020-04-02 16:47:28,079 	Hypothesis: 3 2
2020-04-02 16:47:28,079 Example #3
2020-04-02 16:47:28,079 	Raw source:     ['3', '0']
2020-04-02 16:47:28,079 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:28,079 	Source:     3 0
2020-04-02 16:47:28,079 	Reference:  0 3
2020-04-02 16:47:28,079 	Hypothesis: 0 3
2020-04-02 16:47:28,079 Example #6
2020-04-02 16:47:28,079 	Raw source:     ['0', '0']
2020-04-02 16:47:28,079 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:28,079 	Source:     0 0
2020-04-02 16:47:28,079 	Reference:  0 0
2020-04-02 16:47:28,079 	Hypothesis: 0 0
2020-04-02 16:47:28,079 Validation result (greedy) at epoch  32, step      320: bleu: 100.00, loss:   0.2370, ppl:   1.0092, duration: 0.0075s
2020-04-02 16:47:28,604 Epoch  32: total training loss 0.25
2020-04-02 16:47:28,606 EPOCH 33
2020-04-02 16:47:28,756 Epoch  33 Step:      330 Batch Loss:     0.009262 Tokens per Sec:     1641, Lr: 0.000250
2020-04-02 16:47:28,763 Example #0
2020-04-02 16:47:28,763 	Raw source:     ['2', '3']
2020-04-02 16:47:28,763 	Raw hypothesis: ['3', '2']
2020-04-02 16:47:28,763 	Source:     2 3
2020-04-02 16:47:28,763 	Reference:  3 2
2020-04-02 16:47:28,763 	Hypothesis: 3 2
2020-04-02 16:47:28,763 Example #3
2020-04-02 16:47:28,763 	Raw source:     ['3', '0']
2020-04-02 16:47:28,763 	Raw hypothesis: ['0', '3']
2020-04-02 16:47:28,763 	Source:     3 0
2020-04-02 16:47:28,763 	Reference:  0 3
2020-04-02 16:47:28,763 	Hypothesis: 0 3
2020-04-02 16:47:28,763 Example #6
2020-04-02 16:47:28,763 	Raw source:     ['0', '0']
2020-04-02 16:47:28,763 	Raw hypothesis: ['0', '0']
2020-04-02 16:47:28,763 	Source:     0 0
2020-04-02 16:47:28,763 	Reference:  0 0
2020-04-02 16:47:28,763 	Hypothesis: 0 0
2020-04-02 16:47:28,763 Validation result (greedy) at epoch  33, step      330: bleu: 100.00, loss:   0.2296, ppl:   1.0089, duration: 0.0075s
2020-04-02 16:47:29,288 Training ended since minimum lr 0.000200 was reached.
2020-04-02 16:47:29,290 Best validation result (greedy) at step      150: 100.00 eval_metric.
2020-04-02 16:47:29,308  dev bleu: 100.00 [Greedy decoding]
2020-04-02 16:47:29,308 Translations saved to: mini_reverse_model/00000150.hyps.dev
2020-04-02 16:47:29,312 test bleu: 100.00 [Greedy decoding]
2020-04-02 16:47:29,312 Translations saved to: mini_reverse_model/00000150.hyps.test
