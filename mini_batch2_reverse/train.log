2020-04-30 12:30:07,226 Hello! This is Joey-NMT.
2020-04-30 12:30:07,247 Total params: 19264
2020-04-30 12:30:07,248 Trainable parameters: ['decoder.att_vector_layer.bias', 'decoder.att_vector_layer.weight', 'decoder.attention.key_layer.weight', 'decoder.bridge_layer.bias', 'decoder.bridge_layer.weight', 'decoder.output_layer.weight', 'decoder.rnn.bias_hh_l0', 'decoder.rnn.bias_ih_l0', 'decoder.rnn.weight_hh_l0', 'decoder.rnn.weight_ih_l0', 'encoder.rnn.bias_hh_l0', 'encoder.rnn.bias_hh_l0_reverse', 'encoder.rnn.bias_ih_l0', 'encoder.rnn.bias_ih_l0_reverse', 'encoder.rnn.weight_hh_l0', 'encoder.rnn.weight_hh_l0_reverse', 'encoder.rnn.weight_ih_l0', 'encoder.rnn.weight_ih_l0_reverse', 'src_embed.lut.weight', 'trg_embed.lut.weight']
2020-04-30 12:30:07,250 cfg.name                           : mini_batch2_reverse
2020-04-30 12:30:07,250 cfg.data.src                       : src
2020-04-30 12:30:07,250 cfg.data.trg                       : trg
2020-04-30 12:30:07,251 cfg.data.train                     : test/data/mini_batch2_reverse/train
2020-04-30 12:30:07,251 cfg.data.dev                       : test/data/mini_batch2_reverse/dev
2020-04-30 12:30:07,251 cfg.data.test                      : test/data/mini_batch2_reverse/test
2020-04-30 12:30:07,252 cfg.data.level                     : word
2020-04-30 12:30:07,252 cfg.data.lowercase                 : False
2020-04-30 12:30:07,252 cfg.data.max_sent_length           : 25
2020-04-30 12:30:07,252 cfg.data.src_voc_min_freq          : 0
2020-04-30 12:30:07,253 cfg.data.src_voc_limit             : 100
2020-04-30 12:30:07,253 cfg.data.trg_voc_min_freq          : 0
2020-04-30 12:30:07,253 cfg.data.trg_voc_limit             : 100
2020-04-30 12:30:07,254 cfg.testing.beam_size              : 1
2020-04-30 12:30:07,254 cfg.testing.alpha                  : 1.0
2020-04-30 12:30:07,254 cfg.training.random_seed           : 42
2020-04-30 12:30:07,254 cfg.training.optimizer             : adam
2020-04-30 12:30:07,255 cfg.training.learning_rate         : 0.005
2020-04-30 12:30:07,255 cfg.training.learning_rate_min     : 0.0002
2020-04-30 12:30:07,255 cfg.training.weight_decay          : 0.0
2020-04-30 12:30:07,255 cfg.training.clip_grad_norm        : 1.0
2020-04-30 12:30:07,256 cfg.training.batch_size            : 32
2020-04-30 12:30:07,256 cfg.training.batch_type            : sentence
2020-04-30 12:30:07,256 cfg.training.scheduling            : plateau
2020-04-30 12:30:07,257 cfg.training.patience              : 5
2020-04-30 12:30:07,257 cfg.training.decrease_factor       : 0.5
2020-04-30 12:30:07,257 cfg.training.early_stopping_metric : eval_metric
2020-04-30 12:30:07,257 cfg.training.epochs                : 300
2020-04-30 12:30:07,258 cfg.training.validation_freq       : 10
2020-04-30 12:30:07,258 cfg.training.logging_freq          : 10
2020-04-30 12:30:07,258 cfg.training.eval_metric           : bleu
2020-04-30 12:30:07,259 cfg.training.model_dir             : mini_batch2_reverse
2020-04-30 12:30:07,259 cfg.training.overwrite             : True
2020-04-30 12:30:07,259 cfg.training.shuffle               : True
2020-04-30 12:30:07,259 cfg.training.use_cuda              : False
2020-04-30 12:30:07,260 cfg.training.max_output_length     : 10
2020-04-30 12:30:07,260 cfg.training.print_valid_sents     : [0, 3, 6]
2020-04-30 12:30:07,260 cfg.training.keep_last_ckpts       : 2
2020-04-30 12:30:07,261 cfg.model.initializer              : xavier
2020-04-30 12:30:07,261 cfg.model.embed_initializer        : normal
2020-04-30 12:30:07,261 cfg.model.embed_init_weight        : 0.1
2020-04-30 12:30:07,261 cfg.model.bias_initializer         : zeros
2020-04-30 12:30:07,262 cfg.model.init_rnn_orthogonal      : False
2020-04-30 12:30:07,262 cfg.model.lstm_forget_gate         : 0.0
2020-04-30 12:30:07,262 cfg.model.encoder.rnn_type         : lstm
2020-04-30 12:30:07,262 cfg.model.encoder.embeddings.embedding_dim : 16
2020-04-30 12:30:07,263 cfg.model.encoder.embeddings.scale : False
2020-04-30 12:30:07,263 cfg.model.encoder.hidden_size      : 24
2020-04-30 12:30:07,263 cfg.model.encoder.bidirectional    : True
2020-04-30 12:30:07,264 cfg.model.encoder.dropout          : 0.1
2020-04-30 12:30:07,264 cfg.model.encoder.num_layers       : 1
2020-04-30 12:30:07,264 cfg.model.decoder.rnn_type         : lstm
2020-04-30 12:30:07,264 cfg.model.decoder.embeddings.embedding_dim : 16
2020-04-30 12:30:07,265 cfg.model.decoder.embeddings.scale : False
2020-04-30 12:30:07,265 cfg.model.decoder.hidden_size      : 24
2020-04-30 12:30:07,265 cfg.model.decoder.dropout          : 0.1
2020-04-30 12:30:07,265 cfg.model.decoder.hidden_dropout   : 0.1
2020-04-30 12:30:07,266 cfg.model.decoder.num_layers       : 1
2020-04-30 12:30:07,266 cfg.model.decoder.input_feeding    : True
2020-04-30 12:30:07,266 cfg.model.decoder.init_hidden      : bridge
2020-04-30 12:30:07,267 cfg.model.decoder.attention        : luong
2020-04-30 12:30:07,267 cfg.dqn.epochs                     : 2000
2020-04-30 12:30:07,267 cfg.dqn.sample_size                : 256
2020-04-30 12:30:07,267 cfg.dqn.lr                         : 0.0001
2020-04-30 12:30:07,268 cfg.dqn.egreed_max                 : 0.9
2020-04-30 12:30:07,268 cfg.dqn.egreed_min                 : 0.001
2020-04-30 12:30:07,268 cfg.dqn.gamma_max                  : 0.9
2020-04-30 12:30:07,269 cfg.dqn.gamma_min                  : 0.3
2020-04-30 12:30:07,269 cfg.dqn.nu_iter                    : 10
2020-04-30 12:30:07,269 cfg.dqn.mem_cap                    : 4000
2020-04-30 12:30:07,269 cfg.dqn.beam_min                   : 1
2020-04-30 12:30:07,270 cfg.dqn.beam_max                   : 50
2020-04-30 12:30:07,270 cfg.dqn.state_type                 : hidden
2020-04-30 12:30:07,270 cfg.dqn.reward_type                : bleu_batch
2020-04-30 12:30:07,271 cfg.dqn.nu_pretrain                : 40
2020-04-30 12:30:07,271 cfg.dqn.other_descrip              : _mini_batch2_test_
2020-04-30 12:30:07,271 Data set sizes: 
	train 200,
	valid 200,
	test 200
2020-04-30 12:30:07,271 First training example:
	[SRC] 1 2 3 4 5
	[TRG] 5 4 3 2 1
2020-04-30 12:30:07,272 First 10 words (src): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) 3 (5) 1 (6) 2 (7) 4 (8) 6 (9) 7
2020-04-30 12:30:07,272 First 10 words (trg): (0) <unk> (1) <pad> (2) <s> (3) </s> (4) 3 (5) 1 (6) 2 (7) 4 (8) 6 (9) 7
2020-04-30 12:30:07,273 Number of Src words (types): 14
2020-04-30 12:30:07,273 Number of Trg words (types): 14
2020-04-30 12:30:07,274 Model(
	encoder=RecurrentEncoder(LSTM(16, 24, batch_first=True, bidirectional=True)),
	decoder=RecurrentDecoder(rnn=LSTM(40, 24, batch_first=True), attention=LuongAttention),
	src_embed=Embeddings(embedding_dim=16, vocab_size=14),
	trg_embed=Embeddings(embedding_dim=16, vocab_size=14))
2020-04-30 12:30:07,275 EPOCH 1
2020-04-30 12:30:08,267 Epoch   1: total training loss 139.45
2020-04-30 12:30:08,269 EPOCH 2
2020-04-30 12:30:08,701 Epoch   2 Step:       10 Batch Loss:    26.266211 Tokens per Sec:     1707, Lr: 0.005000
2020-04-30 12:30:09,069 Hooray! New best validation result [eval_metric]!
2020-04-30 12:30:09,070 Saving new checkpoint.
2020-04-30 12:30:09,082 Example #0
2020-04-30 12:30:09,082 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:30:09,082 	Raw hypothesis: []
2020-04-30 12:30:09,083 	Source:     1 2 3 4 5
2020-04-30 12:30:09,083 	Reference:  5 4 3 2 1
2020-04-30 12:30:09,083 	Hypothesis: 
2020-04-30 12:30:09,083 Example #3
2020-04-30 12:30:09,084 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:30:09,084 	Raw hypothesis: []
2020-04-30 12:30:09,084 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:30:09,084 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:30:09,084 	Hypothesis: 
2020-04-30 12:30:09,085 Example #6
2020-04-30 12:30:09,085 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:30:09,085 	Raw hypothesis: []
2020-04-30 12:30:09,085 	Source:     1 3 6 7 2
2020-04-30 12:30:09,085 	Reference:  2 7 6 3 1
2020-04-30 12:30:09,086 	Hypothesis: 
2020-04-30 12:30:09,086 Validation result (greedy) at epoch   2, step       10: bleu:   0.00, loss: 3477.4304, ppl:  10.8244, duration: 0.3832s
2020-04-30 12:30:10,491 Epoch   2: total training loss 128.18
2020-04-30 12:30:10,492 EPOCH 3
2020-04-30 12:30:11,530 Epoch   3 Step:       20 Batch Loss:    18.220987 Tokens per Sec:     1345, Lr: 0.005000
2020-04-30 12:30:11,989 Example #0
2020-04-30 12:30:11,989 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:30:11,990 	Raw hypothesis: ['8', '2', '2', '2', '3', '1', '1']
2020-04-30 12:30:11,990 	Source:     1 2 3 4 5
2020-04-30 12:30:11,990 	Reference:  5 4 3 2 1
2020-04-30 12:30:11,991 	Hypothesis: 8 2 2 2 3 1 1
2020-04-30 12:30:11,991 Example #3
2020-04-30 12:30:11,991 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:30:11,992 	Raw hypothesis: ['8', '8', '4', '3', '1', '1', '1', '1', '1']
2020-04-30 12:30:11,992 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:30:11,992 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:30:11,993 	Hypothesis: 8 8 4 3 1 1 1 1 1
2020-04-30 12:30:11,993 Example #6
2020-04-30 12:30:11,993 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:30:11,993 	Raw hypothesis: ['2', '2', '2', '2', '3', '1', '1']
2020-04-30 12:30:11,993 	Source:     1 3 6 7 2
2020-04-30 12:30:11,993 	Reference:  2 7 6 3 1
2020-04-30 12:30:11,994 	Hypothesis: 2 2 2 2 3 1 1
2020-04-30 12:30:11,994 Validation result (greedy) at epoch   3, step       20: bleu:   0.00, loss: 3191.9661, ppl:   8.9020, duration: 0.4614s
2020-04-30 12:30:14,380 Epoch   3: total training loss 122.76
2020-04-30 12:30:14,381 EPOCH 4
2020-04-30 12:30:15,558 Epoch   4: total training loss 115.10
2020-04-30 12:30:15,560 EPOCH 5
2020-04-30 12:30:15,740 Epoch   5 Step:       30 Batch Loss:     4.400221 Tokens per Sec:     1904, Lr: 0.005000
2020-04-30 12:30:16,418 Example #0
2020-04-30 12:30:16,419 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:30:16,419 	Raw hypothesis: ['8', '3', '3']
2020-04-30 12:30:16,419 	Source:     1 2 3 4 5
2020-04-30 12:30:16,420 	Reference:  5 4 3 2 1
2020-04-30 12:30:16,420 	Hypothesis: 8 3 3
2020-04-30 12:30:16,421 Example #3
2020-04-30 12:30:16,421 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:30:16,421 	Raw hypothesis: ['8', '8', '8', '1', '1', '1']
2020-04-30 12:30:16,421 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:30:16,422 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:30:16,422 	Hypothesis: 8 8 8 1 1 1
2020-04-30 12:30:16,423 Example #6
2020-04-30 12:30:16,423 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:30:16,423 	Raw hypothesis: ['3', '3']
2020-04-30 12:30:16,423 	Source:     1 3 6 7 2
2020-04-30 12:30:16,424 	Reference:  2 7 6 3 1
2020-04-30 12:30:16,424 	Hypothesis: 3 3
2020-04-30 12:30:16,424 Validation result (greedy) at epoch   5, step       30: bleu:   0.00, loss: 2924.5386, ppl:   7.4121, duration: 0.6837s
2020-04-30 12:30:18,847 Epoch   5: total training loss 107.29
2020-04-30 12:30:18,848 EPOCH 6
2020-04-30 12:30:19,664 Epoch   6 Step:       40 Batch Loss:    15.764103 Tokens per Sec:     1343, Lr: 0.005000
2020-04-30 12:30:20,191 Example #0
2020-04-30 12:30:20,192 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:30:20,192 	Raw hypothesis: ['3', '3']
2020-04-30 12:30:20,192 	Source:     1 2 3 4 5
2020-04-30 12:30:20,193 	Reference:  5 4 3 2 1
2020-04-30 12:30:20,193 	Hypothesis: 3 3
2020-04-30 12:30:20,193 Example #3
2020-04-30 12:30:20,194 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:30:20,194 	Raw hypothesis: ['8', '8', '8', '8', '9', '1', '1']
2020-04-30 12:30:20,194 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:30:20,194 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:30:20,195 	Hypothesis: 8 8 8 8 9 1 1
2020-04-30 12:30:20,195 Example #6
2020-04-30 12:30:20,195 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:30:20,196 	Raw hypothesis: ['3', '3']
2020-04-30 12:30:20,196 	Source:     1 3 6 7 2
2020-04-30 12:30:20,197 	Reference:  2 7 6 3 1
2020-04-30 12:30:20,197 	Hypothesis: 3 3
2020-04-30 12:30:20,197 Validation result (greedy) at epoch   6, step       40: bleu:   0.00, loss: 2777.4182, ppl:   6.7016, duration: 0.5321s
2020-04-30 12:30:21,691 Epoch   6: total training loss 104.36
2020-04-30 12:30:21,692 EPOCH 7
2020-04-30 12:30:22,646 Epoch   7: total training loss 102.26
2020-04-30 12:30:22,646 EPOCH 8
2020-04-30 12:30:22,778 Epoch   8 Step:       50 Batch Loss:     9.232873 Tokens per Sec:     1281, Lr: 0.005000
2020-04-30 12:30:23,615 Example #0
2020-04-30 12:30:23,617 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:30:23,618 	Raw hypothesis: ['8', '4', '7', '3', '1', '1']
2020-04-30 12:30:23,618 	Source:     1 2 3 4 5
2020-04-30 12:30:23,618 	Reference:  5 4 3 2 1
2020-04-30 12:30:23,618 	Hypothesis: 8 4 7 3 1 1
2020-04-30 12:30:23,618 Example #3
2020-04-30 12:30:23,618 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:30:23,618 	Raw hypothesis: ['8', '8', '8', '9', '1', '1', '1', '1', '1', '1']
2020-04-30 12:30:23,618 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:30:23,619 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:30:23,619 	Hypothesis: 8 8 8 9 1 1 1 1 1 1
2020-04-30 12:30:23,619 Example #6
2020-04-30 12:30:23,619 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:30:23,619 	Raw hypothesis: ['6', '6', '2', '2', '3', '3', '1']
2020-04-30 12:30:23,619 	Source:     1 3 6 7 2
2020-04-30 12:30:23,619 	Reference:  2 7 6 3 1
2020-04-30 12:30:23,619 	Hypothesis: 6 6 2 2 3 3 1
2020-04-30 12:30:23,619 Validation result (greedy) at epoch   8, step       50: bleu:   0.00, loss: 2654.3113, ppl:   6.1597, duration: 0.8353s
2020-04-30 12:30:27,291 Epoch   8: total training loss 96.20
2020-04-30 12:30:27,293 EPOCH 9
2020-04-30 12:30:27,991 Epoch   9 Step:       60 Batch Loss:    16.813089 Tokens per Sec:     1263, Lr: 0.005000
2020-04-30 12:30:28,666 Example #0
2020-04-30 12:30:28,666 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:30:28,666 	Raw hypothesis: ['8', '7', '3', '1']
2020-04-30 12:30:28,666 	Source:     1 2 3 4 5
2020-04-30 12:30:28,666 	Reference:  5 4 3 2 1
2020-04-30 12:30:28,666 	Hypothesis: 8 7 3 1
2020-04-30 12:30:28,667 Example #3
2020-04-30 12:30:28,667 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:30:28,667 	Raw hypothesis: ['8', '8', '9', '8', '9', '1', '5']
2020-04-30 12:30:28,667 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:30:28,667 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:30:28,667 	Hypothesis: 8 8 9 8 9 1 5
2020-04-30 12:30:28,668 Example #6
2020-04-30 12:30:28,668 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:30:28,668 	Raw hypothesis: ['6', '7', '3', '7']
2020-04-30 12:30:28,668 	Source:     1 3 6 7 2
2020-04-30 12:30:28,668 	Reference:  2 7 6 3 1
2020-04-30 12:30:28,668 	Hypothesis: 6 7 3 7
2020-04-30 12:30:28,668 Validation result (greedy) at epoch   9, step       60: bleu:   0.00, loss: 2330.1194, ppl:   4.9331, duration: 0.6670s
2020-04-30 12:30:30,969 Epoch   9: total training loss 88.26
2020-04-30 12:30:30,969 EPOCH 10
2020-04-30 12:30:31,892 Epoch  10 Step:       70 Batch Loss:    10.351954 Tokens per Sec:     1583, Lr: 0.005000
2020-04-30 12:30:32,366 Example #0
2020-04-30 12:30:32,367 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:30:32,367 	Raw hypothesis: ['8', '3', '7', '3', '1']
2020-04-30 12:30:32,367 	Source:     1 2 3 4 5
2020-04-30 12:30:32,367 	Reference:  5 4 3 2 1
2020-04-30 12:30:32,367 	Hypothesis: 8 3 7 3 1
2020-04-30 12:30:32,367 Example #3
2020-04-30 12:30:32,367 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:30:32,367 	Raw hypothesis: ['8', '8', '9', '8', '5', '3', '1']
2020-04-30 12:30:32,367 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:30:32,368 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:30:32,368 	Hypothesis: 8 8 9 8 5 3 1
2020-04-30 12:30:32,368 Example #6
2020-04-30 12:30:32,368 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:30:32,368 	Raw hypothesis: ['6', '7', '3', '1']
2020-04-30 12:30:32,368 	Source:     1 3 6 7 2
2020-04-30 12:30:32,368 	Reference:  2 7 6 3 1
2020-04-30 12:30:32,368 	Hypothesis: 6 7 3 1
2020-04-30 12:30:32,368 Validation result (greedy) at epoch  10, step       70: bleu:   0.00, loss: 2036.8313, ppl:   4.0353, duration: 0.4718s
2020-04-30 12:30:34,037 Epoch  10: total training loss 81.26
2020-04-30 12:30:34,037 EPOCH 11
2020-04-30 12:30:34,759 Epoch  11: total training loss 74.65
2020-04-30 12:30:34,759 EPOCH 12
2020-04-30 12:30:35,100 Epoch  12 Step:       80 Batch Loss:    12.399179 Tokens per Sec:     2139, Lr: 0.002500
2020-04-30 12:30:35,761 Hooray! New best validation result [eval_metric]!
2020-04-30 12:30:35,762 Saving new checkpoint.
2020-04-30 12:30:35,778 Example #0
2020-04-30 12:30:35,779 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:30:35,779 	Raw hypothesis: ['8', '3', '7', '3', '1']
2020-04-30 12:30:35,779 	Source:     1 2 3 4 5
2020-04-30 12:30:35,779 	Reference:  5 4 3 2 1
2020-04-30 12:30:35,779 	Hypothesis: 8 3 7 3 1
2020-04-30 12:30:35,780 Example #3
2020-04-30 12:30:35,780 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:30:35,780 	Raw hypothesis: ['8', '8', '9', '8', '9', '1', '5']
2020-04-30 12:30:35,780 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:30:35,780 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:30:35,780 	Hypothesis: 8 8 9 8 9 1 5
2020-04-30 12:30:35,781 Example #6
2020-04-30 12:30:35,781 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:30:35,781 	Raw hypothesis: ['6', '7', '3', '7']
2020-04-30 12:30:35,781 	Source:     1 3 6 7 2
2020-04-30 12:30:35,781 	Reference:  2 7 6 3 1
2020-04-30 12:30:35,781 	Hypothesis: 6 7 3 7
2020-04-30 12:30:35,782 Validation result (greedy) at epoch  12, step       80: bleu:  17.98, loss: 1857.0171, ppl:   3.5677, duration: 0.6815s
2020-04-30 12:30:38,252 Epoch  12: total training loss 69.95
2020-04-30 12:30:38,254 EPOCH 13
2020-04-30 12:30:39,075 Epoch  13 Step:       90 Batch Loss:     5.844913 Tokens per Sec:     1692, Lr: 0.002500
2020-04-30 12:30:39,569 Hooray! New best validation result [eval_metric]!
2020-04-30 12:30:39,570 Saving new checkpoint.
2020-04-30 12:30:39,587 Example #0
2020-04-30 12:30:39,587 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:30:39,588 	Raw hypothesis: ['8', '3', '7', '3', '1']
2020-04-30 12:30:39,588 	Source:     1 2 3 4 5
2020-04-30 12:30:39,588 	Reference:  5 4 3 2 1
2020-04-30 12:30:39,589 	Hypothesis: 8 3 7 3 1
2020-04-30 12:30:39,589 Example #3
2020-04-30 12:30:39,589 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:30:39,590 	Raw hypothesis: ['8', '8', '9', '8', '5', '3', '1']
2020-04-30 12:30:39,590 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:30:39,590 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:30:39,590 	Hypothesis: 8 8 9 8 5 3 1
2020-04-30 12:30:39,590 Example #6
2020-04-30 12:30:39,591 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:30:39,591 	Raw hypothesis: ['2', '7', '3', '1']
2020-04-30 12:30:39,591 	Source:     1 3 6 7 2
2020-04-30 12:30:39,591 	Reference:  2 7 6 3 1
2020-04-30 12:30:39,592 	Hypothesis: 2 7 3 1
2020-04-30 12:30:39,592 Validation result (greedy) at epoch  13, step       90: bleu:  21.60, loss: 1706.3730, ppl:   3.2180, duration: 0.5171s
2020-04-30 12:30:41,576 Epoch  13: total training loss 66.91
2020-04-30 12:30:41,577 EPOCH 14
2020-04-30 12:30:41,971 Epoch  14: total training loss 63.74
2020-04-30 12:30:41,972 EPOCH 15
2020-04-30 12:30:42,158 Epoch  15 Step:      100 Batch Loss:    10.146775 Tokens per Sec:     3320, Lr: 0.002500
2020-04-30 12:30:42,530 Hooray! New best validation result [eval_metric]!
2020-04-30 12:30:42,530 Saving new checkpoint.
2020-04-30 12:30:42,545 Example #0
2020-04-30 12:30:42,546 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:30:42,546 	Raw hypothesis: ['8', '7', '3', '7', '3', '1']
2020-04-30 12:30:42,546 	Source:     1 2 3 4 5
2020-04-30 12:30:42,546 	Reference:  5 4 3 2 1
2020-04-30 12:30:42,547 	Hypothesis: 8 7 3 7 3 1
2020-04-30 12:30:42,547 Example #3
2020-04-30 12:30:42,547 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:30:42,548 	Raw hypothesis: ['8', '8', '9', '8', '5', '9', '1', '5']
2020-04-30 12:30:42,548 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:30:42,548 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:30:42,549 	Hypothesis: 8 8 9 8 5 9 1 5
2020-04-30 12:30:42,549 Example #6
2020-04-30 12:30:42,549 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:30:42,549 	Raw hypothesis: ['2', '7', '7', '3', '1']
2020-04-30 12:30:42,549 	Source:     1 3 6 7 2
2020-04-30 12:30:42,550 	Reference:  2 7 6 3 1
2020-04-30 12:30:42,550 	Hypothesis: 2 7 7 3 1
2020-04-30 12:30:42,550 Validation result (greedy) at epoch  15, step      100: bleu:  30.87, loss: 1582.2118, ppl:   2.9556, duration: 0.3907s
2020-04-30 12:30:45,472 Epoch  15: total training loss 61.19
2020-04-30 12:30:45,473 EPOCH 16
2020-04-30 12:30:45,977 Epoch  16 Step:      110 Batch Loss:     0.506201 Tokens per Sec:     1677, Lr: 0.002500
2020-04-30 12:30:46,586 Example #0
2020-04-30 12:30:46,587 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:30:46,587 	Raw hypothesis: ['5', '7', '3', '7']
2020-04-30 12:30:46,587 	Source:     1 2 3 4 5
2020-04-30 12:30:46,588 	Reference:  5 4 3 2 1
2020-04-30 12:30:46,588 	Hypothesis: 5 7 3 7
2020-04-30 12:30:46,588 Example #3
2020-04-30 12:30:46,589 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:30:46,589 	Raw hypothesis: ['0', '8', '9', '1', '5', '5']
2020-04-30 12:30:46,589 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:30:46,589 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:30:46,590 	Hypothesis: 0 8 9 1 5 5
2020-04-30 12:30:46,590 Example #6
2020-04-30 12:30:46,590 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:30:46,590 	Raw hypothesis: ['2', '7', '7', '3', '1']
2020-04-30 12:30:46,591 	Source:     1 3 6 7 2
2020-04-30 12:30:46,591 	Reference:  2 7 6 3 1
2020-04-30 12:30:46,591 	Hypothesis: 2 7 7 3 1
2020-04-30 12:30:46,591 Validation result (greedy) at epoch  16, step      110: bleu:  29.54, loss: 1457.3014, ppl:   2.7133, duration: 0.6132s
2020-04-30 12:30:48,472 Epoch  16: total training loss 58.95
2020-04-30 12:30:48,472 EPOCH 17
2020-04-30 12:30:49,830 Epoch  17: total training loss 54.90
2020-04-30 12:30:49,836 EPOCH 18
2020-04-30 12:30:49,975 Epoch  18 Step:      120 Batch Loss:     4.049559 Tokens per Sec:     1221, Lr: 0.002500
2020-04-30 12:30:50,642 Hooray! New best validation result [eval_metric]!
2020-04-30 12:30:50,643 Saving new checkpoint.
2020-04-30 12:30:50,657 Example #0
2020-04-30 12:30:50,658 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:30:50,658 	Raw hypothesis: ['5', '7', '3', '7']
2020-04-30 12:30:50,659 	Source:     1 2 3 4 5
2020-04-30 12:30:50,659 	Reference:  5 4 3 2 1
2020-04-30 12:30:50,660 	Hypothesis: 5 7 3 7
2020-04-30 12:30:50,660 Example #3
2020-04-30 12:30:50,660 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:30:50,660 	Raw hypothesis: ['0', '8', '9', '8', '5', '5', '3']
2020-04-30 12:30:50,661 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:30:50,661 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:30:50,661 	Hypothesis: 0 8 9 8 5 5 3
2020-04-30 12:30:50,662 Example #6
2020-04-30 12:30:50,662 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:30:50,662 	Raw hypothesis: ['2', '7', '7', '3', '1']
2020-04-30 12:30:50,663 	Source:     1 3 6 7 2
2020-04-30 12:30:50,663 	Reference:  2 7 6 3 1
2020-04-30 12:30:50,663 	Hypothesis: 2 7 7 3 1
2020-04-30 12:30:50,664 Validation result (greedy) at epoch  18, step      120: bleu:  32.53, loss: 1357.8093, ppl:   2.5345, duration: 0.6861s
2020-04-30 12:30:54,345 Epoch  18: total training loss 52.40
2020-04-30 12:30:54,350 EPOCH 19
2020-04-30 12:30:55,923 Epoch  19 Step:      130 Batch Loss:    13.129283 Tokens per Sec:      570, Lr: 0.002500
2020-04-30 12:30:56,902 Example #0
2020-04-30 12:30:56,903 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:30:56,903 	Raw hypothesis: ['5', '7', '3', '7']
2020-04-30 12:30:56,903 	Source:     1 2 3 4 5
2020-04-30 12:30:56,904 	Reference:  5 4 3 2 1
2020-04-30 12:30:56,904 	Hypothesis: 5 7 3 7
2020-04-30 12:30:56,904 Example #3
2020-04-30 12:30:56,905 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:30:56,905 	Raw hypothesis: ['0', '8', '0', '8', '9', '1', '5', '5']
2020-04-30 12:30:56,908 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:30:56,909 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:30:56,909 	Hypothesis: 0 8 0 8 9 1 5 5
2020-04-30 12:30:56,909 Example #6
2020-04-30 12:30:56,910 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:30:56,910 	Raw hypothesis: ['2', '7', '3', '1']
2020-04-30 12:30:56,910 	Source:     1 3 6 7 2
2020-04-30 12:30:56,910 	Reference:  2 7 6 3 1
2020-04-30 12:30:56,911 	Hypothesis: 2 7 3 1
2020-04-30 12:30:56,911 Validation result (greedy) at epoch  19, step      130: bleu:  27.06, loss: 1295.5609, ppl:   2.4287, duration: 0.9772s
2020-04-30 12:31:00,102 Epoch  19: total training loss 51.59
2020-04-30 12:31:00,104 EPOCH 20
2020-04-30 12:31:02,010 Epoch  20 Step:      140 Batch Loss:    12.949421 Tokens per Sec:      767, Lr: 0.002500
2020-04-30 12:31:02,931 Hooray! New best validation result [eval_metric]!
2020-04-30 12:31:02,932 Saving new checkpoint.
2020-04-30 12:31:02,935 Example #0
2020-04-30 12:31:02,935 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:31:02,935 	Raw hypothesis: ['5', '7', '3', '7', '3']
2020-04-30 12:31:02,935 	Source:     1 2 3 4 5
2020-04-30 12:31:02,935 	Reference:  5 4 3 2 1
2020-04-30 12:31:02,936 	Hypothesis: 5 7 3 7 3
2020-04-30 12:31:02,936 Example #3
2020-04-30 12:31:02,936 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:31:02,936 	Raw hypothesis: ['0', '8', '5', '9', '8', '5', '3', '1']
2020-04-30 12:31:02,936 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:31:02,936 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:31:02,936 	Hypothesis: 0 8 5 9 8 5 3 1
2020-04-30 12:31:02,936 Example #6
2020-04-30 12:31:02,936 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:31:02,936 	Raw hypothesis: ['2', '7', '7', '3', '1']
2020-04-30 12:31:02,936 	Source:     1 3 6 7 2
2020-04-30 12:31:02,936 	Reference:  2 7 6 3 1
2020-04-30 12:31:02,936 	Hypothesis: 2 7 7 3 1
2020-04-30 12:31:02,936 Validation result (greedy) at epoch  20, step      140: bleu:  36.39, loss: 1186.6112, ppl:   2.2541, duration: 0.9254s
2020-04-30 12:31:05,230 Epoch  20: total training loss 48.94
2020-04-30 12:31:05,230 EPOCH 21
2020-04-30 12:31:05,804 Epoch  21: total training loss 46.75
2020-04-30 12:31:05,805 EPOCH 22
2020-04-30 12:31:06,215 Epoch  22 Step:      150 Batch Loss:     7.944048 Tokens per Sec:     1745, Lr: 0.002500
2020-04-30 12:31:06,826 Hooray! New best validation result [eval_metric]!
2020-04-30 12:31:06,826 Saving new checkpoint.
2020-04-30 12:31:06,831 Example #0
2020-04-30 12:31:06,832 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:31:06,832 	Raw hypothesis: ['5', '7', '3', '7']
2020-04-30 12:31:06,832 	Source:     1 2 3 4 5
2020-04-30 12:31:06,832 	Reference:  5 4 3 2 1
2020-04-30 12:31:06,832 	Hypothesis: 5 7 3 7
2020-04-30 12:31:06,832 Example #3
2020-04-30 12:31:06,832 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:31:06,832 	Raw hypothesis: ['0', '8', '5', '5', '3', '5', '5']
2020-04-30 12:31:06,832 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:31:06,832 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:31:06,832 	Hypothesis: 0 8 5 5 3 5 5
2020-04-30 12:31:06,832 Example #6
2020-04-30 12:31:06,832 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:31:06,833 	Raw hypothesis: ['2', '7', '7', '3', '1']
2020-04-30 12:31:06,833 	Source:     1 3 6 7 2
2020-04-30 12:31:06,833 	Reference:  2 7 6 3 1
2020-04-30 12:31:06,833 	Hypothesis: 2 7 7 3 1
2020-04-30 12:31:06,833 Validation result (greedy) at epoch  22, step      150: bleu:  49.17, loss: 1128.5607, ppl:   2.1662, duration: 0.6171s
2020-04-30 12:31:09,228 Epoch  22: total training loss 46.44
2020-04-30 12:31:09,228 EPOCH 23
2020-04-30 12:31:09,856 Epoch  23 Step:      160 Batch Loss:     0.204735 Tokens per Sec:     1870, Lr: 0.002500
2020-04-30 12:31:10,304 Hooray! New best validation result [eval_metric]!
2020-04-30 12:31:10,304 Saving new checkpoint.
2020-04-30 12:31:10,311 Example #0
2020-04-30 12:31:10,311 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:31:10,312 	Raw hypothesis: ['5', '7', '3', '7']
2020-04-30 12:31:10,312 	Source:     1 2 3 4 5
2020-04-30 12:31:10,312 	Reference:  5 4 3 2 1
2020-04-30 12:31:10,312 	Hypothesis: 5 7 3 7
2020-04-30 12:31:10,312 Example #3
2020-04-30 12:31:10,312 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:31:10,312 	Raw hypothesis: ['0', '8', '5', '9', '0', '1', '5', '5']
2020-04-30 12:31:10,312 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:31:10,313 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:31:10,313 	Hypothesis: 0 8 5 9 0 1 5 5
2020-04-30 12:31:10,313 Example #6
2020-04-30 12:31:10,313 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:31:10,313 	Raw hypothesis: ['2', '7', '6', '3', '1']
2020-04-30 12:31:10,313 	Source:     1 3 6 7 2
2020-04-30 12:31:10,313 	Reference:  2 7 6 3 1
2020-04-30 12:31:10,314 	Hypothesis: 2 7 6 3 1
2020-04-30 12:31:10,314 Validation result (greedy) at epoch  23, step      160: bleu:  55.18, loss: 1017.5532, ppl:   2.0076, duration: 0.4575s
2020-04-30 12:31:12,076 Epoch  23: total training loss 41.71
2020-04-30 12:31:12,077 EPOCH 24
2020-04-30 12:31:12,718 Epoch  24: total training loss 40.74
2020-04-30 12:31:12,720 EPOCH 25
2020-04-30 12:31:13,012 Epoch  25 Step:      170 Batch Loss:     6.326669 Tokens per Sec:     1512, Lr: 0.002500
2020-04-30 12:31:13,599 Hooray! New best validation result [eval_metric]!
2020-04-30 12:31:13,601 Saving new checkpoint.
2020-04-30 12:31:13,616 Example #0
2020-04-30 12:31:13,616 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:31:13,617 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-04-30 12:31:13,617 	Source:     1 2 3 4 5
2020-04-30 12:31:13,617 	Reference:  5 4 3 2 1
2020-04-30 12:31:13,618 	Hypothesis: 5 4 3 2 1
2020-04-30 12:31:13,618 Example #3
2020-04-30 12:31:13,618 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:31:13,618 	Raw hypothesis: ['0', '8', '0', '0', '8', '5', '5', '3', '1']
2020-04-30 12:31:13,619 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:31:13,619 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:31:13,619 	Hypothesis: 0 8 0 0 8 5 5 3 1
2020-04-30 12:31:13,620 Example #6
2020-04-30 12:31:13,620 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:31:13,620 	Raw hypothesis: ['2', '7', '6', '3', '1']
2020-04-30 12:31:13,620 	Source:     1 3 6 7 2
2020-04-30 12:31:13,621 	Reference:  2 7 6 3 1
2020-04-30 12:31:13,621 	Hypothesis: 2 7 6 3 1
2020-04-30 12:31:13,621 Validation result (greedy) at epoch  25, step      170: bleu:  57.48, loss: 939.5974, ppl:   1.9032, duration: 0.6081s
2020-04-30 12:31:15,967 Epoch  25: total training loss 39.35
2020-04-30 12:31:15,969 EPOCH 26
2020-04-30 12:31:16,614 Epoch  26 Step:      180 Batch Loss:     4.758552 Tokens per Sec:     1602, Lr: 0.002500
2020-04-30 12:31:17,194 Hooray! New best validation result [eval_metric]!
2020-04-30 12:31:17,194 Saving new checkpoint.
2020-04-30 12:31:17,206 Example #0
2020-04-30 12:31:17,207 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:31:17,207 	Raw hypothesis: ['5', '7', '3', '2', '1']
2020-04-30 12:31:17,207 	Source:     1 2 3 4 5
2020-04-30 12:31:17,207 	Reference:  5 4 3 2 1
2020-04-30 12:31:17,208 	Hypothesis: 5 7 3 2 1
2020-04-30 12:31:17,208 Example #3
2020-04-30 12:31:17,209 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:31:17,209 	Raw hypothesis: ['0', '8', '5', '9', '0', '1', '5']
2020-04-30 12:31:17,209 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:31:17,209 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:31:17,209 	Hypothesis: 0 8 5 9 0 1 5
2020-04-30 12:31:17,210 Example #6
2020-04-30 12:31:17,210 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:31:17,210 	Raw hypothesis: ['2', '7', '6', '3', '1']
2020-04-30 12:31:17,210 	Source:     1 3 6 7 2
2020-04-30 12:31:17,210 	Reference:  2 7 6 3 1
2020-04-30 12:31:17,210 	Hypothesis: 2 7 6 3 1
2020-04-30 12:31:17,211 Validation result (greedy) at epoch  26, step      180: bleu:  61.96, loss: 887.0424, ppl:   1.8360, duration: 0.5948s
2020-04-30 12:31:18,950 Epoch  26: total training loss 38.15
2020-04-30 12:31:18,950 EPOCH 27
2020-04-30 12:31:19,852 Epoch  27: total training loss 35.26
2020-04-30 12:31:19,854 EPOCH 28
2020-04-30 12:31:20,068 Epoch  28 Step:      190 Batch Loss:     5.118804 Tokens per Sec:     1688, Lr: 0.002500
2020-04-30 12:31:20,482 Example #0
2020-04-30 12:31:20,483 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:31:20,483 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-04-30 12:31:20,483 	Source:     1 2 3 4 5
2020-04-30 12:31:20,483 	Reference:  5 4 3 2 1
2020-04-30 12:31:20,483 	Hypothesis: 5 4 3 2 1
2020-04-30 12:31:20,483 Example #3
2020-04-30 12:31:20,483 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:31:20,483 	Raw hypothesis: ['0', '0', '8', '5', '9', '0', '1', '5', '5']
2020-04-30 12:31:20,484 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:31:20,484 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:31:20,484 	Hypothesis: 0 0 8 5 9 0 1 5 5
2020-04-30 12:31:20,484 Example #6
2020-04-30 12:31:20,484 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:31:20,484 	Raw hypothesis: ['2', '7', '6', '3', '1']
2020-04-30 12:31:20,484 	Source:     1 3 6 7 2
2020-04-30 12:31:20,484 	Reference:  2 7 6 3 1
2020-04-30 12:31:20,484 	Hypothesis: 2 7 6 3 1
2020-04-30 12:31:20,484 Validation result (greedy) at epoch  28, step      190: bleu:  61.80, loss: 813.2328, ppl:   1.7454, duration: 0.4151s
2020-04-30 12:31:22,380 Epoch  28: total training loss 32.57
2020-04-30 12:31:22,381 EPOCH 29
2020-04-30 12:31:23,158 Epoch  29 Step:      200 Batch Loss:     1.631153 Tokens per Sec:      958, Lr: 0.002500
2020-04-30 12:31:23,982 Hooray! New best validation result [eval_metric]!
2020-04-30 12:31:23,982 Saving new checkpoint.
2020-04-30 12:31:23,991 Example #0
2020-04-30 12:31:23,991 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:31:23,992 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-04-30 12:31:23,992 	Source:     1 2 3 4 5
2020-04-30 12:31:23,992 	Reference:  5 4 3 2 1
2020-04-30 12:31:23,992 	Hypothesis: 5 4 3 2 1
2020-04-30 12:31:23,993 Example #3
2020-04-30 12:31:23,993 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:31:23,993 	Raw hypothesis: ['0', '8', '5', '9', '0', '1', '5', '5']
2020-04-30 12:31:23,993 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:31:23,993 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:31:23,993 	Hypothesis: 0 8 5 9 0 1 5 5
2020-04-30 12:31:23,993 Example #6
2020-04-30 12:31:23,994 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:31:23,994 	Raw hypothesis: ['2', '7', '6', '3', '1']
2020-04-30 12:31:23,994 	Source:     1 3 6 7 2
2020-04-30 12:31:23,994 	Reference:  2 7 6 3 1
2020-04-30 12:31:23,994 	Hypothesis: 2 7 6 3 1
2020-04-30 12:31:23,994 Validation result (greedy) at epoch  29, step      200: bleu:  65.64, loss: 730.9971, ppl:   1.6498, duration: 0.8358s
2020-04-30 12:31:26,867 Epoch  29: total training loss 29.84
2020-04-30 12:31:26,867 EPOCH 30
2020-04-30 12:31:28,061 Epoch  30 Step:      210 Batch Loss:     1.517388 Tokens per Sec:     1224, Lr: 0.002500
2020-04-30 12:31:28,930 Hooray! New best validation result [eval_metric]!
2020-04-30 12:31:28,931 Saving new checkpoint.
2020-04-30 12:31:28,944 Example #0
2020-04-30 12:31:28,944 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:31:28,945 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-04-30 12:31:28,945 	Source:     1 2 3 4 5
2020-04-30 12:31:28,945 	Reference:  5 4 3 2 1
2020-04-30 12:31:28,945 	Hypothesis: 5 4 3 2 1
2020-04-30 12:31:28,945 Example #3
2020-04-30 12:31:28,945 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:31:28,945 	Raw hypothesis: ['0', '8', '5', '9', '0', '1', '5']
2020-04-30 12:31:28,945 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:31:28,945 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:31:28,946 	Hypothesis: 0 8 5 9 0 1 5
2020-04-30 12:31:28,946 Example #6
2020-04-30 12:31:28,946 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:31:28,946 	Raw hypothesis: ['2', '7', '6', '3', '1']
2020-04-30 12:31:28,946 	Source:     1 3 6 7 2
2020-04-30 12:31:28,946 	Reference:  2 7 6 3 1
2020-04-30 12:31:28,946 	Hypothesis: 2 7 6 3 1
2020-04-30 12:31:28,946 Validation result (greedy) at epoch  30, step      210: bleu:  69.90, loss: 643.2831, ppl:   1.5536, duration: 0.8837s
2020-04-30 12:31:31,223 Epoch  30: total training loss 28.52
2020-04-30 12:31:31,223 EPOCH 31
2020-04-30 12:31:32,050 Epoch  31: total training loss 26.15
2020-04-30 12:31:32,050 EPOCH 32
2020-04-30 12:31:32,259 Epoch  32 Step:      220 Batch Loss:     1.244650 Tokens per Sec:     3886, Lr: 0.002500
2020-04-30 12:31:32,698 Hooray! New best validation result [eval_metric]!
2020-04-30 12:31:32,698 Saving new checkpoint.
2020-04-30 12:31:32,704 Example #0
2020-04-30 12:31:32,705 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:31:32,705 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-04-30 12:31:32,705 	Source:     1 2 3 4 5
2020-04-30 12:31:32,705 	Reference:  5 4 3 2 1
2020-04-30 12:31:32,705 	Hypothesis: 5 4 3 2 1
2020-04-30 12:31:32,705 Example #3
2020-04-30 12:31:32,705 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:31:32,705 	Raw hypothesis: ['0', '8', '5', '9', '0', '1', '5']
2020-04-30 12:31:32,705 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:31:32,706 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:31:32,706 	Hypothesis: 0 8 5 9 0 1 5
2020-04-30 12:31:32,706 Example #6
2020-04-30 12:31:32,706 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:31:32,706 	Raw hypothesis: ['2', '7', '6', '3', '1']
2020-04-30 12:31:32,706 	Source:     1 3 6 7 2
2020-04-30 12:31:32,706 	Reference:  2 7 6 3 1
2020-04-30 12:31:32,706 	Hypothesis: 2 7 6 3 1
2020-04-30 12:31:32,706 Validation result (greedy) at epoch  32, step      220: bleu:  70.98, loss: 560.7201, ppl:   1.4682, duration: 0.4471s
2020-04-30 12:31:34,693 Epoch  32: total training loss 24.02
2020-04-30 12:31:34,697 EPOCH 33
2020-04-30 12:31:35,605 Epoch  33 Step:      230 Batch Loss:     0.110804 Tokens per Sec:     1424, Lr: 0.002500
2020-04-30 12:31:35,998 Hooray! New best validation result [eval_metric]!
2020-04-30 12:31:35,998 Saving new checkpoint.
2020-04-30 12:31:36,003 Example #0
2020-04-30 12:31:36,003 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:31:36,003 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-04-30 12:31:36,003 	Source:     1 2 3 4 5
2020-04-30 12:31:36,004 	Reference:  5 4 3 2 1
2020-04-30 12:31:36,004 	Hypothesis: 5 4 3 2 1
2020-04-30 12:31:36,004 Example #3
2020-04-30 12:31:36,004 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:31:36,004 	Raw hypothesis: ['0', '8', '5', '9', '0', '1', '5', '5']
2020-04-30 12:31:36,004 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:31:36,004 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:31:36,004 	Hypothesis: 0 8 5 9 0 1 5 5
2020-04-30 12:31:36,004 Example #6
2020-04-30 12:31:36,005 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:31:36,005 	Raw hypothesis: ['2', '7', '6', '3', '1']
2020-04-30 12:31:36,005 	Source:     1 3 6 7 2
2020-04-30 12:31:36,005 	Reference:  2 7 6 3 1
2020-04-30 12:31:36,005 	Hypothesis: 2 7 6 3 1
2020-04-30 12:31:36,005 Validation result (greedy) at epoch  33, step      230: bleu:  82.07, loss: 493.4034, ppl:   1.4021, duration: 0.3992s
2020-04-30 12:31:37,634 Epoch  33: total training loss 22.53
2020-04-30 12:31:37,635 EPOCH 34
2020-04-30 12:31:38,614 Epoch  34: total training loss 21.33
2020-04-30 12:31:38,615 EPOCH 35
2020-04-30 12:31:38,892 Epoch  35 Step:      240 Batch Loss:     1.440976 Tokens per Sec:     1136, Lr: 0.002500
2020-04-30 12:31:39,524 Hooray! New best validation result [eval_metric]!
2020-04-30 12:31:39,524 Saving new checkpoint.
2020-04-30 12:31:39,529 Example #0
2020-04-30 12:31:39,529 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:31:39,529 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-04-30 12:31:39,529 	Source:     1 2 3 4 5
2020-04-30 12:31:39,529 	Reference:  5 4 3 2 1
2020-04-30 12:31:39,529 	Hypothesis: 5 4 3 2 1
2020-04-30 12:31:39,529 Example #3
2020-04-30 12:31:39,529 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:31:39,529 	Raw hypothesis: ['0', '8', '5', '9', '0', '4', '1', '5']
2020-04-30 12:31:39,529 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:31:39,529 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:31:39,530 	Hypothesis: 0 8 5 9 0 4 1 5
2020-04-30 12:31:39,530 Example #6
2020-04-30 12:31:39,530 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:31:39,530 	Raw hypothesis: ['2', '7', '6', '3', '1']
2020-04-30 12:31:39,530 	Source:     1 3 6 7 2
2020-04-30 12:31:39,530 	Reference:  2 7 6 3 1
2020-04-30 12:31:39,530 	Hypothesis: 2 7 6 3 1
2020-04-30 12:31:39,530 Validation result (greedy) at epoch  35, step      240: bleu: 100.00, loss: 426.5319, ppl:   1.3393, duration: 0.6370s
2020-04-30 12:31:41,652 Epoch  35: total training loss 19.03
2020-04-30 12:31:41,653 EPOCH 36
2020-04-30 12:31:42,059 Epoch  36 Step:      250 Batch Loss:     0.485799 Tokens per Sec:     2518, Lr: 0.002500
2020-04-30 12:31:42,407 Example #0
2020-04-30 12:31:42,408 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:31:42,408 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-04-30 12:31:42,408 	Source:     1 2 3 4 5
2020-04-30 12:31:42,408 	Reference:  5 4 3 2 1
2020-04-30 12:31:42,408 	Hypothesis: 5 4 3 2 1
2020-04-30 12:31:42,408 Example #3
2020-04-30 12:31:42,408 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:31:42,409 	Raw hypothesis: ['0', '8', '5', '9', '0', '4', '1', '5']
2020-04-30 12:31:42,409 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:31:42,409 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:31:42,409 	Hypothesis: 0 8 5 9 0 4 1 5
2020-04-30 12:31:42,409 Example #6
2020-04-30 12:31:42,409 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:31:42,409 	Raw hypothesis: ['2', '7', '6', '3', '1']
2020-04-30 12:31:42,409 	Source:     1 3 6 7 2
2020-04-30 12:31:42,409 	Reference:  2 7 6 3 1
2020-04-30 12:31:42,410 	Hypothesis: 2 7 6 3 1
2020-04-30 12:31:42,410 Validation result (greedy) at epoch  36, step      250: bleu: 100.00, loss: 361.3846, ppl:   1.2808, duration: 0.3497s
2020-04-30 12:31:44,166 Epoch  36: total training loss 17.02
2020-04-30 12:31:44,166 EPOCH 37
2020-04-30 12:31:44,988 Epoch  37: total training loss 15.48
2020-04-30 12:31:44,989 EPOCH 38
2020-04-30 12:31:45,109 Epoch  38 Step:      260 Batch Loss:     1.255383 Tokens per Sec:     1880, Lr: 0.002500
2020-04-30 12:31:45,717 Example #0
2020-04-30 12:31:45,717 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:31:45,717 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-04-30 12:31:45,717 	Source:     1 2 3 4 5
2020-04-30 12:31:45,718 	Reference:  5 4 3 2 1
2020-04-30 12:31:45,718 	Hypothesis: 5 4 3 2 1
2020-04-30 12:31:45,718 Example #3
2020-04-30 12:31:45,718 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:31:45,718 	Raw hypothesis: ['0', '8', '5', '9', '0', '4', '1', '5']
2020-04-30 12:31:45,718 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:31:45,718 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:31:45,718 	Hypothesis: 0 8 5 9 0 4 1 5
2020-04-30 12:31:45,719 Example #6
2020-04-30 12:31:45,719 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:31:45,719 	Raw hypothesis: ['2', '7', '6', '3', '1']
2020-04-30 12:31:45,719 	Source:     1 3 6 7 2
2020-04-30 12:31:45,719 	Reference:  2 7 6 3 1
2020-04-30 12:31:45,719 	Hypothesis: 2 7 6 3 1
2020-04-30 12:31:45,719 Validation result (greedy) at epoch  38, step      260: bleu: 100.00, loss: 306.3004, ppl:   1.2334, duration: 0.6106s
2020-04-30 12:31:48,030 Epoch  38: total training loss 14.02
2020-04-30 12:31:48,032 EPOCH 39
2020-04-30 12:31:48,311 Epoch  39 Step:      270 Batch Loss:     1.366618 Tokens per Sec:     2002, Lr: 0.002500
2020-04-30 12:31:48,679 Example #0
2020-04-30 12:31:48,679 	Raw source:     ['1', '2', '3', '4', '5']
2020-04-30 12:31:48,679 	Raw hypothesis: ['5', '4', '3', '2', '1']
2020-04-30 12:31:48,679 	Source:     1 2 3 4 5
2020-04-30 12:31:48,679 	Reference:  5 4 3 2 1
2020-04-30 12:31:48,680 	Hypothesis: 5 4 3 2 1
2020-04-30 12:31:48,680 Example #3
2020-04-30 12:31:48,680 	Raw source:     ['5', '1', '4', '0', '9', '5', '8', '0']
2020-04-30 12:31:48,680 	Raw hypothesis: ['0', '8', '5', '9', '0', '4', '1', '5']
2020-04-30 12:31:48,680 	Source:     5 1 4 0 9 5 8 0
2020-04-30 12:31:48,680 	Reference:  0 8 5 9 0 4 1 5
2020-04-30 12:31:48,680 	Hypothesis: 0 8 5 9 0 4 1 5
2020-04-30 12:31:48,680 Example #6
2020-04-30 12:31:48,680 	Raw source:     ['1', '3', '6', '7', '2']
2020-04-30 12:31:48,681 	Raw hypothesis: ['2', '7', '6', '3', '1']
2020-04-30 12:31:48,681 	Source:     1 3 6 7 2
2020-04-30 12:31:48,681 	Reference:  2 7 6 3 1
2020-04-30 12:31:48,681 	Hypothesis: 2 7 6 3 1
2020-04-30 12:31:48,681 Validation result (greedy) at epoch  39, step      270: bleu: 100.00, loss: 276.9439, ppl:   1.2089, duration: 0.3693s
2020-04-30 12:31:50,883 Epoch  39: total training loss 13.58
2020-04-30 12:31:50,885 EPOCH 40
