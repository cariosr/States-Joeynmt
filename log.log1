Sample size:  256
State size:  24
Action size:  9
bleu_seq
You select the reward based on the sequence accuaracy bleu_seq
EPOCH %d 1
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.9 0.9

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 7 3]]
Reward:  [1.  0.8] 

0 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
1 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 

2 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
3 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 5 3]
Eval  :  [[2 4 5 3]]
Reward:  [1.  0.8 0.6] 

4 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
5 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
6 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 3]
Eval  :  [[2 4 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 6 3]
Eval  :  [[2 6 3]]
Reward:  [1.  0.8] 

EPOCH %d 2
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.81 0.81
2493 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2494 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2495 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2496 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2497 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2498 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2499 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 3
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.7290000000000001 0.7290000000000001
4986 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4987 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4988 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4989 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4990 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4991 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4992 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
As referece this first test on dev data. Is maded with the Q networks, initialized randomly : 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7167,  0.0667,  0.3410])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9378,  0.6153, -0.6642])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9584,  0.7692, -0.9055])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9540,  0.8120, -0.9279])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9512,  0.8205, -0.9322])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9491,  0.8240, -0.9336])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9477,  0.8256, -0.9341])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9469,  0.8265, -0.9344])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9464,  0.8269, -0.9346])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9461,  0.8272, -0.9346])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.  -0.2 -0.4 -0.6 -0.8 -1.  -1.2 -1.4 -1.6 -1.8] 

roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
So far:  [array([2])]  the state[:3] is:  tensor([-0.7554,  0.8335, -0.4593])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.9850,  0.9089, -0.9363])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9922,  0.9398, -0.9843])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9903,  0.9516, -0.9886])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9894,  0.9543, -0.9892])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9887,  0.9556, -0.9894])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9882,  0.9562, -0.9895])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9880,  0.9565, -0.9895])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9879,  0.9567, -0.9895])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9878,  0.9567, -0.9895])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.  -0.2 -0.4 -0.6 -0.8 -1.  -1.2 -1.4 -1.6 -1.8] 

roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
So far:  [array([2])]  the state[:3] is:  tensor([0.2954, 0.9133, 0.9181])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.5009,  0.9886,  0.3796])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9673,  0.9915, -0.7579])
So far:  [array([2]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9833,  0.9930, -0.9192])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9852,  0.9933, -0.9380])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9853,  0.9933, -0.9427])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9850,  0.9934, -0.9443])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9848,  0.9934, -0.9449])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9846,  0.9934, -0.9452])
So far:  [array([2]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9845,  0.9934, -0.9453])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.  -2.2 -0.4 -0.6 -0.8 -1.  -1.2 -1.4 -1.6 -1.8] 

roptimal:  tensor([[2, 4, 5]]) [[2 4 5 3]]
[1.  0.8 0.6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.  -0.2 -0.4 -0.6 -0.8 -1.  -1.2 -1.4 -1.6 -1.8] 

roptimal:  tensor([[2, 7, 6]]) [[2 7 6 3]]
[1.  0.8 0.6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  8  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.  -0.2 -0.4 -0.6 -0.8 -1.  -1.2 -1.4 -1.6 -1.8] 

roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  5  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.  -0.2 -0.4 -0.6 -0.8 -1.  -1.2 -1.4 -1.6 -1.8] 

roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  6  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.  -0.2 -0.4 -0.6 -0.8 -1.  -1.2 -1.4 -1.6 -1.8] 

roptimal:  tensor([[2, 6]]) [[2 6 3]]
[1.  0.8]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  4  6  3 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [ 1.  -2.2 -0.4 -0.6 -0.8 -1.  -1.2 -1.4 -1.6 -1.8] 

roptimal:  tensor([[2, 4, 6]]) [[2 4 6 3]]
[1.  0.8 0.6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  5  3 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.  -0.2 -0.4 -0.6 -0.8 -1.  -1.2 -1.4 -1.6 -1.8] 

roptimal:  tensor([[2, 7, 5]]) [[2 7 5 3]]
[1.  0.8 0.6]

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [ 2  7  3 10 10 10 10 10 10 10 10]
Eval  :  [[2 4 4 4 4 4 4 4 4 4 4]]
Reward:  [-1.  -0.2 -0.4 -0.6 -0.8 -1.  -1.2 -1.4 -1.6 -1.8] 

roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 6, 7]]) [[2 6 7 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 7, 6]]) [[2 7 6 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 6]]) [[2 6 3]]
[1.  0.8]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 8, 8]]) [[2 8 8 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 5, 4]]) [[2 5 4 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 4, 8]]) [[2 4 8 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 7, 8]]) [[2 7 8 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 6, 5]]) [[2 6 5 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 7, 6]]) [[2 7 6 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 4, 7]]) [[2 4 7 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 6]]) [[2 6 3]]
[1.  0.8]
roptimal:  tensor([[2, 8, 6]]) [[2 8 6 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 6, 6]]) [[2 6 6 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 4, 6]]) [[2 4 6 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 6, 8]]) [[2 6 8 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 4, 6]]) [[2 4 6 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 5, 6]]) [[2 5 6 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 6]]) [[2 6 3]]
[1.  0.8]
roptimal:  tensor([[2, 6, 4]]) [[2 6 4 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 6]]) [[2 6 3]]
[1.  0.8]
roptimal:  tensor([[2, 6, 6]]) [[2 6 6 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 5, 7]]) [[2 5 7 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 6, 8]]) [[2 6 8 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 4, 6]]) [[2 4 6 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 4, 7]]) [[2 4 7 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 4, 7]]) [[2 4 7 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 5, 8]]) [[2 5 8 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 5, 5]]) [[2 5 5 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 5, 6]]) [[2 5 6 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 4, 4]]) [[2 4 4 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 6, 7]]) [[2 6 7 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 4, 8]]) [[2 4 8 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 5, 8]]) [[2 5 8 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 8, 6]]) [[2 8 6 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 6]]) [[2 6 3]]
[1.  0.8]
roptimal:  tensor([[2, 5, 6]]) [[2 5 6 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 6]]) [[2 6 3]]
[1.  0.8]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 6, 5]]) [[2 6 5 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 4, 6]]) [[2 4 6 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 8, 8]]) [[2 8 8 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 6, 6]]) [[2 6 6 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 7, 4]]) [[2 7 4 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 5, 7]]) [[2 5 7 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 4, 4]]) [[2 4 4 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 4, 8]]) [[2 4 8 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 6, 6]]) [[2 6 6 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 4, 7]]) [[2 4 7 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 5]]) [[2 5 3]]
[1.  0.8]
roptimal:  tensor([[2, 5, 4]]) [[2 5 4 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 8]]) [[2 8 3]]
[1.  0.8]
roptimal:  tensor([[2, 4, 7]]) [[2 4 7 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 7, 7]]) [[2 7 7 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 7]]) [[2 7 3]]
[1.  0.8]
roptimal:  tensor([[2, 5, 8]]) [[2 5 8 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 8, 6]]) [[2 8 6 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 7, 5]]) [[2 7 5 3]]
[1.  0.8 0.6]
roptimal:  tensor([[2, 4]]) [[2 4 3]]
[1.  0.8]
roptimal:  tensor([[2, 6]]) [[2 6 3]]
[1.  0.8]
roptimal:  tensor([[2, 7, 6]]) [[2 7 6 3]]
[1.  0.8 0.6]
The optimal reward is:  216.60000000000042
valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1', '1 1 1 1 1 1 1 1 1 1']
1  r_total and score:  38.8 0.0
Current Bleu score is:  0.0
learn step counter:  1
dev_network_count:  1
Using pretraining...
learn step counter:  51
dev_network_count:  1
learn step counter:  101
dev_network_count:  1
learn step counter:  151
dev_network_count:  1
learn step counter:  201
dev_network_count:  1
learn step counter:  251
dev_network_count:  1

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7167,  0.0667,  0.3410])
So far:  [array([2]), array([6])]  the state[:3] is:  tensor([-0.9057,  0.6030, -0.6316])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

So far:  [array([2])]  the state[:3] is:  tensor([-0.7554,  0.8335, -0.4593])
So far:  [array([2]), array([8])]  the state[:3] is:  tensor([-0.9850,  0.8968, -0.9234])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 

So far:  [array([2])]  the state[:3] is:  tensor([0.2954, 0.9133, 0.9181])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.5009,  0.9886,  0.3796])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9601,  0.9921, -0.7420])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 5 3]
Eval  :  [[2 4 7 3]]
Reward:  [ 1.  -2.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 6 3]
Eval  :  [[2 6 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 5 3]
Eval  :  [[2 5 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 6 3]
Eval  :  [[2 6 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 6 3]
Eval  :  [[2 8 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 5 3]
Eval  :  [[2 7 7 3]]
Reward:  [ 1.  -2.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['4', '2', '1 3', '4 4', '2', '0', '4', '2 4', '3 3', '4']
2  r_total and score:  276.0000000000004 49.56385459568427
Current Bleu score is:  49.56385459568427
learn step counter:  301
dev_network_count:  2
learn step counter:  351
dev_network_count:  2
learn step counter:  401
dev_network_count:  2
learn step counter:  451
dev_network_count:  2
learn step counter:  501
dev_network_count:  2
learn step counter:  551
dev_network_count:  2

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7167,  0.0667,  0.3410])
So far:  [array([2]), array([6])]  the state[:3] is:  tensor([-0.9057,  0.6030, -0.6316])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

So far:  [array([2])]  the state[:3] is:  tensor([-0.7554,  0.8335, -0.4593])
So far:  [array([2]), array([8])]  the state[:3] is:  tensor([-0.9850,  0.8968, -0.9234])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 

So far:  [array([2])]  the state[:3] is:  tensor([0.2954, 0.9133, 0.9181])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.5256,  0.9823,  0.5156])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9656,  0.9911, -0.7185])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 5 3]
Eval  :  [[2 5 4 3]]
Reward:  [-1.  -0.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 6 3]
Eval  :  [[2 6 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 5 3]
Eval  :  [[2 5 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 6 3]
Eval  :  [[2 6 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 6 3]
Eval  :  [[2 8 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 5 3]
Eval  :  [[2 5 7 3]]
Reward:  [-1.  -0.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['4', '2', '0 1', '4 4', '2', '0', '4', '2 4', '0 3', '4']
3  r_total and score:  270.8000000000004 51.83960757134804
Current Bleu score is:  51.83960757134804
learn step counter:  601
dev_network_count:  3
learn step counter:  651
dev_network_count:  3
learn step counter:  701
dev_network_count:  3
learn step counter:  751
dev_network_count:  3
learn step counter:  801
dev_network_count:  3
learn step counter:  851
dev_network_count:  3

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7167,  0.0667,  0.3410])
So far:  [array([2]), array([6])]  the state[:3] is:  tensor([-0.9057,  0.6030, -0.6316])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

So far:  [array([2])]  the state[:3] is:  tensor([-0.7554,  0.8335, -0.4593])
So far:  [array([2]), array([8])]  the state[:3] is:  tensor([-0.9850,  0.8968, -0.9234])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 

So far:  [array([2])]  the state[:3] is:  tensor([0.2954, 0.9133, 0.9181])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.5256,  0.9823,  0.5156])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9656,  0.9911, -0.7185])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 5 3]
Eval  :  [[2 5 4 3]]
Reward:  [-1.  -0.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 6 3]
Eval  :  [[2 6 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 5 3]
Eval  :  [[2 5 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 6 3]
Eval  :  [[2 6 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 6 3]
Eval  :  [[2 8 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 5 3]
Eval  :  [[2 5 7 3]]
Reward:  [-1.  -0.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['4', '2', '0 1', '4 4', '2', '0', '4', '2 4', '0 3', '4']
4  r_total and score:  264.20000000000044 56.511488983186176
Current Bleu score is:  56.511488983186176
learn step counter:  901
dev_network_count:  4
learn step counter:  951
dev_network_count:  4
EPOCH %d 4
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.6561 0.6561
2479 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2480 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2481 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2482 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
Starting using Q target net....
2483 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2484 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2485 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  1001
dev_network_count:  4
learn step counter:  1051
dev_network_count:  4
learn step counter:  1101
dev_network_count:  4
learn step counter:  1151
dev_network_count:  4

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7167,  0.0667,  0.3410])
So far:  [array([2]), array([6])]  the state[:3] is:  tensor([-0.9057,  0.6030, -0.6316])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

So far:  [array([2])]  the state[:3] is:  tensor([-0.7554,  0.8335, -0.4593])
So far:  [array([2]), array([8])]  the state[:3] is:  tensor([-0.9850,  0.8968, -0.9234])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 

So far:  [array([2])]  the state[:3] is:  tensor([0.2954, 0.9133, 0.9181])
So far:  [array([2]), array([5])]  the state[:3] is:  tensor([-0.5256,  0.9823,  0.5156])
So far:  [array([2]), array([5]), array([4])]  the state[:3] is:  tensor([-0.9656,  0.9911, -0.7185])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 5 3]
Eval  :  [[2 5 4 3]]
Reward:  [-1.  -0.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 6 3]
Eval  :  [[2 6 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 5 3]
Eval  :  [[2 5 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 6 3]
Eval  :  [[2 6 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 6 3]
Eval  :  [[2 8 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 5 3]
Eval  :  [[2 5 7 3]]
Reward:  [-1.  -0.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['4', '2', '0 1', '4 4', '2', '0', '4', '2 4', '0 3', '4']
5  r_total and score:  260.8000000000004 56.633681297993704
Current Bleu score is:  56.633681297993704
learn step counter:  1201
dev_network_count:  5
learn step counter:  1251
dev_network_count:  5
learn step counter:  1301
dev_network_count:  5
learn step counter:  1351
dev_network_count:  5
learn step counter:  1401
dev_network_count:  5
learn step counter:  1451
dev_network_count:  5

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7167,  0.0667,  0.3410])
So far:  [array([2]), array([6])]  the state[:3] is:  tensor([-0.9057,  0.6030, -0.6316])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

So far:  [array([2])]  the state[:3] is:  tensor([-0.7554,  0.8335, -0.4593])
So far:  [array([2]), array([8])]  the state[:3] is:  tensor([-0.9850,  0.8968, -0.9234])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 

So far:  [array([2])]  the state[:3] is:  tensor([0.2954, 0.9133, 0.9181])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.5009,  0.9886,  0.3796])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9601,  0.9921, -0.7420])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 5 3]
Eval  :  [[2 4 7 3]]
Reward:  [ 1.  -2.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 6 3]
Eval  :  [[2 6 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 5 3]
Eval  :  [[2 5 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 6 3]
Eval  :  [[2 6 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 6 3]
Eval  :  [[2 8 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 5 3]
Eval  :  [[2 5 7 3]]
Reward:  [-1.  -0.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['4', '2', '1 3', '4 4', '2', '0', '4', '2 4', '0 3', '4']
6  r_total and score:  266.6000000000004 57.781568665270356
Current Bleu score is:  57.781568665270356
learn step counter:  1501
dev_network_count:  6
learn step counter:  1551
dev_network_count:  6
learn step counter:  1601
dev_network_count:  6
learn step counter:  1651
dev_network_count:  6
learn step counter:  1701
dev_network_count:  6
learn step counter:  1751
dev_network_count:  6

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7167,  0.0667,  0.3410])
So far:  [array([2]), array([6])]  the state[:3] is:  tensor([-0.9057,  0.6030, -0.6316])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

So far:  [array([2])]  the state[:3] is:  tensor([-0.7554,  0.8335, -0.4593])
So far:  [array([2]), array([8])]  the state[:3] is:  tensor([-0.9850,  0.8968, -0.9234])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 

So far:  [array([2])]  the state[:3] is:  tensor([0.2954, 0.9133, 0.9181])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.5009,  0.9886,  0.3796])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9673,  0.9915, -0.7579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 5 3]
Eval  :  [[2 4 4 3]]
Reward:  [ 1.  -2.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 6 3]
Eval  :  [[2 6 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 5 3]
Eval  :  [[2 5 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 6 3]
Eval  :  [[2 6 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 6 3]
Eval  :  [[2 8 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 5 3]
Eval  :  [[2 5 7 3]]
Reward:  [-1.  -0.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['4', '2', '1 1', '4 4', '2', '0', '4', '2 4', '0 3', '4']
7  r_total and score:  263.40000000000043 59.02432522055574
Current Bleu score is:  59.02432522055574
learn step counter:  1801
dev_network_count:  7
learn step counter:  1851
dev_network_count:  7
learn step counter:  1901
dev_network_count:  7
learn step counter:  1951
dev_network_count:  7
EPOCH %d 5
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.5904900000000001 0.5904900000000001
4972 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4973 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4974 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4975 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4976 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4977 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4978 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
learn step counter:  2001
dev_network_count:  7
learn step counter:  2051
dev_network_count:  7

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7167,  0.0667,  0.3410])
So far:  [array([2]), array([6])]  the state[:3] is:  tensor([-0.9057,  0.6030, -0.6316])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

So far:  [array([2])]  the state[:3] is:  tensor([-0.7554,  0.8335, -0.4593])
So far:  [array([2]), array([8])]  the state[:3] is:  tensor([-0.9850,  0.8968, -0.9234])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 

So far:  [array([2])]  the state[:3] is:  tensor([0.2954, 0.9133, 0.9181])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.5009,  0.9886,  0.3796])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9601,  0.9921, -0.7420])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 5 3]
Eval  :  [[2 4 7 3]]
Reward:  [ 1.  -2.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 6 3]
Eval  :  [[2 6 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 5 3]
Eval  :  [[2 5 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 6 3]
Eval  :  [[2 6 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 6 3]
Eval  :  [[2 4 6 3]]
Reward:  [1.  0.8 0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 5 3]
Eval  :  [[2 6 7 3]]
Reward:  [-1.  -0.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['4', '2', '1 3', '4 4', '2', '0', '4', '1 4', '4 3', '4']
8  r_total and score:  257.8000000000004 69.88114688402233
Current Bleu score is:  69.88114688402233
learn step counter:  2101
dev_network_count:  8
learn step counter:  2151
dev_network_count:  8
learn step counter:  2201
dev_network_count:  8
learn step counter:  2251
dev_network_count:  8
learn step counter:  2301
dev_network_count:  8
learn step counter:  2351
dev_network_count:  8

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7167,  0.0667,  0.3410])
So far:  [array([2]), array([6])]  the state[:3] is:  tensor([-0.9057,  0.6030, -0.6316])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

So far:  [array([2])]  the state[:3] is:  tensor([-0.7554,  0.8335, -0.4593])
So far:  [array([2]), array([8])]  the state[:3] is:  tensor([-0.9850,  0.8968, -0.9234])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 

So far:  [array([2])]  the state[:3] is:  tensor([0.2954, 0.9133, 0.9181])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.5009,  0.9886,  0.3796])
So far:  [array([2]), array([4]), array([4])]  the state[:3] is:  tensor([-0.9673,  0.9915, -0.7579])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 5 3]
Eval  :  [[2 4 4 3]]
Reward:  [ 1.  -2.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 6 3]
Eval  :  [[2 6 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 5 3]
Eval  :  [[2 5 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 6 3]
Eval  :  [[2 6 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 6 3]
Eval  :  [[2 4 6 3]]
Reward:  [1.  0.8 0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 5 3]
Eval  :  [[2 6 7 3]]
Reward:  [-1.  -0.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['4', '2', '1 1', '4 4', '2', '0', '4', '1 4', '4 3', '4']
9  r_total and score:  253.4000000000004 72.61510072703895
Current Bleu score is:  72.61510072703895
learn step counter:  2401
dev_network_count:  9
learn step counter:  2451
dev_network_count:  9
learn step counter:  2501
dev_network_count:  9
learn step counter:  2551
dev_network_count:  9
learn step counter:  2601
dev_network_count:  9
learn step counter:  2651
dev_network_count:  9

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7167,  0.0667,  0.3410])
So far:  [array([2]), array([6])]  the state[:3] is:  tensor([-0.9057,  0.6030, -0.6316])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

So far:  [array([2])]  the state[:3] is:  tensor([-0.7554,  0.8335, -0.4593])
So far:  [array([2]), array([8])]  the state[:3] is:  tensor([-0.9850,  0.8968, -0.9234])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 

So far:  [array([2])]  the state[:3] is:  tensor([0.2954, 0.9133, 0.9181])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.5009,  0.9886,  0.3796])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9601,  0.9921, -0.7420])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 5 3]
Eval  :  [[2 4 7 3]]
Reward:  [ 1.  -2.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 6 3]
Eval  :  [[2 6 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 5 3]
Eval  :  [[2 5 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 6 3]
Eval  :  [[2 6 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 6 3]
Eval  :  [[2 4 6 3]]
Reward:  [1.  0.8 0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 5 3]
Eval  :  [[2 6 7 3]]
Reward:  [-1.  -0.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['4', '2', '1 3', '4 4', '2', '0', '4', '1 4', '4 3', '4']
10  r_total and score:  253.20000000000041 72.90498252127077
Current Bleu score is:  72.90498252127077
learn step counter:  2701
dev_network_count:  10
learn step counter:  2751
dev_network_count:  10
learn step counter:  2801
dev_network_count:  10
learn step counter:  2851
dev_network_count:  10
learn step counter:  2901
dev_network_count:  10
learn step counter:  2951
dev_network_count:  10
EPOCH %d 6
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.531441 0.531441
2465 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2466 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2467 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2468 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2469 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2470 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2471 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7167,  0.0667,  0.3410])
So far:  [array([2]), array([7])]  the state[:3] is:  tensor([-0.9274,  0.6028, -0.6498])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 7 3]]
Reward:  [1.  0.8] 

So far:  [array([2])]  the state[:3] is:  tensor([-0.7554,  0.8335, -0.4593])
So far:  [array([2]), array([8])]  the state[:3] is:  tensor([-0.9850,  0.8968, -0.9234])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 

So far:  [array([2])]  the state[:3] is:  tensor([0.2954, 0.9133, 0.9181])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.5009,  0.9886,  0.3796])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9601,  0.9921, -0.7420])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 5 3]
Eval  :  [[2 4 7 3]]
Reward:  [ 1.  -2.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 6 3]
Eval  :  [[2 6 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 5 3]
Eval  :  [[2 7 3]]
Reward:  [-1.   2.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 6 3]
Eval  :  [[2 6 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 6 3]
Eval  :  [[2 4 6 3]]
Reward:  [1.  0.8 0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 5 3]
Eval  :  [[2 5 7 3]]
Reward:  [-1.  -0.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 7 3]]
Reward:  [1.  0.8] 

valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['3', '2', '1 3', '4 4', '2', '3', '4', '1 4', '0 3', '3']
11  r_total and score:  253.60000000000045 68.37635211648524
Current Bleu score is:  68.37635211648524
learn step counter:  3001
dev_network_count:  11
learn step counter:  3051
dev_network_count:  11
learn step counter:  3101
dev_network_count:  11
learn step counter:  3151
dev_network_count:  11
learn step counter:  3201
dev_network_count:  11
learn step counter:  3251
dev_network_count:  11

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7167,  0.0667,  0.3410])
So far:  [array([2]), array([6])]  the state[:3] is:  tensor([-0.9057,  0.6030, -0.6316])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

So far:  [array([2])]  the state[:3] is:  tensor([-0.7554,  0.8335, -0.4593])
So far:  [array([2]), array([8])]  the state[:3] is:  tensor([-0.9850,  0.8968, -0.9234])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 

So far:  [array([2])]  the state[:3] is:  tensor([0.2954, 0.9133, 0.9181])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.5009,  0.9886,  0.3796])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9601,  0.9921, -0.7420])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 5 3]
Eval  :  [[2 4 7 3]]
Reward:  [ 1.  -2.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 6 3]
Eval  :  [[2 6 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 5 3]
Eval  :  [[2 7 3]]
Reward:  [-1.   2.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 6 3]
Eval  :  [[2 6 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 6 3]
Eval  :  [[2 4 6 3]]
Reward:  [1.  0.8 0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 5 3]
Eval  :  [[2 6 7 3]]
Reward:  [-1.  -0.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['4', '2', '1 3', '4 4', '2', '3', '4', '1 4', '4 3', '4']
12  r_total and score:  264.40000000000043 69.34647072837512
Current Bleu score is:  69.34647072837512
learn step counter:  3301
dev_network_count:  12
learn step counter:  3351
dev_network_count:  12
learn step counter:  3401
dev_network_count:  12
learn step counter:  3451
dev_network_count:  12
learn step counter:  3501
dev_network_count:  12
learn step counter:  3551
dev_network_count:  12

 Lets copy the Q-value Net in to Q-target net!. And test the performace on the dev data: 
So far:  [array([2])]  the state[:3] is:  tensor([-0.7167,  0.0667,  0.3410])
So far:  [array([2]), array([6])]  the state[:3] is:  tensor([-0.9057,  0.6030, -0.6316])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

So far:  [array([2])]  the state[:3] is:  tensor([-0.7554,  0.8335, -0.4593])
So far:  [array([2]), array([8])]  the state[:3] is:  tensor([-0.9850,  0.8968, -0.9234])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 

So far:  [array([2])]  the state[:3] is:  tensor([0.2954, 0.9133, 0.9181])
So far:  [array([2]), array([4])]  the state[:3] is:  tensor([-0.5009,  0.9886,  0.3796])
So far:  [array([2]), array([4]), array([7])]  the state[:3] is:  tensor([-0.9601,  0.9921, -0.7420])

 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 5 3]
Eval  :  [[2 4 7 3]]
Reward:  [ 1.  -2.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 6 3]
Eval  :  [[2 6 6 3]]
Reward:  [-1.   2.8  0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 8 3]
Eval  :  [[2 8 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 5 3]
Eval  :  [[2 5 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 6 3]
Eval  :  [[2 6 3]]
Reward:  [1.  0.8] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 4 6 3]
Eval  :  [[2 4 6 3]]
Reward:  [1.  0.8 0.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 5 3]
Eval  :  [[2 6 7 3]]
Reward:  [-1.  -0.2  3.6] 


 Sample-------------Target vs Eval_net prediction:--Raw---and---Decoded-----
Target:  [2 7 3]
Eval  :  [[2 6 3]]
Reward:  [-1.   2.8] 

valid_references:  ['3', '2', '1 0', '3 4', '2', '0', '4', '1 4', '3 0', '3']
valid_hypotheses:  ['4', '2', '1 3', '4 4', '2', '0', '4', '1 4', '4 3', '4']
13  r_total and score:  257.8000000000004 69.88114688402233
Current Bleu score is:  69.88114688402233
learn step counter:  3601
dev_network_count:  13
EPOCH %d 7
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.4782969000000001 0.4782969000000001
4958 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4959 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4960 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4961 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4962 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4963 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4964 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 8
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.4304672100000001 0.4304672100000001
2451 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2452 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2453 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2454 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2455 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2456 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2457 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 9
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.3874204890000001 0.3874204890000001
4944 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4945 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4946 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4947 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4948 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4949 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4950 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 10
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.3486784401000001 0.3486784401000001
2437 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2438 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2439 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2440 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2441 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2442 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2443 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 11
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.31381059609000006 0.31381059609000006
4930 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4931 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4932 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4933 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4934 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4935 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4936 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 12
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.2824295364810001 0.3
2423 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2424 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2425 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2426 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2427 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2428 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2429 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 13
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.2541865828329001 0.3
4916 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4917 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4918 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4919 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4920 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4921 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4922 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 14
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.2287679245496101 0.3
2409 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2410 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2411 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2412 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2413 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2414 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2415 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 15
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.20589113209464907 0.3
4902 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4903 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4904 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4905 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4906 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4907 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4908 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 16
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.18530201888518416 0.3
2395 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2396 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2397 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2398 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2399 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2400 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2401 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 17
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.16677181699666577 0.3
4888 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4889 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4890 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4891 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4892 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4893 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4894 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 18
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.15009463529699918 0.3
2381 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2382 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2383 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2384 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2385 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2386 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2387 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 19
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.13508517176729928 0.3
4874 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4875 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4876 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4877 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4878 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4879 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4880 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 20
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.12157665459056935 0.3
2367 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2368 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2369 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2370 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2371 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2372 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2373 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 21
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.10941898913151242 0.3
4860 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4861 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4862 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4863 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4864 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4865 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4866 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 22
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.09847709021836118 0.3
2353 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2354 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2355 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2356 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2357 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2358 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2359 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 23
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.08862938119652507 0.3
4846 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4847 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4848 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4849 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4850 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4851 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4852 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 24
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.07976644307687256 0.3
2339 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2340 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2341 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2342 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2343 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2344 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2345 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 25
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.0717897987691853 0.3
4832 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4833 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4834 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4835 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4836 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4837 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4838 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 26
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.06461081889226677 0.3
2325 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2326 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2327 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2328 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2329 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2330 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2331 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 27
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.058149737003040096 0.3
4818 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4819 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4820 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4821 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4822 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4823 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4824 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 28
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.05233476330273609 0.3
2311 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2312 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2313 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2314 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2315 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2316 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2317 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 29
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.047101286972462485 0.3
4804 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4805 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4806 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4807 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4808 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4809 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4810 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 30
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.04239115827521624 0.3
2297 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2298 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2299 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2300 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2301 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2302 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2303 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 31
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.038152042447694615 0.3
4790 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4791 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4792 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4793 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4794 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4795 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4796 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 32
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.03433683820292515 0.3
2283 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2284 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2285 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2286 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2287 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2288 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2289 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 33
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.030903154382632636 0.3
4776 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4777 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4778 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4779 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4780 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4781 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4782 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 34
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.027812838944369374 0.3
2269 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2270 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2271 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2272 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2273 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2274 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2275 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 35
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.025031555049932437 0.3
4762 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4763 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4764 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4765 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4766 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4767 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4768 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 36
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.022528399544939195 0.3
2255 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2256 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2257 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2258 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2259 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2260 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2261 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 37
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.020275559590445275 0.3
4748 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4749 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4750 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4751 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4752 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4753 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4754 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 38
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.01824800363140075 0.3
2241 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2242 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2243 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2244 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2245 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2246 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2247 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 39
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.016423203268260675 0.3
4734 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4735 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4736 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4737 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4738 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4739 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4740 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 40
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.014780882941434608 0.3
2227 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2228 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2229 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2230 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2231 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2232 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2233 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 41
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.013302794647291146 0.3
4720 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4721 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4722 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4723 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4724 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4725 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4726 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 42
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.011972515182562033 0.3
2213 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2214 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2215 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2216 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2217 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2218 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2219 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 43
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.01077526366430583 0.3
4706 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4707 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4708 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4709 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4710 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4711 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4712 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 44
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.009697737297875247 0.3
2199 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2200 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2201 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2202 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2203 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2204 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2205 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 45
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.008727963568087723 0.3
4692 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4693 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4694 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4695 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4696 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4697 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4698 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 46
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.00785516721127895 0.3
2185 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2186 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2187 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2188 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2189 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2190 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2191 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 47
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.007069650490151055 0.3
4678 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4679 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4680 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4681 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4682 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4683 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4684 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 48
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.00636268544113595 0.3
2171 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2172 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2173 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2174 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2175 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2176 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2177 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 49
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.005726416897022355 0.3
4664 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4665 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4666 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4667 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4668 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4669 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4670 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 50
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.00515377520732012 0.3
2157 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2158 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2159 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2160 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2161 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2162 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2163 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 51
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.004638397686588108 0.3
4650 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4651 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4652 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4653 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4654 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4655 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4656 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 52
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.004174557917929297 0.3
2143 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2144 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2145 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2146 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2147 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2148 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2149 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 53
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.0037571021261363674 0.3
4636 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4637 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4638 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4639 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4640 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4641 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4642 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 54
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.0033813919135227306 0.3
2129 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2130 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2131 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2132 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2133 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2134 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2135 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 55
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.0030432527221704577 0.3
4622 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4623 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4624 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4625 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4626 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4627 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4628 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 56
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.002738927449953412 0.3
2115 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2116 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2117 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2118 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2119 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2120 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2121 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 57
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.002465034704958071 0.3
4608 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4609 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4610 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4611 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4612 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4613 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4614 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 58
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.002218531234462264 0.3
2101 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2102 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2103 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2104 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2105 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2106 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2107 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 59
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.0019966781110160375 0.3
4594 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4595 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4596 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4597 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4598 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4599 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4600 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 60
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001797010299914434 0.3
2087 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2088 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2089 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2090 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2091 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2092 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2093 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 61
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.0016173092699229906 0.3
4580 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4581 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4582 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4583 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4584 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4585 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4586 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 62
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.0014555783429306916 0.3
2073 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2074 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2075 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2076 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2077 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2078 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2079 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 63
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.0013100205086376223 0.3
4566 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4567 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4568 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4569 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4570 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4571 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4572 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 64
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.0011790184577738603 0.3
2059 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2060 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2061 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2062 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2063 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2064 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2065 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 65
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001061116611996474 0.3
4552 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4553 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4554 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4555 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4556 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4557 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4558 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 66
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
2045 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2046 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2047 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2048 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2049 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2050 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2051 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 67
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
4538 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4539 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4540 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4541 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4542 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4543 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4544 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 68
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
2031 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2032 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2033 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2034 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2035 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2036 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2037 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 69
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
4524 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4525 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4526 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4527 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4528 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4529 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4530 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 70
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
2017 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2018 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2019 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2020 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2021 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2022 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2023 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 71
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
4510 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4511 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4512 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4513 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4514 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4515 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4516 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 72
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
2003 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
2004 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
2005 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
2006 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
2007 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
2008 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
2009 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 73
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
4496 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4497 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4498 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4499 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4500 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4501 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4502 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 74
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
1989 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
1990 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
1991 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
1992 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
1993 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
1994 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
1995 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 75
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
4482 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4483 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4484 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4485 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4486 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4487 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4488 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 76
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
1975 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
1976 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
1977 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
1978 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
1979 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
1980 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
1981 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 77
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
4468 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4469 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4470 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4471 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4472 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4473 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4474 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 78
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
1961 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
1962 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
1963 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
1964 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
1965 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
1966 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
1967 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 79
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
4454 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4455 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4456 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4457 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4458 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4459 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4460 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 80
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
1947 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
1948 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
1949 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
1950 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
1951 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
1952 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
1953 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 81
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
4440 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4441 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4442 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4443 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4444 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4445 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4446 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 82
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
1933 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
1934 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
1935 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
1936 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
1937 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
1938 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
1939 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 83
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
4426 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4427 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4428 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4429 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4430 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4431 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4432 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 84
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
1919 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
1920 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
1921 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
1922 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
1923 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
1924 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
1925 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 85
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
4412 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4413 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4414 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4415 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4416 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4417 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4418 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 86
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
1905 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
1906 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
1907 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
1908 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
1909 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
1910 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
1911 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 87
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
4398 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4399 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4400 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4401 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4402 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4403 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4404 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 88
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
1891 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
1892 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
1893 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
1894 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
1895 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
1896 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
1897 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 89
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
4384 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4385 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4386 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4387 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4388 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4389 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4390 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 90
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
1877 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
1878 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
1879 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
1880 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
1881 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
1882 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
1883 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 91
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
4370 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4371 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4372 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4373 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4374 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4375 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4376 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 92
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
1863 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
1864 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
1865 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
1866 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
1867 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
1868 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
1869 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 93
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
4356 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4357 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4358 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4359 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4360 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4361 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4362 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 94
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
1849 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
1850 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
1851 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
1852 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
1853 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
1854 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
1855 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 95
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
4342 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4343 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4344 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4345 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4346 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4347 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4348 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 96
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
1835 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
1836 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
1837 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
1838 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
1839 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
1840 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
1841 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
EPOCH %d 97
On the pretrain of the Q target network. The beam_dqn =1.
 beam_dqn, egreed, gamma:  1 0.001 0.3
4328 7 1.0 3 1  ... s[:3]:  [-0.71668434  0.06666937  0.34099293]  ... s_[:5]:  [-0.9274273   0.6027868  -0.64979553]
4329 3 0.8 0 0  ... s[:3]:  [-0.9274273   0.6027868  -0.64979553]  ... s_[:5]:  [0. 0. 0.]
4330 8 1.0 3 1  ... s[:3]:  [-0.75541776  0.83350456 -0.4593433 ]  ... s_[:5]:  [-0.9849706   0.89682406 -0.9233895 ]
4331 3 0.8 0 0  ... s[:3]:  [-0.9849706   0.89682406 -0.9233895 ]  ... s_[:5]:  [0. 0. 0.]
4332 4 1.0 5 1  ... s[:3]:  [0.29544878 0.91327965 0.91813076]  ... s_[:5]:  [-0.5008849   0.9886308   0.37956738]
4333 5 0.8 3 1  ... s[:3]:  [-0.5008849   0.9886308   0.37956738]  ... s_[:5]:  [-0.97250515  0.9893948  -0.73787904]
4334 3 0.6 0 0  ... s[:3]:  [-0.97250515  0.9893948  -0.73787904]  ... s_[:5]:  [0. 0. 0.]
